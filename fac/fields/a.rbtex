<%
  require "../eruby_util.rb"
%>

<% clear_answer_data %>

<%
  chapter(
    '01',
    %q{Electric and Magnetic Fields},
    'ch:fields-intro',
    %q{A telescopic view of an energetic eruption on the sun, August 2012. The bright loops at 
     the upper left are
     ionized gas following the sun's magnetic field lines.},
    {'opener'=>'coronal-mass-ejection','sidecaption'=>true,'anonymous'=>true}
  )
%>

A college campus. Many, perhaps most, of the people walking by are
doing something with their phones. They are sending and receiving
invisible radio signals, which are disturbances in the electric and
magnetic \emph{fields}, sort of like disturbances in ``the force'' in
Star Wars. Surrounding and penetrating the landscape of people, trees,
and buildings, there is a second, hidden landscape of fields.  This
hidden aspect of reality has no mass and is not made of material
particles such as electrons. 

<% begin_sec("A surprising link to the nature of time",0,'time') %>

Bear with me for a page while I describe some seemingly unrelated
ideas about the nature of time, which will turn out to tie back in
logically to our study of fields.  The phone signals in the college
campus scene are structured in complex ways and carry information
using codes like English and binary, but often the signal can carry
all the needed information simply because of the \emph{time} when it
arrives. My wife worries about my safety when I head out for a day of
rock climbing, so when her phone rings late in the afternoon, the
simple fact of the arrival of a signal from me carries the information
that I'm safe. This suggests that we consider the nature of
\emph{time} as a basic question when embarking on our study of
electricity and magnetism. 

A colorful experiment demonstrating the nature of time was done by
Hafele and Keating in 1971 (figure \figref{hk-in-cabin}).  The two
physicists brought atomic clocks with them on round-the-world flights
aboard commercial passenger jets, then compared the clocks with other
clocks that had been left at home. When the clocks were reunited, they
\emph{disagreed} by $\sim 100\ \zu{ns}$. The results were consistent
with Einstein's 1915 theory of relativity, and were interpreted as a
combined effect from motion and gravity. Because it's difficult to
move a clock very fast without putting it on an airplane, it wasn't
until 2010 that Chou \emph{et al.}\footnote{Science 329 (2010) 1630}
succeeded in carrying out a conceptually simpler tabletop experiment
in which a clock was simply moved around (at speeds on the order of 10
m/s) without taking it to high elevation, thus isolating the effect of
motion from the gravitational effect. It is the effect of motion that
will be of interest to us here.

<% marg(50) %>
<%   
  fig(
    'hk-in-cabin',
    %q{The clock took up two seats, and two tickets were bought for it under the name of ``Mr.~Clock.''}
  )
%>
<% end_marg %>

It would be natural to try to explain this effect of motion on time as
arising from the clocks' sensitivity to noise, cabin pressure, or
vibration. But exactly the same effect is observed with other,
completely different types of clocks under completely different
circumstances, and even with processes such as the decay of elementary
particles moving at high speeds --- the radioactive half-life is
prolonged if the particles are in motion. 

The conclusion is that \emph{time itself} is not absolute: when one
observer is in motion relative to another observer, they will disagree
on the rate at which time passes. A clock appears to tick at its
normal rate according to an observer who is at rest relative to the
clock, while observers moving relative to the clock say that the clock
is slow. 

We are now ready to connect these observations about time back to our
main subjects of study, which are the electric and magnetic fields.
We will prove that if time is relative, then disturbances in the
electric and magnetic fields must propagate (travel or spread out) at
some finite speed, not instantaneously. The logic works like this.
Suppose that observers Alice and Betty are both aboard spaceships, and
moving at velocities that are different from each other, but both
constant.  Alice is free to choose her own ship as a frame of
reference, in which case she considers herself to be at rest while
Betty moves.  But the situation is completely symmetrical, so Betty
can say the same thing. Because motion is relative, we can't say who
is ``really'' moving and who is ``really'' at rest. Alice says Betty's
time is slowed down due to the effect of motion on time, but Betty
says Alice is slowed down. This seems paradoxical, since it seems that
they should be able to get in contact by radio and resolve the
disagreement. But our experience talking on cell phones misleads us
into assuming that radio communication is instantaneous. It isn't.  I
haven't demonstrated in mathematical detail exactly how logical
consistency is restored by the fact that signals take time to
propagate. (That would take us too far afield into a discussion of
relativity, which is not our main topic right now.) But this example
is sufficient to show that logical consistency cannot be preserved if
there is some mechanism for sending signals instantaneously, as in the
``subspace radio'' of the Star Trek universe. Thus we can never send
signals simultaneously. 

In your previous study of mechanics, you were probably briefly exposed
to the concept of a field through mentions of the gravitational field.
From that experience, it would be easy to get the impression that
fields are an optional concept, and that changes in the gravitational
field (e.g., due to the motion of a planet in its orbit) would take
effect immediately, throughout the universe. This is what Isaac Newton
believed, but it is not how the universe actually turns out to work.

The maximum speed at which signals can propagate is notated $c$, and
it has the numerical value of about $3.0\times10^8\ \munit/\sunit$.
We often refer to it as the speed of light, since visible light travels at $c$.
Light is a wave disturbance in the electric and magnetic fields, and
the visible spectrum from red to violet constitutes one part of a much
larger electromagnetic spectrum, which includes phenomena as apparently disparate
as radio waves and x-rays. Different parts of the spectrum are distinguished
either by their frequency (the number of vibrations per unit time) or, equivalently, by their
wavelength (the distance between successive wave crests). Fundamentally,
it's best to think of $c$ not as the speed of light but as a maximum
speed of cause and effect, or as a sort of conversion factor between time
and space units.
<% end_sec('time') %>

<% begin_sec("Basic properties of fields",0,'fields-basic-properties') %>
In order to get started with our study of the electric and magnetic fields,
we present three basic assumptions:

<% marg(-300) %>
<%   
  fig(
    'coil-spring-superposition-two-pos',
    %q{Wave pulses on a coil spring travel toward each other, superpose, and reemerge.}
  )
%>
<% end_marg %>

\begin{enumerate}
\item The electric and magnetic fields are \emph{observable}. We can measure them.
\item The electric and magnetic fields are \emph{vectors}.
\item \emph{Superposition:\/} When fields are created by two effects, the fields contributed
by the two effects at a particular point add as vectors, and it is the vector sum that is actually
observed at that location in space.
\end{enumerate}

Assumption 3, superposition, is typical of wave phenomena, as shown in figure \figref{coil-spring-superposition-two-pos}.
As an example involving electric and magnetic fields,
the lens in figure \figref{converging-rays} brings the three beams of light together at a point,
then the waves will pass through one another. The electric and magnetic fields in
the region of intersection add as vectors but not otherwise interact. The beams
emerge unscathed on the other side.

To see the significance of assumptions 1 and 2, the observability and vector nature of the fields,
it may be helpful to see examples of how
they do not hold for other phenomena besides electricity and magnetism. These are a little
exotic and are just for fun. If this sort of thing doesn't interest you for its own sake,
feel free to skip ahead to section \ref{sec:vectors}.

Our universe does contain fields that are scalars rather than vectors. One example is
dark energy, discovered in 1998, which drives the accelerating expansion of the universe.
Another example is the Higgs field, whose existence was predicted theoretically in 1964
and which was detected experimentally at the Large Hadron Collider in 2012.

<% marg(60) %>
<%   
  fig(
    'converging-rays',
    %q{Three rays of light converge.}
  )
%>
<% end_marg %>

<%
  fig(
    'ep',
    'The gravitational field is not observable.',
    {'width'=>'wide','sidecaption'=>true}
  )
%>

One of the considerations that led Einstein to his general theory of
relativity is that the gravitational field is \emph{not} necessarily
observable.  Consider Cathy, the girl in figure \figref{ep}.  She is shown in a
cutaway view, sealed inside a well-lit and air-conditioned box, which
happens to be her favorite place to go and think about physics. (It's
small, but it's private and it's all hers.)  She feels pressure from
the seat of the chair, and this would normally suggest that she was
experiencing a gravitational force, perhaps from a nearby planet,
\subfigref{ep}{2}. But Cathy can't infer this without peeking outside at her
surroundings.  It's equally possible that the box is in deep space,
\subfigref{ep}{3}, with no gravity whatsoever, but is being towed by a rocket
ship, so that it accelerates constantly. No possible experiment done
inside the box can tell her which of these is the
case.

<% end_sec('fields-basic-properties') %>

<% begin_sec("Review of vectors",4,'vectors') %>

<% begin_sec("Definition of vectors and scalars",0,'vectors-and-scalars') %>

Because the electric and magnetic fields are vectors, we present a brief review of the topic, starting
with a definition that may be different from the one you've seen previously, but
is in better agreement with how physicists actually think about these things.

Most of the things we want to measure in physics fall into two categories,
called vectors and scalars.\index{vector}\index{scalar}
A \emph{scalar} is something
that doesn't change when you turn it around, while a \emph{vector} does change
when you rotate it, and the way in which it changes is the same as the way
in which a pointer such as a pencil or an arrow would change.
Figure \figref{vectors-and-scalars} shows two examples.
<%
  fig(
    'vectors-and-scalars',
    %q{Temperature is a scalar: a hot cup of coffee doesn't change its temperature
        when we turn it around. Force is a vector. When I play tug-of-war with my dog,
        her force and mine are the same in strength, but they're in opposite directions.
        If we swap positions, our forces reverse their directions, just as a pair of arrows would.},
    {'width'=>'wide','sidecaption'=>true}
  )
%>
A vector $\vc{A}$ has a magnitude $|\vc{A}|$, which means its size, length, or amount. Rotating a vector
can change the vector, but will never change its magnitude.

<%
  fig(
    'earth-field-three-components',
    %q{A magnetic compass and dip meter are used to find the direction of the earth's field in three dimensions.},
    {'width'=>'wide','sidecaption'=>true}
  )
%>

In figure \figref{earth-field-three-components}, a compass is first used to find the vertical plane
containing the earth's magnetic field. The needle defines the magnetic north-south direction
(differing from true north, which is defined by the earth's rotation). Once this plane has been determined,
a magnetic dip meter is used to find the three-dimensional direction of the field. The field
has a large vertical component.

<% end_sec('vectors-and-scalars') %>

<% begin_sec("Components of vectors",0,'vector-components') %>
A component of a vector is a signed real number giving its projection onto a line
such as a coordinate axis.
In two dimensions,
when a vector $\vc{A}$ lies in the $x$-$y$ plane, at an angle $\theta$ counterclockwise from the $x$
axis, its components are $A_x=A\cos\theta$ and $A_y=A\sin\theta$, where $A$ is a shorthand notation for 
$|\vc{A}|$.

In figure \figref{horseshoe-magnet-components}, the 
magnetic field sensor only measures the component of the field parallel to the wand,
at its tip. At the point being tested, the
component along the horseshoe's axis of symmetry is nearly zero. Rotating the sensor
by 90 degrees gives a large reading, showing that the field is perpendicular to the
axis of symmetry. If the magnetic field had been a scalar, then these two measurements
would have had to give the same result.
<%
  fig(
    'horseshoe-magnet-components',
    'A magnetic field sensor measures two perpendicular components of the field of a horseshoe magnet.',
    {'width'=>'wide','sidecaption'=>true}
  )
%>


<% end_sec('vector-components') %>

<% begin_sec("Vector addition",0,'vector-addition') %>

<% marg() %>
<%   
  fig(
    'tip-to-tail',
    %q{Graphical addition of vectors.}
  )
%>
<% end_marg %>

Scalars are just numbers, and we do arithmetic on them in the usual
way. Vectors are different. Vectors can be added by placing them tip to tail,
and then drawing a vector from the tail of the first vector to the tip
of the second vector. A vector can be multiplied by a scalar to give a new
vector. For instance, if $\vc{A}$ is a vector, then $2\vc{A}$ is a vector
that has the same direction but twice the magnitude. Multiplying by $-1$ is
the same as flipping the vector, $-\vc{A}=(-1)\vc{A}$. Vector subtraction can be
accomplished by flipping and adding.

The tip-to-tail method of adding vectors is called graphical addition.
It is equivalent to adding components, which is called
analytic addition. The following example demonstrates analytic addition in
a case where it is necessary to do conversions back and forth between
the magnitude-direction and Cartesian descriptions of the vectors. If you have
any trouble following this example, then you should review vector addition
from a source that provides more detail than this brief review.

\begin{eg}{Analytic addition of vectors}\label{eg:la-vegas}
\egquestion
The displacement vector from San Diego to Los Angeles has magnitude
190 km and direction 129\degunit counterclockwise from east.  The one
from LA to Las Vegas is 370 km at 38\degunit counterclockwise from
east. Find the distance and direction from San Diego to Las Vegas. 

<% marg(300) %>
<%   
  fig(
    'eg-sd-vegas',
    %q{Example \ref{eg:la-vegas}.},
    {
      'anonymous'=>true
    }

  )
%>
<% end_marg %>


\eganswer
The trig needed in order
to find the components of the first leg (San Diego to LA) is:
\begin{align*}
  \Delta x_1 &= (190\ \zu{km})\cos 129\degunit = -120\ \zu{km} \\
  \Delta y_1 &= (190\ \zu{km})\sin 129\degunit = 148\ \zu{km} 
\end{align*}
Applying the same pattern to the second leg (LA to Vegas), we have:
\begin{align*}
  \Delta x_2 &= (370\ \zu{km})\cos 38\degunit = 292\ \zu{km} \\
  \Delta y_2 &= (370\ \zu{km})\sin 38\degunit = 228\ \zu{km} 
\end{align*}
For the vector directly from San Diego to Las Vegas, we have
\begin{align*}
  \Delta x &= \Delta x_1 +  \Delta x_2 = 172\ \zu{km}\\
  \Delta y &= \Delta y_1 +  \Delta y_2 = 376\ \zu{km}\eqquad.
\end{align*}
The distance from San Diego to Las Vegas is found using the Pythagorean theorem,
\begin{equation*}
  \sqrt{(172\ \zu{km})^2+(376\ \zu{km})^2} = 410\ \zu{km}
\end{equation*}
(rounded to two sig figs). The direction
is one of the two possible values of the inverse tangent
\begin{equation*}
  \tan^{-1} (\Delta y/\Delta x) = \{65\degunit,245\degunit\}\eqquad.
\end{equation*}
Consulting a sketch shows that the first of these values is the correct one.
\end{eg}

<% end_sec('vector-addition') %>

<% begin_sec("Unit vector notation",0,'unit-vector-notation') %>
Suppose we want to tell someone that a certain vector $\vc{A}$ in two dimensions
has components $A_x=3$ and $A_y=7$. A more compact way of notating this is
$\vc{A}=3\hat{\vc{x}}+7\hat{\vc{y}}$, where $\hat{\vc{x}}$ and $\hat{\vc{y}}$, read ``x-hat'' and ``y-hat,''
are the vectors with magnitude one that point in the positive $x$ and $y$
directions. Some authors notate the unit vectors as $\hat{\vc{i}}$, $\hat{\vc{j}}$, and $\hat{\vc{k}}$
rather than $\hat{\vc{x}}$, $\hat{\vc{y}}$, and $\hat{\vc{z}}$.
<% end_sec('unit-vector-notation') %>

<% begin_sec("Rotational invariance",0,'rotational-invariance') %>
Certain vector operations
are useful and others are not. Consider the operation of
multiplying two vectors component by component to produce a third vector:
\begin{align*}
        R_x    &=    P_x Q_x  \\
        R_y    &=    P_y Q_y  \\
        R_z    &=    P_z Q_z.
\end{align*}
This operation will never be useful in physics because it can give different
results depending on our choice of coordinates. That is, if we change our coordinate
system by rotating the axes, then the resulting vector
$\vc{R}$ will of course have different components, but these will not (except in exceptional cases)
be the components of the same vector expressed in the new coordinates. We say that this
operation is not rotationally invariant.\index{rotational invariance}

The universe doesn't come equipped with coordinates, so if any vector operation is to be useful in
physics, it must be rotationally invariant. Vector addition, for example, is rotationally invariant, since we
can define it using tip-to-tail graphical addition, and this definition doesn't even refer to any coordinate
system. This rotational invariance would still have held, but might not have been so obvious,
if we had defined addition in terms of addition of components.

\begin{eg}{Calibrating an electronic compass}
Some smart phones and GPS units contain electronic compasses that can
sense the direction of the earth's magnetic field vector, notated
$\vc{B}$. Because all vectors work according to the same rules, you
don't need to know anything yet about magnetism in order to understand
this example.  Unlike a traditional compass that uses a magnetized
needle on a bearing, an electronic compass has no moving parts. It
contains two sensors oriented perpendicular to one another, and each
sensor is only sensitive to the component of the earth's field that
lies along its own axis. Because a choice of coordinates is arbitrary,
we can take one of these sensors as defining the $x$ axis and the
other the $y$. Given the two components $B_x$ and $B_y$, the device's
computer chip can compute the angle of magnetic north relative to its
sensors, $\tan^{-1}(B_y/B_x)$.

All compasses are vulnerable to errors because of nearby magnetic
materials, and in particular it may happen that some part of the
compass's own housing becomes magnetized. In an electronic compass,
rotational invariance provides a convenient way of calibrating away
such effects by having the user rotate the device in a horizontal
circle. 

Suppose that when the compass is oriented in a certain way, it
measures $B_x=1.00$ and $B_y=0.00$ (in certain units).  We then expect
that when it is rotated 90 degrees clockwise, the sensors will detect
$B_x=0.00$ and $B_y=1.00$. 

But imagine instead that we get $B_x=0.20$ and $B_y=0.80$. This would
violate rotational invariance, since rotating the coordinate system is
supposed to give a different description of the \emph{same} vector.
The magnitude appears to have changed from 1.00 to
$\sqrt{0.20^2+0.80^2}=0.82$, and a vector can't change its magnitude
just because you rotate it. The compass's computer chip figures out
that some effect, possibly a slight magnetization of its housing, must
be adding an erroneous 0.2 units to all the $B_x$ readings, because
subtracting this amount from all the $B_x$ values gives vectors that
have the same magnitude, satisfying rotational invariance.
\end{eg}
<% end_sec('rotational-invariance') %>

<% begin_sec("Dot and cross product",0,'dot-and-cross-product') %>
The vector dot product\index{dot product} $\vc{A}\cdot\vc{B}$ is
defined as the (signed) component of $\vc{A}$ parallel to $\vc{B}$. It
is a scalar. If we know the magnitudes of the vectors and the angle
$\theta_{AB}$ between them, we can compute the dot product as
$|\vc{A}||\vc{B}|\cos\theta_{AB}$. If we know the components of the
vectors in a particular coordinate system, we can express the dot
product as $A_xB_x+A_yB_y+A_zB_z$. The dot product of a vector with
itself is the square of its magnitude, $|\vc{A}|^2=\vc{A}\cdot\vc{A}$,
and when we write $A^2$ as a notational shortcut, this is what we
mean. 

<% marg(300) %>
<%   
  fig(
    'parallelogram',
    %q{The magnitude of the cross product is the area of the shaded parallelogram.}
  )
%>
\spacebetweenfigs
<%   
  fig(
    'righthandxprod',
    %q{The right-hand rule for the direction of the vector cross product.}
  )
%>
<% end_marg %>

There is also a way of multiplying two vectors to obtain a vector
result. This is called the vector cross product\index{cross product},
$\vc{C}=\vc{A}\times\vc{B}$.  The magnitude of the cross product is
the area of the parallelogram illustrated in figure
\ref{fig:parallelogram}.  The direction of the cross product is
perpendicular to the plane in which $\vc{A}$ and $\vc{B}$ lie.  There
are two such directions, and of these two, we choose the one defined
by the right-hand rule illustrated in figure \ref{fig:righthandxprod}. 

The dot and cross products are the \emph{only} useful ways of
multiplying two vectors to form a scalar or a vector, respectively.
Any other definition of multiplication either will not yield a scalar
or vector, will not be rotationally invariant, or will be a trivial
variation on the dot or cross products in which the definitions are
multiplied by some scalar, e.g., $7\vc{A}\cdot\vc{B}$ or
$-\vc{A}\times\vc{B}$.

Unlike ordinary multiplication of real numbers, the cross product is anticommutative,
$\vc{A}\times\vc{B}=-\vc{B}\times\vc{A}$. The magnitude of the cross product can be expressed as
$|\vc{A}||\vc{B}|\sin\theta_{AB}$. In terms of the components, we have
\begin{align*}
        \vc{C}_x        &=  A_yB_z - B_yA_z\\
        \vc{C}_y        &=  A_zB_x - B_zA_x\\
        \vc{C}_z        &=  A_xB_y - B_xA_y.
\end{align*}

<% end_sec('dot-and-cross-product') %>

<% end_sec('vectors') %>

<% begin_hw_sec %>
<% begin_hw('b-field-dip',nil) %>__incl(hw/b-field-dip)<% end_hw() %>

<% end_hw_sec %>

<% end_chapter() %>
 %%----------------------------------------------------------


