
<%
  require "../eruby_util.rb"
%>

<%
  chapter(
    '11',
    %q{Electromagnetism},
    'ch:em',
    '',
    {'opener'=>''}
  )
%>

\epigraph{Think not that I am come to destroy the law, or the prophets:
I am not come to destroy, but to fulfill.}{Matthew 5:17}

<% begin_sec("More about the magnetic field",0) %>

<% begin_sec("Magnetic forces") %>

In this chapter, I assume you know a few basic ideas about Einstein's theory of relativity,
as described in sections \ref{sec:time-not-absolute} and \ref{sec:x-t-distortion}. 
Unless your typical workday involves rocket ships or particle accelerators,
all this relativity stuff might sound like a description of some bizarre
futuristic world that is completely hypothetical. There is, however, a relativistic
effect that occurs in everyday life, and it is obvious and dramatic: magnetism.
Magnetism, as we discussed previously, is an interaction between a moving
charge and another moving charge,
as opposed to electric forces, which act between any pair of charges, regardless of their
motion. Relativistic effects are weak for speeds that are small compared to the speed
of light, and the average speed at which electrons drift through a wire is quite
low (centimeters per second, typically), so how can relativity be behind an impressive
effect like a car being lifted by an electromagnet hanging from a crane? The key is
that matter is almost perfectly electrically neutral, and electric forces therefore
cancel out almost perfectly. Magnetic forces really aren't very strong, but electric
forces are even weaker.

<% marg(20) %>
<%
  fig(
    'fulfill',
    %q{The pair of charged particles, as seen in two different frames of reference.}
  )
%>
<% end_marg %>

What about the word ``relativity'' in the name of the theory?
It would seem problematic if moving charges interact differently than stationary charges,
since motion is a matter of opinion, depending on your frame of reference.
Magnetism, however, comes not to destroy relativity but to fulfill it. Magnetic interactions
\emph{must} exist according to the theory of relativity. To understand how this can be,
consider how time and space behave in relativity. Observers in different frames of reference
disagree about the lengths of measuring sticks and the speeds of clocks, but the laws
of physics are valid and self-consistent in either frame of reference.
Similarly, observers in different frames of reference disagree about what electric and magnetic
fields and forces there are, but they agree about concrete physical events.
For instance, figure \figref{fulfill}/1 shows two particles, with opposite charges,
which are not moving at a particular moment in time. An observer in this frame of reference
says there are electric fields around the particles, and predicts that as time goes on, the
particles will begin to accelerate towards one another, eventually colliding.
A different observer, \figref{fulfill}/2, says the particles are moving. This observer
also predicts that the particles will collide, but explains their motion in terms of both
an electric field, $\vc{E}$, and a magnetic field, $\vc{B}$. As we'll see shortly, the
magnetic field is \emph{required} in order to maintain consistency between the predictions made
in the two frames of reference.

<% marg(0) %>
<%
  fig(
    'bdeflects',
    %q{%
      A large current is created by shorting across the leads of the
              battery. The moving charges in the wire attract the moving charges in the
              electron beam, causing the electrons to curve.
    }
  )
%>

\spacebetweenfigs

<%
  fig(
    'brelativity',
    %q{%
      A charged particle and a current, seen in
              two different frames of reference. The second frame is moving at
              velocity $v$ with respect to the first frame, so all the velocities
              have $v$ subtracted from them. (As discussed in the main text,
              this is only approximately correct.)
    }
  )
%>
<% end_marg %>

To see how this really works out, we need to find a nice simple example that is
easy to calculate. An example like figure \figref{fulfill} is \emph{not} easy
to handle, because in the second frame of reference, the moving charges
create fields that change over time at any given location. Examples like
figure \figref{bdeflects} are easier, because there is a steady flow of charges, and
all the fields stay the same over time.\footnote{For a more practical 
demonstration of this effect, you can put an ordinary magnet
near a computer monitor. The picture will
be distorted. Make sure that the monitor has a demagnetizing (``degaussing'') button,
however! Otherwise you may permanently damage it. Don't use a television tube,
because TV tubes don't have demagnetizing buttons.}
What is remarkable about this demonstration is that there can be no electric fields
acting on the electron beam at all, since the total charge density throughout the wire
is zero. Unlike figure \figref{fulfill}/2, figure \figref{bdeflects} is purely magnetic.



To see why this must occur based on relativity, we make the mathematically idealized model
shown in figure \figref{brelativity}. The charge by itself is like one of the electrons
in the vacuum tube beam of figure \figref{bdeflects}, and a 
pair of moving, infinitely long line charges has been substituted for the wire. The electrons in a real wire
are in rapid thermal motion, and the current is created only by a slow drift superimposed
on this chaos. A second deviation from reality is that in the real experiment, the protons
are at rest with respect to the tabletop, and it is the electrons that are in motion, but in
\figref{brelativity}/1 we have the positive charges moving in
one direction and the negative ones moving
the other way. If we wanted to, we could construct a third frame of reference in which the
positive charges were at rest, which would be more like the frame of reference fixed to the
tabletop in the real demonstration. However, as we'll see shortly, frames 
\figref{brelativity}/1 and \figref{brelativity}/2 are designed so that they are
particularly easy to analyze. It's important to note that even though the two line charges
are moving in opposite directions, their currents don't cancel. A negative charge moving
to the left makes a current that goes to the right, so in frame \figref{brelativity}/1,
the total current is twice that contributed by either line charge.

Frame 1 is easy to analyze because the charge densities of the two line charges cancel out,
and the electric field experienced by the lone charge is therefore zero:
\begin{equation*}
                \vc{E}_1 = 0
\end{equation*}
In frame 1, any force experienced by the lone charge must therefore be attributed solely
to magnetism.

Frame 2 shows what we'd see if we were observing all this from a frame of reference moving
along with the lone charge.
Why don't the charge densities also cancel in this frame?
Here's where the relativity comes in. Relativity tells us that moving objects
appear contracted to an observer who is not moving along with them.
Both line charges are in motion in both frames of reference, but in frame 1, the
line charges were moving at equal speeds, so their contractions were equal, and their
charge densities canceled out. In frame 2, however, their speeds are unequal. The positive
charges are moving more slowly than in frame 1, so in frame 2 they are less contracted.
The negative charges are moving more quickly, so their contraction is greater now.
Since the charge densities don't cancel, there is an electric field in frame 2, which
points into the wire, attracting the lone charge. Furthermore, the attraction felt
by the lone charge must be purely electrical, since the lone charge is at rest in this
frame of reference, and magnetic effects occur only between moving charges and other
moving charges.\footnote{One could object that this is circular reasoning, since the
whole purpose of this argument is to prove from first principles that magnetic effects
follow from the theory of relativity. Could there be some extra interaction which occurs
between a moving charge and \emph{any} other charge, regardless of whether the other
charge is moving or not? We can argue, however, that such a theory would lack self-consistency,
since we have to define the electric field somehow, and the only way to define it is in terms
of $F/q$, where $F$ is the force on a test charge $q$ which is at rest. In other words, we'd
have to say that there was some extra contribution to the \emph{electric} field if the
charge making it was in motion. This would, however, violate Gauss' law, and Gauss' law
is amply supported by experiment, even when the sources of the electric field are moving.
It would also violate the time-reversal symmetry of the laws of physics.}

To summarize, frame 1 displays a purely magnetic attraction, while in frame 2 it is
purely electrical. 

Now we can calculate the force in frame 2, and equating it to the force in frame 1, we
can find out how much magnetic force occurs.
To keep the math simple, and to keep from assuming too much about your knowledge
of relativity, we're going to carry out this whole calculation in the approximation
where all the speeds are fairly small compared to the speed of light.\footnote{The
reader who wants to see the full relativistic treatment is referred to
E.M. Purcell, \emph{Electricity and Magnetism}, McGraw Hill, 1985, p. 174.} For instance, if
we find an expression such as $(v/c)^2+(v/c)^4$, we will assume that the fourth-order
term is negligible by comparison. This is known as a calculation ``to leading order
in $v/c$.'' In fact, I've already used the leading-order approximation twice
without saying so! The first time I used it implicitly was in figure \figref{brelativity},
where I assumed that the velocities of the two line charges were $u-v$ and $-u-v$.
Relativistic velocities don't just combine by simple addition and subtraction like
this, but this is an effect we can ignore in the present approximation. The second
sleight of hand occurred when I stated that we could equate the forces in the two
frames of reference. Force, like time and distance, is distorted relativistically
when we change from one frame of reference to another. Again, however, this is an effect
that we can ignore to the desired level of approximation.

Let $\pm\lambda$ be the charge per unit length of each line charge without relativistic
contraction, i.e., in the frame moving with that line charge.
Using the approximation $\gamma=(1-v^2/c^2)^{-1/2}\approx 1+v^2/2c^2$ for $v\ll c$, the
total charge per unit length in frame 2 is
\begin{align*}
        \lambda_{total,\ 2}        &\approx \lambda\left[1+\frac{(u-v)^2}{2c^2}\right]
                                        -\lambda\left[1+\frac{(-u-v)^2}{2c^2}\right]\\
                                &= \frac{-2\lambda uv}{c^2}\eqquad.
\end{align*}
Let $R$ be the distance from the line charge to the lone charge.
Applying Gauss' law to a cylinder of radius $R$ centered on the line charge,
we find that the magnitude of the electric field experienced by the lone charge
in frame 2 is
\begin{equation*}
        E        =        \frac{4k\lambda uv}{c^2R}\eqquad,
\end{equation*}
and the force acting on the lone charge $q$ is
\begin{equation*}
        F        =        \frac{4k\lambda quv}{c^2R}\eqquad.
\end{equation*}
In frame 1, the current is $I=2\lambda_1 u$ (see homework problem \ref{hw:linechargecurrent}),
which we can approximate
as $I=2\lambda u$, since the current, unlike $\lambda_{total,\ 2}$, doesn't
vanish completely without the relativistic effect.
The magnetic force on the lone charge $q$ due to the current $I$ is
\begin{equation*}
        F        =        \frac{2kI qv}{c^2R}\eqquad.
\end{equation*}\label{wireforce}

\startdqs

\begin{dq}
In the situation shown in figure \figref{brelativity}, is there a frame in which
the force $\vc{F}$ is a purely electric one, $\vc{F}_E$? Pure $\vc{F}_B$?\\
Is there a frame in which the electromagnetic field is a pure $\vc{E}$? Pure $\vc{B}$?\\
Is the charge density $\rho$ zero in both frames? One? Neither?\\
What about the current $I$ (or current density $\vc{j}$)?
\end{dq}

\begin{dq}
For the situation shown in figure \figref{brelativity}, draw a spacetime diagram
in the style demonstrated in sec.~\ref{sec:x-t-distortion}, p.~\pageref{sec:x-t-distortion},
showing the positive charges as black world-lines and the negative as red, in the
wire's rest frame. Use a ruler, and draw the spacing fairly accurately. Interpret this
in the frame of the lone charge.
\end{dq}


\begin{dq}
Resolve the following paradox concerning the argument given in this section.
We would expect that at any given time,
electrons in a solid would be associated with protons in a definite way.
For simplicity, let's imagine that the solid is made out of hydrogen (which
actually does become a metal under conditions of very high pressure).
A hydrogen atom consists of a single proton and a single electron.
Even if the electrons are moving and forming an electric current, we would
imagine that this would be like a game of musical chairs, with the protons
as chairs and the electrons as people. Each electron has a proton that is its
``friend,'' at least for the moment. This is the situation shown in figure
\subfigref{brelativity}{1}. How, then, can an observer in a different frame
see the electrons and protons as not being paired up, as in \subfigref{brelativity}{2}?
\end{dq}

<% end_sec() %>

<% begin_sec("The magnetic field") %>

<% begin_sec("Definition in terms of the force on a moving particle") %>

With electricity, it turned out to be useful to define an electric field
rather than always working in terms of electric forces. Likewise, we want
to define a magnetic field, $\vc{B}$. Let's look at the result of the preceding subsection
for insight. The equation 
\begin{equation*}
        F        =        \frac{2kI qv}{c^2R}
\end{equation*}
shows that when we put a moving charge
near other moving charges, there is an extra magnetic force on it, in addition to 
any electric forces that may exist. Equations for electric forces always have a factor
of $k$ in front --- the Coulomb constant $k$ is called 
the coupling constant\index{coupling constant} for
electric forces. Since magnetic effects are relativistic in origin, they end up
having a factor of $k/c^2$ instead of just $k$. In a world where the speed of light
was infinite, relativistic effects, including magnetism, would be absent, and the
coupling constant for magnetism would be zero. A cute feature of the metric system
is that we have $k/c^2=10^{-7}\ \zu{N}\cdot\zu{s}^2/\zu{C}^2$ exactly,
as a matter of definition.

<% marg(50) %>
<%
  fig(
    'vbf',
    %q{%
      The right-hand relationship between the velocity of a positively charged
              particle,
              the magnetic field through which it is moving, and the magnetic force on it.
    }
  )
%>

\spacebetweenfigs

<%
  fig(
    'tesla',
    %q{The unit of magnetic field, the tesla, is named after Serbian-American inventor Nikola Tesla.}
  )
%>
<% end_marg %>

Naively, we could try to work by analogy with the electric field, and define
the magnetic field as the magnetic force per unit charge. However, if we think
of the lone charge in our example as the test charge, we'll find that this
approach fails, because the force depends not just on the test particle's charge,
but on its velocity, $v$, as well. Although we only carried out calculations for
the case where the particle was moving parallel to the wire, in general this velocity
is a vector, \vc{v}, in three dimensions. We can also anticipate that the magnetic
field will be a vector. The electric and gravitational fields are vectors, and we
expect intuitively based on our experience with magnetic compasses that a magnetic field
has a particular direction in space. Furthermore, reversing the current $I$ in our
example would have reversed the force, which would only make sense if the magnetic
field had a direction in space that could be reversed. Summarizing, we think there
must be a magnetic field vector \vc{B}, and the force on a test particle moving
through a magnetic field is proportional both to the \vc{B} vector
and to the particle's own \vc{v} vector. In other words, the magnetic force vector \vc{F} is
found by some sort of vector multiplication of the vectors \vc{v} and \vc{B}.
As proved on page \pageref{misc:uniquexproof}, however, there is only one physically
useful way of defining such a multiplication, which is the cross product.

\begin{important}
We
therefore define the magnetic field vector, \vc{B}, as the vector that determines
the force on a charged particle according to the following rule:
\begin{equation*}
        \vc{F} = q\vc{v}\times\vc{B} \qquad \text{[definition of the magnetic field]}
\end{equation*}
\end{important}

From this definition, we see that the magnetic field's units are
$\zu{N}\cdot\zu{s}/\zu{C}\cdot\zu{m}$, which are usually abbreviated as
teslas, $1\ \zu{T}=1\ \zu{N}\cdot\zu{s}/\zu{C}\cdot\zu{m}$.\index{magnetic field!defined}
\index{tesla (unit)} The definition implies a right-hand-rule relationship
among the vectors, figure \figref{vbf}, if the charge $q$ is positive, and
the opposite handedness if it is negative.

This is not just a definition but a bold prediction! Is it really true
that for any point in space, we can always find a vector \vc{B} that successfully
predicts the force on any passing particle, regardless of its charge and 
velocity vector? Yes --- it's not obvious that it can be done, but
experiments verify that it can. How? Well for example, the cross product of parallel vectors
is zero, so we can try particles moving in various directions, and hunt for the
direction that produces zero force; the \vc{B} vector lies along that line, in
either the same direction the particle was moving, or the opposite one.
We can then go back to our data from one of the other cases, where the
force was nonzero, and use it to choose between these two directions and find
the magnitude of the \vc{B} vector. We could then verify that this vector
gave correct force predictions in a variety of other cases.

Even with this empirical reassurance, the meaning of this equation is
not intuitively transparent,
nor is it practical in most cases to measure a magnetic field this way. For these
reasons, let's look at an alternative method of defining the magnetic field which,
although not as fundamental or mathematically simple, may be more appealing.

        
<% end_sec() %>

<% begin_sec("Definition in terms of the torque on a dipole") %>

A compass needle in a magnetic field experiences a torque which tends to align
it with the field. This is just like the behavior of an electric dipole in
an electric field, so we consider the compass needle to be a 
\emph{magnetic dipole}.\index{dipole!magnetic}\index{magnetic dipole}
In subsection \ref{subsec:efielddipoledef} on
 page \pageref{subsec:efielddipoledef},
 we gave an alternative definition of the
electric field in terms of the torque on an electric dipole.

<% marg(150) %>
<%
  fig(
    'current-loop-dipole',
    %q{%
      A standard dipole made from a square loop of wire shorting
              across a battery. It acts very much like a bar magnet, but its
              strength is more easily quantified.
    }
  )
%>

\spacebetweenfigs
%

<%
  fig(
    'current-loop-aligns',
    %q{%
      A dipole tends to align itself to the surrounding magnetic
              field.
    }
  )
%>

\spacebetweenfigs
%

<%
  fig(
    'arearh',
    %q{The \vc{m} and \vc{A} vectors.}
  )
%>
<% end_marg %>

To define the strength of a magnetic field, however, we need
some way of defining the strength of a test dipole, i.e., we
need a definition of the magnetic dipole moment. We could
use an iron permanent magnet constructed according to
certain specifications, but such an object is really an
extremely complex system consisting of many iron atoms, only
some of which are aligned with each other. A more fundamental standard
dipole is a square current loop. This could be little
resistive circuit consisting of a square of wire shorting across a battery, \figref{current-loop-dipole}.

Applying $\vc{F}=\vc{v}\times\vc{B}$, we
 find that such a loop, when placed in a magnetic
field, \figref{current-loop-aligns}, 
experiences a torque that tends to align plane so
that its interior ``face'' points in a certain direction.
Since the loop is symmetric, it doesn't care if we rotate it
like a wheel without changing the plane in which it lies. It
is this preferred facing direction that we will end up
using as our alternative definition of the magnetic field.

If the loop is out of alignment with the
field, the torque on it is proportional to the amount of
current, and also to the interior area of the loop. The
proportionality to current makes sense, since magnetic
forces are interactions between moving charges, and current
is a measure of the motion of charge. The proportionality to
the loop's area is also not hard to understand, because
increasing the length of the sides of the square increases
both the amount of charge contained in this circular
``river'' and the amount of leverage supplied for making
torque. Two separate physical reasons for a proportionality
to length result in an overall proportionality to length
squared, which is the same as the area of the loop. For
these reasons, we define the magnetic dipole moment of a
square current loop as
\begin{equation*}
                \vc{m}         =    I\vc{A}\eqquad,         
\end{equation*}
where the direction of the vectors is defined as shown in figure \figref{arearh}.
%

<% marg(100) %>
<%
  fig(
    'squaretorque',
    %q{%
      The torque on a current loop in a magnetic field.  
              The current comes out of the page, goes across, goes
              back into the page, and then back across
              the other way in the hidden side of the loop. 
    }
  )
%>

\spacebetweenfigs
%

<%
  fig(
    'inout',
    %q{%
      A vector coming out of the page is shown with the tip of an arrowhead.
              A vector going into the page is represented using the tailfeathers of the arrow.
    }
  )
%>

\spacebetweenfigs
%

<%
  fig(
    'adddipoles',
    %q{Dipole vectors can be added.}
  )
%>
<% end_marg %>

We can now give an alternative definition of the \index{magnetic field!defined}magnetic
field:

\begin{important}
The magnetic field vector, \vc{B}, at any location in space is
defined by observing the torque exerted on a magnetic test
dipole $\vc{m}_{t}$ consisting of a square current loop. The
field's magnitude is
\begin{equation*}
        |\vc{B}| = \frac{\tau}{|\vc{m}_{t}|\sin\theta}\eqquad,
\end{equation*}
where $\theta$ is the angle between the dipole vector and the field.
This is equivalent to the vector cross product $\btau=\vc{m}_t\times\vc{B}$.
\end{important}

Let's show that this is consistent with the previous definition, using the
geometry shown in figure \figref{squaretorque}. The velocity vectors that point in
and out of the page are shown using the convention defined
in figure \figref{inout}.
Let the mobile charge carriers in the wire have linear
density $\lambda$, and
let the sides of the loop have
length $h$, so that we have $I=\lambda v$, and
$m=h^2\lambda v$. The only nonvanishing torque comes from the forces on the
left and right sides. The currents in these sides are perpendicular to the field,
so the magnitude of the cross product $\vc{F}=q\vc{v}\times\vc{B}$ is simply
$|\vc{F}|=qvB$. The torque supplied by each of these forces
is $\vc{r}\times\vc{F}$, where the lever arm $\vc{r}$ has length $h/2$,
and makes an angle $\theta$ with respect to the force vector. The magnitude of the total torque
acting on the loop is therefore
\begin{align*}
  |\btau|        &=2\frac{h}{2}|\vc{F}|\sin\theta \\
                          &=h\:qvB\:\sin\theta\eqquad,\\
 \intertext{and substituting $q=\lambda h$ and $v=m/h^2\lambda$, we have}
          |\btau|        &= h\:\lambda h\:\frac{m}{h^2\lambda} B\sin\theta \\
                          &=m B\sin\theta\eqquad,\\
\end{align*}
which is consistent with the second definition of the field.

It undoubtedly seems artificial to you that we have discussed dipoles only in
the form of a square loop of current. A permanent magnet, for example, is made
out of atomic dipoles, and atoms aren't square! However, it turns out that the
shape doesn't matter. To see why this is so, consider the additive property of
areas and dipole moments, shown in figure \figref{adddipoles}. Each of the square
dipoles has a dipole moment that points out of the page. When they are placed
side by side, the currents in the adjoining sides cancel out, so they are equivalent
to a single rectangular loop with twice the area. We can break down
any irregular shape into little squares, as shown in figure \figref{irregularloop},
so the dipole moment of any planar current loop can be calculated based on its area,
regardless of its shape.

<% marg(80) %>
<%
  fig(
    'irregularloop',
    %q{An irregular loop can be broken up into little squares.}
  )
%>

\spacebetweenfigs

<% fig(
        'iron-filings-around-magnet',
        %q{The magnetic field pattern around a bar magnet is created by the superposition of
        the dipole fields of the individual iron atoms. Roughly speaking, it looks like the
        field of one big dipole, especially farther away from the magnet. Closer in, however,
        you can see a hint of the magnet's rectangular shape. The picture was made by placing iron filings
        on a piece of paper, and then bringing a magnet up underneath.}
   )
%>
<% end_marg %>

\begin{eg}{The magnetic dipole moment of an atom}
Let's make an order-of-magnitude estimate of the magnetic dipole moment of an atom.
A hydrogen atom is about $10^{-10}$ m in diameter, and the electron moves at speeds
of about $10^{-2} c$. We don't know the shape of the orbit, and indeed it turns out that
according to the principles of quantum mechanics, the electron doesn't even have a well-defined
orbit, but if we're brave, we can still estimate the dipole moment using the
cross-sectional area of the atom, which will be on the order of 
$(10^{-10}\ \zu{m})^2=10^{-20}\ \zu{m}^2$.
The electron is a single particle, not a steady current, but again we throw caution to
the winds, and estimate the current it creates as $e/\Delta t$,
where $\Delta t$, the time for one orbit, can be estimated by dividing the
size of the atom by the electron's velocity. (This is only a rough estimate,
and we don't know the shape of the orbit, so it would be silly, for instance,
to bother with multiplying the diameter by $\pi$ based on our intuitive visualization
of the electron as moving around the circumference of a circle.)
The result for the dipole moment is $m\sim10^{-23}\ \zu{A}\unitdot\zu{m}^2$. 

Should we
be impressed with how small this dipole moment is, or with how big it is, considering
that it's being made by a single atom? 
Very large or very small numbers are never very interesting by themselves. To get a
feeling for what they mean, we need to compare them to something else. An interesting
comparison here is to think in terms of the total number of atoms in a typical object,
which might be on the order of $10^{26}$ (Avogadro's number). Suppose we had this
many atoms, with their moments all aligned. The total dipole moment would be on the
order of $10^3\ \zu{A}\unitdot\zu{m}^2$, which is a pretty big number. To get
a dipole moment this strong using human-scale devices,
we'd have to send a thousand amps of current through a
one-square meter loop of wire! The insight to be gained here is that, even in
a permanent magnet, we must not have all the atoms perfectly aligned, because that
would cause more spectacular magnetic effects than we really observe. Apparently, nearly
all the atoms in such a magnet are oriented randomly, and do not contribute to the
magnet's dipole moment.
\end{eg}

\startdqs
\begin{dq}\label{dq:relativity-fields}
The physical situation shown in figure \figref{brelativity} on page \pageref{fig:brelativity}
was analyzed entirely in terms of forces. Now let's go back and think about it in terms of fields.
The charge by itself up above the wire is like a test charge, being used to determine the magnetic
and electric fields created by the wire. In figures \figref{brelativity}/1 and
\figref{brelativity}/2, are there fields that are purely electric or purely magnetic? Are there
fields that are a mixture of $\vc{E}$ and $\vc{B}$? How does this compare with the forces?
\end{dq}

\begin{dq}
Continuing the analysis begun in discussion question \ref{dq:relativity-fields}, can we come up
with a scenario involving some charged particles such that the fields are purely magnetic
in one frame of reference but a mixture of $\vc{E}$ and $\vc{B}$ in another frame?
How about an example where the fields are purely electric in one frame, but mixed in
another? Or an example where the fields are purely electric in one frame, but purely
magnetic in another?
\end{dq}

<% end_sec() %>

<% end_sec() %>

<% begin_sec("Some applications") %>

<% marg(0) %>
<%
  fig(
    'battery-wire-magnet',
    %q{%
      Example \ref{eg:battery-wire-magnet}.
    }
  )
%>
<% end_marg %>

\begin{eg}{Magnetic levitation}\label{eg:battery-wire-magnet}
      In figure \figref{battery-wire-magnet}, a small, disk-shaped permanent magnet is stuck on the side of a
      battery, and a wire is clasped loosely around the battery, shorting it.
      A large current flows through the wire. The electrons moving through the
      wire feel a force from the magnetic field made by the permanent magnet,
      and this force levitates the wire.

      From the photo, it's possible to find the direction of the magnetic field made by the permanent magnet.
      The electrons in the copper wire are negatively charged, so they flow from the negative (flat) terminal
      of the battery to the positive terminal (the one with the bump, in front). As the electrons pass by the
      permanent magnet, we can imagine that they would experience a field either toward the magnet, or away from
      it, depending on which way the magnet was flipped when it was stuck onto the battery.
      By the right-hand rule (figure \figref{vbf} on page \pageref{fig:vbf}), the field must be toward the battery.
\end{eg}

\begin{eg}{Nervous-system effects during an MRI scan}\index{NMR (nuclear magnetic resonance)}\index{MRI (magnetic resonance imaging)|see {NMR}}
During an MRI scan of the head, the patient's nervous system
is exposed to intense magnetic fields, and there are ions moving
around in the nerves. The resulting forces on the ions can cause
symptoms such as vertigo.
\end{eg}

\begin{eg}{A circular orbit}\label{eg:circular-orbit}\index{circular orbit in a magnetic field}
The magnetic force is always perpendicular to the motion of the particle,
so it can never do any work, and a charged particle moving through a magnetic field
does not experience any change in its kinetic energy: its velocity vector
can change its direction, but not its magnitude. If the velocity vector is
initially perpendicular to the field, then the curve of its motion will remain
in the plane perpendicular to the field, so the magnitude of the magnetic force
on it will stay the same. When an object experiences a force with constant magnitude,
which is always perpendicular to the direction of its motion, the result is that it
travels in a circle.

Figure \figref{circular-orbit} shows a beam of electrons in a spherical vacuum tube. In the top photo, the
beam is emitted near the right side of the tube, and travels straight up. In the bottom photo, a magnetic
field has been imposed by an electromagnet surrounding the vacuum tube; the ammeter on the right shows that the
current through the electromagnet is now nonzero. We observe that the beam is bent into a circle.
\end{eg}

<% marg(200) %>
<%
  fig(
    'circular-orbit',
    %q{Magnetic forces cause a beam of electrons to move in a circle.}
  )
%>

\spacebetweenfigs

<%
  fig(
    'break-bar-magnet',
    %q{You can't isolate the poles of a magnet by breaking it in half.}
  )
%>

\spacebetweenfigs

<%
  fig(
    'breakbaratoms',
    %q{A magnetic dipole is made out of other dipoles, not out of monopoles.}
  )
%>
<% end_marg %>

        
<% self_check('circularorbitbdirection',<<-'SELF_CHECK'
Infer the direction of the magnetic field.
Don't forget that the beam is made of
        electrons, which are negatively charged!
  SELF_CHECK
  ) %>

\noindent Homework problem \ref{hw:cyclotron} is a quantitative analysis of circular orbits.

\begin{eg}{A velocity filter}\index{velocity filter}
Suppose you see the electron beam in figure \figref{circular-orbit}, and you
want to determine how fast the electrons are going.
You certainly can't do it with a stopwatch! Physicists may also encounter situations
where they have a beam of unknown charged particles, and they don't even know their
charges. This happened, for instance, when alpha and beta radiation were discovered.
One solution to this problem relies on the fact that the force experienced by a charged
particle in an electric field, $\vc{F}_E=q\vc{E}$, is independent of its velocity,
but the force due to a magnetic field, $\vc{F}_B=q\vc{v}\times\vc{B}$, isn't. One
can send a beam of charged particles through a space containing both an
 electric and a magnetic field, setting up the fields so that the two forces
 will cancel out perfectly for a certain velocity. Note that since both forces
 are proportional to the charge of the particles, the cancellation is independent
 of charge.
 Such a \emph{velocity filter}\index{velocity filter} can be used either to determine the
 velocity of an unknown beam or particles, or to select from a beam of particles only
 those having velocities within a certain desired range.
 Homework problem \ref{hw:vfilter} is an analysis of this application.
\end{eg}

<% end_sec() %>

<% begin_sec("No magnetic monopoles") %>

If you could play with a handful of electric dipoles and a
handful of bar magnets, they would appear very similar. For
instance, a pair of bar magnets wants to align themselves
head-to-tail, and a pair of electric dipoles does the same
thing. (It is unfortunately not that easy to make a
permanent electric dipole that can be handled like this,
since the charge tends to leak.)

You would eventually notice an important difference between
the two types of objects, however. The electric dipoles can
be broken apart to form isolated positive charges and
negative charges. The two-ended device can be broken into
parts that are not two-ended. But if you break a bar magnet
in half, \figref{break-bar-magnet}, you will find that you have simply made two
smaller two-ended objects.  

The reason for this behavior is not hard to divine from our
microscopic picture of permanent iron magnets. An electric
dipole has extra positive ``stuff'' concentrated in one end
and extra negative in the other. The bar magnet, on the
other hand, gets its magnetic properties not from an
imbalance of magnetic ``stuff'' at the two ends but from the
orientation of the rotation of its electrons. One end is the
one from which we could look down the axis and see the
electrons rotating clockwise, and the other is the one from
which they would appear to go counterclockwise. There is no
difference between the ``stuff'' in one end of the
magnet and the other, \figref{breakbaratoms}.

Nobody has ever succeeded in isolating a single magnetic
pole. In technical language, we say that 
magnetic \emph{monopoles}\index{monopoles!magnetic}\index{magnetic monopoles}
not seem to exist. Electric monopoles \emph{do} exist
--- that's what charges are.

Electric and magnetic forces seem similar in many ways. Both
act at a distance, both can be either attractive or
repulsive, and both are intimately related to the property
of matter called charge. (Recall that magnetism is an
interaction between moving charges.) Physicists's aesthetic
senses have been offended for a long time because this
seeming symmetry is broken by the existence of electric
monopoles and the absence of magnetic ones. Perhaps some
exotic form of matter exists, composed of particles that are
magnetic monopoles. If such particles could be found in
cosmic rays or moon rocks, it would be evidence that the
apparent asymmetry was only an asymmetry in the composition
of the universe, not in the laws of physics. For these
admittedly subjective reasons, there have been several
searches for magnetic monopoles. Experiments have been
performed, with negative results, to look for magnetic
monopoles embedded in ordinary matter. Soviet physicists in
the 1960's made exciting claims that they had created and
detected magnetic monopoles in particle accelerators, but
there was no success in attempts to reproduce the results
there or at other accelerators. The most recent search for
magnetic monopoles, done by reanalyzing data from the search
for the top quark at Fermilab, turned up no candidates,
which shows that either monopoles don't exist in nature or
they are extremely massive and thus hard to create in accelerators.

<% marg(0) %>
<%
  fig(
    'ebdipoles',
    %q{Magnetic fields have no sources or sinks.}
  )
%>
<% end_marg %>

The nonexistence of magnetic monopoles means that unlike an
electric field, a magnetic one, can never have
sources or sinks. The magnetic field vectors lead in paths
that loop back on themselves, without ever converging or
diverging at a point, as in the fields shown in figure \figref{ebdipoles}.
Gauss' law for magnetism is therefore much simpler than Gauss'
law for electric fields:
\begin{equation*}
        \Phi_B = \sum \vc{B}_j\cdot\vc{A}_j = 0
\end{equation*}
The magnetic flux through any closed surface is zero.

        
<% self_check('bgauss',<<-'SELF_CHECK'
Draw a Gaussian surface on the electric dipole field
        of figure \figref{ebdipoles}
        that has nonzero electric flux through it, and then draw a similar
        surface on the magnetic field pattern. What happens?
  SELF_CHECK
  ) %>

\begin{eg}{The field of a wire}\label{eg:bwire}
\egquestion
On page \pageref{wireforce}, we showed that a long, straight wire
carrying current $I$ exerts a magnetic force
\begin{equation*}
         F        =        \frac{2 kIqv}{ c^2 R}
\end{equation*}
on a particle with charge $q$ moving parallel to the wire
with velocity $v$. What, then, is the magnetic field of the wire?

\eganswer
Comparing the equation above to the first definition of the magnetic
field, $\vc{F}=\vc{v}\times\vc{B}$, it appears that the magnetic field
is one that falls off like $1/ R$, where $R$ is the distance
from the wire. However, it's not so easy to determine the direction of the
field vector. There are two other axes along which the particle could have
been moving, and the brute-force method would be to carry out relativistic
calculations for these cases as well. Although this would probably be enough
information to determine the field, we don't want to do that much work.

<% marg(60) %>
<%
  fig(
    'bwire',
    %q{Example \ref{eg:bwire}.}
  )
%>
<% end_marg %>

Instead, let's consider what the possibilities are. The field can't be
parallel to the wire, because a cross product vanishes when the two vectors
are parallel, and yet we know from the case we analyzed that the force doesn't
vanish when the particle is moving parallel to the wire. The other two 
possibilities that are consistent with the symmetry of the problem
are shown in figure \figref{bwire}. One is like a bottle brush,
and the other is like a spool of thread. The bottle brush pattern, however,
violates Gauss' law for magnetism. If we made a cylindrical Gaussian surface
with its axis coinciding with the wire, the flux through it would \emph{not} be
zero. We therefore conclude that the spool-of-thread pattern is the correct
one.\footnote{Strictly speaking, there is a hole in this logic, since
I've only ruled out a field that is purely along one of these three
perpendicular directions. What if it has components along more than one
of them? A little more work is required to eliminate these mixed possibilities.
For example, we can rule out a field with a nonzero component parallel
to the wire based on the following symmetry argument. Suppose a charged particle
is moving in the plane of the page directly toward the wire.
 If the field had a component parallel to the wire, then the particle would
feel a force into or out of the page, but such a force is impossible based
on symmetry, since the whole arrangement is symmetric with respect to
mirror-reflection across the plane of the page.}
 Since the particle in our example was moving perpendicular to the field,
we have $| F|=|q|| v|| B|$, so
\begin{align*}
        | B|        &= \frac{| F|}{|q| | v|} \\
                                &= \frac{2 kI}{ c^2 R}\\
\end{align*}
\end{eg}

<% end_sec() %>

<% begin_sec("Symmetry and handedness",nil,'em-parity') %>
\index{symmetry}\index{handedness}

Imagine that you establish
        radio contact with an alien on another planet. Neither of
        you even knows where the other one's planet is, and you
        aren't able to establish any landmarks that you both
        recognize. You manage to learn quite a bit of each other's
        languages, but you're stumped when you try to establish the
        definitions of left and right (or, equivalently, clockwise
        and counterclockwise). Is there any way to do it?

<%
  fig(
    'bsymmetry',
    %q{Left-handed and right-handed definitions.},
    {
      'width'=>'wide'
    }
  )
%>

If there was any way to do it without reference to external
landmarks, then it would imply that the laws of physics
themselves were asymmetric, which would be strange. Why
should they distinguish left from right? The gravitational
field pattern surrounding a star or planet looks the same in
a mirror, and the same goes for electric fields. However,
the magnetic field patterns shown in figure \figref{bwire}
seems to violate this
principle. Could you use these patterns
to explain left and right to the alien? No.
If you look back at the definition of the magnetic
field, it also contains a reference to
handedness: the direction of the vector cross product. The aliens might
have reversed their definition of the magnetic field, in
which case their drawings of field patterns would look like
mirror images of ours, as in the left panel of figure \figref{bsymmetry}.

Until the middle of the twentieth century, physicists
assumed that any reasonable set of physical laws would have
to have this kind of symmetry between left and right. An
asymmetry would be grotesque. Whatever their aesthetic
feelings, they had to change their opinions about reality
when experiments by C.S.~Wu et al.~showed that the \index{weak nuclear
force}weak \index{nuclear forces}nuclear force
violates right-left symmetry! It is still a mystery why
right-left symmetry is observed so scrupulously in general,
but is violated by one particular type of physical process.

<% marg(100) %>
<% fig(
     '../../../share/mechanics/figs/swan-lake-symmetry',
     %q{In this scene from Swan Lake, the choreography has a symmetry with respect to left and right.}
   )
%>

\spacebetweenfigs

<% fig(
     '../../../share/mechanics/figs/c-s-wu-with-beamline',
     %q{C.S.~Wu}
   )
%>
<% end_marg %>

\enlargethispage{\baselineskip}

 % 
 % ----------------------------------------------------------------------------- 
 % 

<% end_sec() %>

<% end_sec() %>

<% begin_sec("Magnetic fields by superposition",4) %>

<% begin_sec("Superposition of straight wires",nil,'superposwires') %>

In chapter \ref{ch:efield}, one of the most important goals was to learn
how to calculate the electric field for a given charge distribution.
The corresponding problem for magnetism would be to calculate the
magnetic field arising from a given set of currents. So far, however,
we only know how to calculate the magnetic field of a long, straight
wire,
\begin{equation*}
        B        = \frac{2kI}{c^2R}\eqquad,
\end{equation*}
with the geometry shown in figure \figref{bwireb}. Whereas a
charge distribution can be broken down into individual point charges,
most currents cannot be broken down into a set of straight-line currents.
Nevertheless, let's see what we can do with the tools that we have.

<% marg(70) %>
<%
  fig(
    'bwireb',
    %q{The magnetic field of a long, straight wire.}
  )
%>

\spacebetweenfigs
%

<%
  fig(
    'gfi',
    %q{A ground fault interrupter.}
  )
%>

\spacebetweenfigs
%

<%
  fig(
    'twowires',
    %q{Example \ref{eg:twowires}.}
  )
%>
<% end_marg %>

\begin{eg}{A ground fault interrupter}\index{ground fault interrupter}
Electric current in your home is supposed to flow out of one side of the outlet,
through an appliance, and back into the wall through the other side of the outlet.
If that's not what happens, then we have a problem --- the current must be finding
its way to ground through some other path, perhaps through someone's body. 
If you have outlets in your home that have ``test'' and ``reset'' buttons on them,
they have a safety device built into them that is meant to protect you in this
situation. The ground fault 
interrupter\index{ground fault interrupter}\index{GFI} (GFI)
shown in figure \figref{gfi}, routes the outgoing and
returning currents through two wires that lie very close together.
The clockwise and counterclockwise fields created by the two wires combine
by vector addition, and normally cancel out almost exactly. However, if current
is not coming back through the circuit, a magnetic field is produced. The
doughnut-shaped collar detects this field (using an effect called induction, to
be discussed in section \ref{sec:induction}), and sends a signal to a logic chip,
which breaks the circuit within about 25 milliseconds.
\end{eg}

\begin{eg}{An example with vector addition}\label{eg:twowires}
\egquestion
Two long, straight wires each carry current $I$ parallel to the $y$ axis,
but in opposite directions. They are separated by a gap $2 h$ in the
$x$ direction. Find the magnitude and direction of the magnetic field at a point
located at a height $z$ above the plane of the wires, directly above the center line.

\eganswer
The magnetic fields contributed by the two wires add like vectors, which means
we can add their $x$ and $z$ components. The $x$ components cancel by
symmetry.
The magnitudes of the individual fields are equal, 
\begin{equation*}
         B_1 =  B_2 = \frac{2 kI}{ c^2 R}\eqquad,\\
\end{equation*}
so the total field in the $z$ direction is
\begin{equation*}
         B_{z} = 2\frac{2 kI}{ c^2 R}\zu{sin}\:\theta\eqquad,\\
\end{equation*}
where $\theta$ is the angle the field vectors make above the $x$ axis.
The sine of this angle equals $h/ R$, so
\begin{equation*}
         B_{z} =  \frac{4 kIh}{ c^2 R^2} .\\
\end{equation*}
(Putting this explicitly in terms of $z$ gives the less attractive
form $B_{z}=4 kIh/ c^2( h^2+ z^2)$.)

At large distances from the wires, the individual fields are mostly in the $\pm x$
direction, so most of their strength cancels out.
It's not surprising that the fields tend to cancel, since the currents are
in opposite directions. What's more interesting is that not only is the field
weaker than the field of one wire, it also falls off as $R^{-2}$ rather than
$R^{-1}$. If the wires were right on top of each other, their currents
would cancel each other out, and the field would be zero.
From far away, the wires appear to be almost on top of each other, which is what
leads to the more drastic  $R^{-2}$ dependence on distance.
\end{eg}

        
<% self_check('betweenwires',<<-'SELF_CHECK'
In example \ref{eg:twowires}, what 
        is the field right between the wires,
        at $z=0$, and how does this simpler result follow from vector addition?
  SELF_CHECK
  ) %>

        
<% begin_sec("An alarming infinity") %>

An interesting aspect of the $R^{-2}$ dependence of the field in
example \ref{eg:twowires} is the energy of the field. We've already established
on p.~\pageref{b-field-energy-propto} that the energy density of the magnetic field must
be proportional to the square of the field strength, $B^2$, the same as for
the gravitational and electric fields. Suppose we try to calculate the energy
per unit length stored in the field of a \emph{single} wire. We haven't yet
found the proportionality factor that goes in front of the $B^2$, but that doesn't
matter, because the energy per unit length turns out to be infinite! To see this,
we can construct concentric cylindrical shells of length $L$, with each shell
extending from $R$ to $R+\der R$. The volume of the shell equals its circumference
times its thickness times its length, $\der v=(2\pi R)(\der R)(L)=2\pi L\der R$.
For a single wire, we have $B\sim R^{-1}$, so the energy density is proportional
to $R^{-2}$, and the energy contained in each shell varies as
$R^{-2}\der v\sim R^{-1}\der r$. Integrating this gives a logarithm, and as we let $R$
approach infinity, we get the logarithm of infinity, which is infinite.

Taken at face value, this result would imply that electrical currents could never
exist, since establishing one would require an infinite amount of energy per unit
length! In reality, however, we would be dealing with an electric \emph{circuit},
which would be more like the two wires of example \ref{eg:twowires}: current
goes out one wire, but comes back through the other. Since the field really
falls off as $R^{-2}$, we have an energy density that varies as $R^{-4}$, which
does \emph{not} give infinity when integrated out to infinity. (There is still
an infinity at $R=0$, but this doesn't occur for a real wire, which has a finite
diameter.)

Still, one might worry about the physical implications of the single-wire
result. For instance, suppose we turn on an electron gun, like the one
in a TV tube. It takes perhaps a microsecond for the beam to progress across
the tube. After it hits the other side of the tube, a return current is established,
but at least for the first microsecond, we have only a single current, not two.
Do we have infinite energy in the resulting magnetic field? No. It takes time
for electric and magnetic field disturbances to travel outward through space,
so during that microsecond, the field spreads only to some finite value of $R$,
not $R=\infty$.

<% marg(-0) %>

<%
  fig(
    'sheet',
    %q{A sheet of charge.}
  )
%>
<% end_marg %>

This reminds us of an important fact about our study of magnetism so far: we have only
been considering situations where the currents and magnetic fields are constant over
time. The equation $B        = 2kI/c^2R$ was derived
under this assumption. This equation is only valid if we assume the current has
been established and flowing steadily for a long time, and if we are talking about the
field at a point in space at which the field has been established for a long time. 
The generalization to time-varying fields is nontrivial, and qualitatively new
effects will crop up. 
We have already seen one example of this on page \pageref{inductorinduction},
where we inferred that an inductor's time-varying magnetic field creates
an electric field --- an electric field which is not created by any charges
anywhere. Effects like these will be discussed in section \ref{sec:induction}

<% end_sec() %>

<% begin_sec("A sheet of current") %>
\label{sheetofcurrent}
        There is a saying that in computer science, there are only three nice numbers:
        zero, one, and however many you please. In other words, computer software shouldn't
        have arbitrary limitations like a maximum of 16 open files, or 256 e-mail messages
        per mailbox. When superposing the fields of long, straight wires, the really
        interesting cases are one wire, two wires, and infinitely many wires. With an infinite
        number of wires, each carrying an infinitesimal current, we can create sheets
        of current, as in figure \figref{sheet}. Such a sheet has a certain amount of
        current per unit length, which we notate $\eta$ (Greek
        letter eta).
        The setup is similar to example \ref{eg:twowires}, except that all the currents
        are in the same direction, and instead of adding up two fields, we add up an
        infinite number of them by doing an integral. For the $y$ component, we have
        \begin{align*}
                B_y        &= \int \frac{2k\der I}{c^2R}\cos\theta \\
                        &= \int_{-a}^{b} \frac{2k\eta\der y}{c^2R}\cos\theta \\
                        &= \frac{2k\eta}{c^2} \int_{-a}^{b} \frac{\cos\theta}{R}\der y \\
                        &= \frac{2k\eta}{c^2} \int_{-a}^{b}\: \frac{z\der y}{y^2+z^2} \\
                        &= \frac{2k\eta}{c^2} \left(\tan^{-1}\frac{b}{z}-\tan^{-1}\frac{-a}{z}\right) \\
                        &= \frac{2k\eta\gamma}{c^2}\eqquad,
        \end{align*}
        where in the last step
        we have used the identity $\tan^{-1}(-x)=-\tan^{-1}x$, combined with the relation
        $\tan^{-1}b/z+\tan^{-1}a/z=\gamma$, which can be verified with a little geometry
        and trigonometry.
        The calculation of $B_z$ is left as an exercise (problem \ref{hw:sheetz}).
         More interesting is what happens underneath the sheet: by the
        right-hand rule, all the currents make rightward contributions to the field there,
        so $B_y$ abruptly reverses itself as we pass through the sheet.

<% marg(0) %>
<%
  fig(
    'sheeteb',
    %q{A sheet of charge and a sheet of current.}
  )
%>
\label{fig:ebsheet}

<% end_marg %>

Close to the sheet, the angle $\gamma$ approaches $\pi$, so we have
\begin{equation*}
        B_y = \frac{2\pi k\eta}{c^2}\eqquad.
\end{equation*}
Figure \figref{sheeteb} shows the similarity between this result
and the result for a sheet of charge. In one case the sources are
charges and the field is electric; in the other case we have currents
and magnetic fields. In both cases we find that the field
changes suddenly when we pass through a sheet of sources, and the amount
of this change doesn't depend on the size of the sheet. It was this type
of reasoning that eventually led us to Gauss' law in the case of electricity,
and in section \ref{sec:ampere} we will see that a similar approach can be
used with magnetism. The difference is that, whereas Gauss' law involves the
flux, a measure of how much the field \emph{spreads out}, the corresponding law
for magnetism will measure how much the field \emph{curls}.

        Is it just dumb luck that the magnetic-field case came out so similar to
        the electric field case? Not at all. We've already seen that what one observer
        perceives as an electric field, another observer may perceive as a magnetic field.
        An observer flying along above a charged sheet will say that the charges are
        in motion, and will therefore say that it is both a sheet of current and a sheet
        of charge. Instead of a pure electric field, this observer will experience a
        combination of an electric field and a magnetic one. (We could also construct
        an example like the one in figure \figref{brelativity} on page
        \pageref{fig:brelativity}, in which the field was purely magnetic.)
 %Examples with long, straight wires

<% end_sec() %>

<% end_sec() %>

<% begin_sec("Energy in the magnetic field") %>
\label{benergy}\index{energy density!of magnetic field}\index{magnetic field!energy density of}
        In section \ref{sec:fieldenergy}, I've already argued that the energy density
        of the magnetic field must be proportional to $|\vc{B}|^2$, which we can write
        as $B^2$ for convenience. To pin down the constant of proportionality, 
        we now need to do something like the argument on page \pageref{sec:fieldenergy}:
        find one example where we can calculate the mechanical work done by the magnetic
        field, and equate that to the amount of energy lost by the field itself.
        The easiest example is two parallel sheets of charge, with their currents
        in opposite directions. Homework problem \ref{hw:bwork} is
        such a calculation, which gives the result
        \begin{equation*}
                \der U_m        =                 \frac{c^2}{8\pi k}B^2 \der v\eqquad.
        \end{equation*}
 %B energy

<% end_sec() %>

<% begin_sec('Superposition of dipoles',nil,'superposdip') %>

To understand this subsection, you'll have to have studied section
\ref{subsec:iterated-int}, on iterated integrals.

<% begin_sec("The distant field of a dipole, in its midplane") %>

Most current
distributions cannot be broken down into long, straight wires, and
subsection \ref{subsec:superposwires} has exhausted most of the interesting
cases we can handle in this way.  A much more
useful building block is a square current loop. We have already seen how
the dipole moment of an irregular current loop can be found by breaking the
loop down into square dipoles (figure \figref{irregularloop} on page
\pageref{fig:irregularloop}), because the currents in adjoining squares cancel
out on their shared edges. Likewise, as shown in figure \figref{irregularloopb},
if we could find the magnetic field of
a square dipole, then we could find the field of any planar loop of current
by adding the contributions to the field from all the squares.

<% marg(40) %>
<%
  fig(
    'irregularloopb',
    %q{%
      The field of any planar current loop can be found
              by breaking it down into square dipoles.
    }
  )
%>
<% end_marg %>

The field of a square-loop dipole is very complicated close up, but luckily for
us, we only need to know the current at distances that are large compared to
the size of the loop, because we're free to make the squares on our grid as small as
we like. The \emph{distant} field of a square dipole turns out to be simple, and
is no different from the distant field of any other dipole with the same
dipole moment. We can also save ourselves some work if we only worry about
finding the field of the dipole in its own plane, i.e., the plane perpendicular
to its dipole moment. By symmetry, the field in this plane cannot have any component
in the radial direction (inward toward the dipole, or outward away from it); it
is perpendicular to the plane, and in the opposite direction compared to the dipole
vector. (The field \emph{inside} the loop is in the same direction as the dipole
vector, but we're interested in the distant field.)
Letting the dipole vector be along the $z$ axis, we find that the field in the
$x-y$ plane is of the form $B_z=f(r)$, where $f(r)$ is some function that depends
only on $r$, the distance from the dipole.

We can pin down the result even more without any math. We know that the magnetic
field made by a current always contains a factor of $k/c^2$, which is the coupling
constant for magnetism. We also know that the field must be proportional to the
dipole moment, $m=IA$. Fields are always directly proportional to currents, and
the proportionality to area follows because dipoles add according to their area.
For instance, a square dipole that is 2 micrometers by 2 micrometers in size can be
cut up into four dipoles that are 1 micrometer on a side. This tells us that our
result must be of the form $B_z=(k/c^2)(IA)g(r)$. Now if we multiply the
quantity $(k/c^2)(IA)$ by the function $g(r)$, we have to get units of teslas,
and this only works out if $g(r)$ has units of $\zu{m}^{-3}$ (homework problem
\ref{hw:dipole-units-proof}), so our result must be of the form\label{dipolederivn}
\begin{equation*}
        B_z=\frac{\beta kIA}{c^2r^3}\eqquad,
\end{equation*}
where $\beta$ is a unitless constant. Thus our only task is to determine
$\beta$, and we will have determined the field of the dipole (in the plane of
its current, i.e., the midplane with respect to its dipole moment vector).

<% marg(0) %>
<%
  fig(
    'diptowire',
    %q{%
      A long, straight current-carrying wire can be constructed
              by filling half of a plane with square dipoles.
    }
  )
%>

\spacebetweenfigs
%

<%
  fig(
    'diptowireint',
    %q{Setting up the integral.}
  )
%>
<% end_marg %>

If we wanted to, we could simply build a dipole, measure its field, and
determine $\beta$ empirically. Better yet, we can get an exact result if we
take a current loop whose field we know exactly, break it down into
infinitesimally small squares, integrate to find the total field, set
this result equal to the known expression for the field of the loop, and
solve for $\beta$. There's just one problem here. We don't yet know an
expression for the field of \emph{any} current loop of \emph{any} shape ---
all we know is the field of a long, straight wire. Are we out of luck?
No, because, as shown in figure \figref{diptowire}, 
we can make a long, straight wire by putting together square
dipoles! Any square dipole away from the edge has all four of its currents
canceled by its neighbors. The only currents that don't cancel are the
ones on the edge, so by superimposing all the square dipoles, we get a
straight-line current.\label{dipolestomakewire}

This might seem strange. If the squares on the interior have all their currents
canceled out by their neighbors, why do we even need them? Well, we need the squares
on the edge in order to make the straight-line current. We need the second row of
squares to cancel out the currents at the top of the first row of squares, and so on.

Integrating as shown in figure \figref{diptowireint}, we have
\begin{align*}
        B_z        &=  \int_{y=0}^\infty \int_{x=-\infty}^\infty \der B_z\eqquad, \\
\intertext{where $\der B_z$ is the contribution to the total magnetic field
at our point of interest, which lies a distance $R$ from the wire.}
        B_z        &= \int_{y=0}^\infty \int_{x=-\infty}^\infty  \frac{\beta kI\der A}{c^2r^3}  \\
                &= \frac{\beta kI}{c^2}%
                                \int_{y=0}^\infty \int_{x=-\infty}^\infty %
                                  \frac{1}{\left[x^2+(R+y)^2\right]^{3/2}}\der x\der y  \\
                &= \frac{\beta kI}{c^2R^3}%
                                \int_{y=0}^\infty \int_{x=-\infty}^\infty %
                                  \left[ %
                                                    \left(\frac{x}{R}\right)^2%
                                                          +\left(1+\frac{y}{R}\right)^2 %
                                  \right]^{-3/2}\der x\der y  \\
\intertext{This can be simplified with the substitutions $x=Ru$, $y=Rv$, and
$\der x\der y=R^2\der u\der v$\/:}
        B_z        &= \frac{\beta kI}{c^2R}%
                                \int_{v=0}^\infty \int_{u=-\infty}^\infty %
                                  \frac{1}{\left[u^2+(1+v)^2\right]^{3/2}}\der u\der v  \\
\intertext{The $u$ integral is of the form
$\int_{-\infty}^{\infty} (u^2+b)^{-3/2}\der u=2/b^2$, so}
        B_z        &= \frac{\beta kI}{c^2R}\int_{v=0}^\infty  %
                                  \frac{1}{(1+v)^2}\der v\eqquad, \\
\intertext{and the remaining $v$ integral is equals 2, so}
        B_z        &= \frac{2\beta kI}{c^2R}\eqquad. \\
\end{align*}
This is the field of a wire, which we already know equals $2kI/c^2R$,
so we have $\beta$=1. Remember, the point of this whole calculation was not to
find the field of a \emph{wire}, which we already knew, but to find the unitless
constant $\beta$ in the expression for the field of a \emph{dipole}.
The distant field of a dipole, in its midplane, is therefore 
$B_z=\beta kIA/c^2r^3= kIA/c^2r^3$, or,
in terms of the dipole moment,
\begin{equation*}
        B_z=\frac{km}{c^2r^3}\eqquad.
\end{equation*}

<% end_sec() %>

<% begin_sec("The distant field of a dipole, out of its midplane") %>

What about the field of a magnetic dipole outside of the dipole's midplane?
Let's compare with an electric dipole. An electric dipole, unlike a magnetic
one, can be built out of two opposite monopoles, i.e., charges, separated by a certain
distance, and it is then straightforward to show by vector addition that the
field of an electric dipole is\index{dipole!electric!field of}\index{electric dipole!field of}
\begin{align*}
        E_z        &= kD\left(3\cos^2\theta-1\right)r^{-3}\\
        E_R        &= kD\left(3\sin\theta\:\cos\theta\right)r^{-3}\eqquad,
\end{align*}
where $r$ is the distance from the dipole to the point of interest, $\theta$
is the angle between the dipole vector and the line connecting the dipole to this
point, and $E_z$ and $E_R$ are, respectively, the components of the field
parallel to and perpendicular to the dipole vector.

In the midplane, $\theta$ equals $\pi/2$, which produces $E_z=-kDr^{-3}$
and $E_R=0$. This is the same as the field of a \emph{magnetic} dipole
in its midplane, except that the electric coupling constant $k$ replaces
the magnetic version $k/c^2$, and the electric dipole moment $D$ is
substituted for the magnetic dipole moment $m$. It is therefore reasonable
to conjecture that by using the same presto-change-o recipe we can find the
field of a magnetic dipole outside its midplane:\index{dipole!magnetic!field of}\index{magnetic dipole!field of}
\begin{align*}
        B_z        &= \frac{km}{c^2}\left(3\cos^2\theta-1\right)r^{-3}\\
        B_R        &= \frac{km}{c^2}\left(3\sin\theta\:\cos\theta\right)r^{-3}\eqquad.
\end{align*}
This turns out to be correct.\label{dipolefieldeqns}
\footnote{If you've
taken a course in differential equations, this won't seem like a very surprising
assertion. The differential form of Gauss' law is a differential equation, and
by giving the value of the field in the midplane, we've specified a boundary
condition for the differential equation. Normally if you specify the boundary
conditions, then there is a unique solution to the differential equation. In this
particular case, it turns out that to ensure uniqueness, we also need to demand
that the solution satisfy the differential form of Amp\`{e}re's law, which is discussed
in section \ref{sec:amperediff}.}

<% marg(120) %>
<%
  fig(
    'field-of-point-dipole',
    %q{The field of a dipole.}
  )
%>
<% end_marg %>

\begin{eg}{Concentric, counterrotating currents}\label{eg:torus}
\egquestion
Two concentric circular current loops, with radii $a$
and $b$, carry the same amount of current $I$, but
in opposite directions. What is the field at the center?

\eganswer
We can produce these currents by tiling the region
between the circles with square current loops, whose currents all
cancel each other except at the inner and outer edges.
The flavor of the calculation is the same as the one in which we
made a line of current by filling a half-plane with square loops.
The main difference is that this geometry has a different symmetry,
so it will make more sense to use polar coordinates instead of $x$ and $y$.
The field at the center is
\begin{align*}
         B_{z}        &=        \int \frac{ kI}{ c^2 r^3}\der A \\
                                        &= \int_{ r= a}^{b}%
                                                \frac{ kI}{ c^2 r^3}\:\cdot2\pi r\der r \\
                                        &= \frac{2\pi kI}{ c^2}\:%
                                                        \left(\frac{1}{a}-\frac{1}{b}\right)\eqquad. 
\end{align*}
The positive sign indicates that the field is out of the page.
\end{eg}

<% marg(0) %>
<%
  fig(
    'torus',
    %q{Example \ref{eg:torus}.}
  )
%>
<% end_marg %>

\pagebreak[4]

\begin{eg}{Field at the center of a circular loop}\label{eg:circularloop}
\egquestion
What is the magnetic field at the center of a circular current loop of radius $a$,
which carries a current $I$?

\eganswer
This is like example \ref{eg:torus}, but with the outer loop being very large, and therefore
too distant to make a significant field at the center. Taking the limit of that result
as $b$ approaches infinity, we have
\begin{equation*}
         B_{z}        = \frac{2\pi kI}{ c^2 a} 
\end{equation*}
\end{eg}

        Comparing the results of examples \ref{eg:torus} and \ref{eg:circularloop}, we see that the
        directions of the fields are both out of the page. In example \ref{eg:torus}, the outer loop
        has a current in the opposite direction, so it contributes a field that is into the page.
        This, however, is weaker than the field due to the inner loop, which dominates because it
        is less distant.
 %Superposition of dipoles

<% end_sec() %>

<% end_sec() %>

<% begin_sec("The g factor (optional)",nil,'g-factor') %>

In section \ref{subsec:superposdip} we exploited a particular trick for
superimposing dipoles consisting of small square current loops.  Let's
now turn to a somewhat different way of superimposing dipoles. The
idea is that matter is made out of atoms, which may act like little
magnetic dipoles, but atoms are themselves made out of subatomic
particles such as electrons, neutrons and protons --- and there is no
obvious way that we can ever know whether we have taken this process
of reductionism (p.~\pageref{subsubsec:reductionism}) to its
conclusion. We can, however, look for clues in the electrical and
mechanical properties of matter. Suppose that a particle of charge $q$
and mass $m$ is whizzing around and around some closed path. We don't
even care whether the trajectory is a square or a circle, an orbit or a random wiggle.
But let's say for convenience that it's a planar shape. The magnetic
dipole moment (averaged over time) is $\vc{m}=I\vc{A}$. But the angular
momentum of a unit mass can also be interpreted (sec.~\ref{subsec:ang-mom-planetary},
p.~\pageref{subsec:ang-mom-planetary}) as twice the area it sweeps out per unit time.
Aside from the factor of two, which is just a historical glitch in the definitions,
this mathematical analogy is exact: mass is to
charge as angular momentum $\vc{L}$ is to magnetic dipole moment $\vc{m}$. Therefore we
have the identity
\begin{equation*}
  \frac{q}{m}\cdot\frac{|\vc{L}|}{|\vc{m}|} = 2
\end{equation*}
(where $\vc{m}$ is the dipole moment, while $m$ is the mass). The left-hand side
is called the $g$ factor. We expect $g=2$
for a single orbiting particle.

Now suppose that we have a collection of particles with identical values of $q/m$ (or
a continuous distribution of charge and mass in which the ratio of the charge and mass
densities is constant). Then vector addition of the $\vc{L}$ and $\vc{m}$ values
gives the same $g=2$ for the system as a whole. On the other hand, if the different
members of the system do \emph{not} all have the same $q/m$, then the $g$ of the system
as a whole need not be 2. For example, a collection of positive and negative charges
could easily have zero net charge but $\vc{m}\ne0$, giving $g=0$.

Particles such as the electron, the neutron, and the proton may be pointlike, or they
may be composites of other particles.
The electon and proton, which are charged, have the expected $g$ factors
of exactly 2 when we measure the $\vc{L}$ and $\vc{m}$ that they have due
to their motion through space. But we also find that electrons, neutrons, and protons all come equipped
with a built-in angular momentum, present even when they are at rest.
This intrinsic angular momentum, called spin,\index{spin}
is fixed in magnitude but can vary in direction, like that of a gyroscope.
Thus if we measure the $\vc{L}$ and $\vc{m}$ of these particles when they
are \emph{at rest}, they have fixed $g$ factors, which are as follows:

\begin{tabular}{ll}
electron & 2.002319304361 \\
neutron & 0 \\
proton & 5.58569471 
\end{tabular}

The electron's intrinsic $g$ factor is extremely close to 2, and if we ignore the small discrepancy for
now, we are led to imagine that the electron is either a pointlike particle or a composite
of smaller particles, each of which has the same charge-to-mass ratio. The neutron does have a
nonvanishing dipole moment, so its zero $g$ factor suggests that it is a composite of other
particles whose charges cancel. The proton's $g$ factor is quite different from 2, so we
infer that it, too, is composite. The current theory is that protons and neutrons
are clusters of particles called quarks.\index{quark} Quarks come in different types,
and the different types have different values of $q/m$.

It is remarkable that we can infer these facts about the internal structures of neutrons and
protons without having to do any experiments that directly probe their interior structure.
We don't need a super-powerful microscope, nor do we need a particle accelerator that can
supply enough energy to shake up their internal structure, like shaking a gift-wrapped box to tell what's inside.
Merely by measuring the external, aggregate properties of the ``box,'' we can get clues about the
structure inside. This is closely analogous to the Tolman-Stewart experiment (example \ref{eg:tolman-stewart}, p.~\pageref{eg:tolman-stewart}),
in which the subatomic structure of metals was probed by measuring inertial effects in an electric circuit.
A more famous and important experiment using these ideas, by Stern and Gerlach, is described in
sec.~\ref{sec:stern-gerlach}, p.~\pageref{sec:stern-gerlach}.

<% end_sec('g-factor') %>

<% begin_sec("The Biot-Savart law (optional)",nil,'biot') %>

In section \ref{subsec:superposdip} we developed a method for finding the field due to a 
given current distribution by tiling a plane with square dipoles. This method 
has several disadvantages:

\begin{itemize}
        \item The currents all have to lie in a single plane, and the point at which we're
                computing the field must be in that plane as well.
        \item We need to do integral over an area, which means one integral inside
                another, e.g., $\int\int\ldots\der x\der y$. That can get messy.
        \item It's physically bizarre to have to construct square dipoles in places where
                there really aren't any currents.
\end{itemize}

<% marg(70) %>
<%
  fig(
    'tilevscylinder',
    %q{Two ways of making a current loop out of square dipoles.}
  )
%>

\spacebetweenfigs
%

<%
  fig(
    'potatochipbmp',
    %q{The new method can handle non-planar currents.}
  )
%>
<% end_marg %>

% Have to use bitmapped version, potatochipbmp, because for some reason epstopdf doesn't
% convert this figure correctly.
Figure \figref{tilevscylinder} shows the first step in eliminating these defects:
instead of spreading our dipoles out in a plane, we bring them out along an axis.
As shown in figure \figref{potatochipbmp}, this eliminates the restriction to currents
that lie in a plane. Now we have to use the general equations for a dipole
field from page \pageref{dipolefieldeqns}, rather than the simpler expression for the field
in the midplane of a dipole. This increase in complication is more than compensated for
by a fortunate feature of the new geometry, which is that the infinite tube can be broken
down into strips, and we can find the field of such a strip for once and for all. This
means that we no longer have to do one integral inside another. The derivation of
the most general case is a little messy, so I'll just present
the case shown in figure \figref{biotsetup}, where the point of interest is assumed to
lie in the $y-z$ plane. Intuitively, what we're really finding is the field of the
short piece of length $\der\ell$ on the end of the U; the two long parallel segments
are going to be canceled out by their neighbors when we assemble all the strips to make the tube.
We expect that the field of this end-piece
will form a pattern that circulates around the $y$ axis, so at the point of
interest, it's really the $x$ component of the field that we want to compute:
\begin{align*}
        \der B_x        &= \int \der B_R \cos \alpha \\
                &= \int \frac{kI\der \ell\der x}{c^2s^3}(3\sin\theta\cos\theta \cos \alpha)  \\
                &= \frac{3kI\der \ell}{c^2} \int_0^\infty \frac{1}{s^3}\left(\frac{xz}{s^2}\right) \der x \\
                &= \frac{3kIz\der \ell}{c^2} \int_0^\infty \frac{x}{(x^2+r^2)^{5/2}} \der x \\
                &= \frac{kI\der \ell\:z}{c^2r^3}\\
                &= \frac{kI\der \ell\:\sin\phi}{c^2r^2}
\end{align*}
In the more general case, \figref{potatochipbmp}, the current loop is not planar, the point of interest is not
in the end-planes of the U's, and the U shapes have their ends staggered, so the end-piece
$\der\ell$ is not the only part of each U whose current is not canceled. Without going into
the gory details, the correct general result is as follows:
\begin{equation*}
  \der \vc{B} = \frac{kI\der \bell\times\vc{r}}{c^2r^3}\eqquad,
\end{equation*}
which is known as the Biot-Savart law. (It rhymes with ``leo bazaar.'' Both t's are silent.)
The distances $\der\ell$ and $ r$ are now defined as vectors, $\der\bell$ and
$\vc{r}$, which point, respectively, in the direction of the current in the end-piece
and the direction from the end-piece to the point of interest. The new equation looks different,
but it is consistent with the old one. The vector cross product $\der\bell\times\vc{r}$
has a magnitude $r\der \ell\:\sin\phi$, which cancels one of $r$'s in the denominator
and makes the $\der \bell\times\vc{r}/r^3$  into a vector with
magnitude $\der \ell\:\sin\phi/r^2$.\index{Biot-Savart law}

<% marg(120) %>
<%
  fig(
    'biotsetup',
    %q{The field of an infinite U.}
  )
%>

\spacebetweenfigs

<%
  fig(
    'biotgeom',
    %q{%
      The geometry of the Biot-Savart law. The small arrows show the result
              of the Biot-Savart law at various positions relative to the current segment $\der\bell$.
              The Biot-Savart law involves a cross product, and the right-hand rule for this cross
              product is demonstrated for one case.
    }
  )
%>
<% end_marg %>

\begin{eg}{The field at the center of a circular loop}
Previously we had to do quite a bit of work (examples \ref{eg:torus} and \ref{eg:circularloop}),
to calculate the field at the center
of a circular loop of current of radius $a$. It's much easier now. Dividing the loop
into many short segments, each $\der\bell$ is perpendicular to the 
$\vc{r}$ vector that goes from it to the center of the circle, and
every $\vc{r}$ vector has magnitude $a$. Therefore 
every cross product $\der\bell\times\vc{r}$ has the same magnitude,
$a\der \ell$, as well as the same direction along the axis perpendicular to the loop.
The field is
\begin{align*}
        B        &= \int \frac{ kIa\der \ell}{ c^2 a^3}\\
                &= \frac{ kI}{ c^2 a^2} \int \der \ell \\
                &= \frac{ kI}{ c^2 a^2} (2\pi a) \\
                &= \frac{2\pi kI}{ c^2 a} \\
\end{align*}
\end{eg}

\begin{eg}{Out-of-the-plane field of a circular loop}\label{eg:biotloop}
\egquestion
What is the magnetic field of a circular loop of current at a point on the axis
perpendicular to the loop,  lying a distance $z$ from the loop's center?

\eganswer
Again, let's write $a$ for the loop's radius. The \vc{r} vector now has
magnitude $\sqrt{ a^2+ z^2}$, but it is still perpendicular to the $\der\bell$
vector. By symmetry, the only nonvanishing component of the field is along the $z$ axis,
\begin{align*}
         B_{z}        &= \int |\der\vc{B}|\:\zu{cos}\:\alpha\\
                &= \int \frac{ kI\,r\,\der \ell}{ c^2 r^3}\frac{ a}{ r}\\
                &= \frac{ kIa}{ c^2 r^3} \int \der \ell \\
                &= \frac{2\pi kIa^2}{ c^2( a^2+ z^2)^{3/2}}\eqquad.
\end{align*}
\end{eg}

<% marg(-300) %>
<%
  fig(
    'biotloopaxis',
    %q{Example \ref{eg:biotloop}.}
  )
%>
<% end_marg %>

        
<% begin_sec("Is it the field of a particle?") %>

We have a simple equation, based on Coulomb's law, for the electric field surrounding a charged particle.
Looking at figure \figref{biotgeom}, we can imagine that if the
current segment $\der\ell$ was very short,
then it might only contain one electron. It's tempting, then, to interpret the Biot-Savart law
as a similar equation for the magnetic field surrounding a moving charged particle.
Tempting but wrong! Suppose you stand at a certain point in space and watch a charged
particle move by. It has an electric field, and since it's moving, you will also detect
a magnetic field on top of that. Both of these fields change over time, however. Not only
do they change their magnitudes and directions due to your changing geometric relationship to the
particle, but they are also time-delayed, because disturbances in the electromagnetic field
 travel at the speed of light, which is finite. The fields you detect are the
ones corresponding to where the particle used to be, not where it is now. 
 Coulomb's law and the Biot-Savart law
are both false in this situation, since neither equation includes time as a variable.
It's valid to think of Coulomb's law as the equation for the field of a stationary
charged particle, but not a moving one. The Biot-Savart law fails completely as
a description of the field of a charged particle, since stationary particles don't make
magnetic fields, and the Biot-Savart law fails in the case where the particle is moving.

If you look back at the long chain of reasoning that led to the Biot-Savart law, it all
started from the relativistic arguments at the beginning of this chapter, where
we assumed a steady current in an infinitely long wire. Everything that came later
was built on this foundation, so all our reasoning depends on the assumption that
the currents are steady. In a steady current, any charge that moves away from a certain
spot is replaced by more charge coming up behind it, so even though the charges are
all moving, the electric and magnetic fields they produce are constant. Problems of
this type are called electrostatics and magnetostatics problems, and it is only
for these problems that Coulomb's law and the Biot-Savart law are valid.

You might think that we could patch up Coulomb's law and the Biot-Savart law
by inserting the appropriate time delays. However, we've already seen a clear
example of a phenomenon that wouldn't be fixed by this patch:
on page \pageref{inductorinduction}, we found that a changing magnetic field
creates an electric field. Induction effects like these also lead to the
existence of light, which is a wave disturbance in the electric and magnetic
fields. We could try to apply another band-aid fix
to Coulomb's law and the Biot-Savart law to make them deal with induction, but
it won't work.

        So what \emph{are} the fundamental equations that describe how sources
        give rise to electromagnetic fields? We've already encountered two of them: Gauss'
        law for electricity and Gauss' law for magnetism. Experiments show that these
        are valid in all situations, not just static ones. But Gauss' law for magnetism
        merely says that the magnetic flux through a closed surface is zero.
        It doesn't tell us how to make magnetic fields using currents. It only tells
        us that we \emph{can't} make them using magnetic monopoles. The following
        section develops a new equation, called Amp\`{e}re's law, which is equivalent
        to the Biot-Savart law for magnetostatics, but 
        which, unlike the
        Biot-Savart law, can easily be extended to nonstatic situations.
 %The Biot-Savart law
 % 
 % ----------------------------------------------------------------------------- 
 % 

<% end_sec() %>

<% end_sec() %>

<% end_sec %>

<% begin_sec("Magnetic fields by Amp\\\`ere's law",nil,'ampere') %>

<% begin_sec("Amp\\\`ere's law") %>\index{Amp\`ere's law}

As discussed at the end of subsection \ref{subsec:biot}, 
our goal now is to find an equation
for magnetism that, unlike the Biot-Savart law, will not end up being a dead end
when we try to extend it to nonstatic situations.\footnote{If you didn't read
this optional subsection, don't worry, because the point is that we need to
try a whole new approach anyway.} Experiments show that Gauss'
law is valid in both static and nonstatic situations, so it would be reasonable
to look for an approach to magnetism that is similar to the way Gauss' law
deals with electricity.

<% marg(45) %>
<%
  fig(
    'sheeteb',
    %q{%
      The electric field of a sheet of charge, and
              the magnetic field of a sheet of current.
    },
    {'suffix'=>'2'}
  )
%>

\spacebetweenfigs
%

<%
  fig(
    'amperiansurface',
    %q{A Gaussian surface and an Amp\`{e}rian surface.}
  )
%>

\spacebetweenfigs
%

<%
  fig(
    'circulation',
    %q{The definition of the circulation, $\Gamma$.}
  )
%>
<% end_marg %>

How can we do this? Figure \figref{sheeteb2}, reproduced from page
\pageref{fig:sheeteb}, is our roadmap. 
Electric fields spread out from charges. Magnetic fields curl around currents.
In figure \figref{amperiansurface}/1, we define a Gaussian surface, and
we define the flux in terms of the electric field pointing out through this surface.
In the magnetic case, \figref{amperiansurface}/2, we define a
surface, called an Amp\`{e}rian surface, and we define a quantity called the
circulation, $\Gamma$ (uppercase Greek gamma), in terms of the magnetic
field that points along the edge of the Amp\`{e}rian surface, \figref{circulation}. We break the
edge into tiny parts $\vc{s}_j$, and for each of these parts, we define
a contribution to the circulation using the dot product of $\der\vc{s}$ with
the magnetic field:
\begin{equation*}
        \Gamma = \sum \vc{s}_j\cdot\vc{B}_j
\end{equation*}
The circulation is a measure of how curly the field is.
Like a Gaussian surface, an Amp\`{e}rian surface is purely a mathematical
construction. It is not a physical object.

In figure \figref{amperiansurface}/2, the field is perpendicular to the
edges on the ends, but parallel to the top and bottom edges. A dot product
is zero when the vectors are perpendicular, so only the
top and bottom edges contribute to $\Gamma$. Let these edges have length $s$.
Since the field is constant along both of these edges, we don't actually have
to break them into tiny parts; we can just have $\vc{s}_1$ on the top edge,
pointing to the left, and $\vc{s}_2$ on the bottom edge, pointing to the right.
The vector $\vc{s}_1$ is in the same direction
as the field $\vc{B}_1$, and $\vc{s}_2$ is in the same direction
as $\vc{B}_2$, so the dot products are simply equal to the products of the vectors'
magnitudes. The resulting circulation is
\begin{align*}
        \Gamma &= |\vc{s}_1||\vc{B}_1|+|\vc{s}_2||\vc{B}_2| \\
                        &= \frac{2\pi k\eta s}{c^2}+\frac{2\pi k\eta s}{c^2} \\
                        &= \frac{4\pi k\eta s}{c^2}\eqquad.
\end{align*}
But $\eta s$ is (current/length)(length), i.e., it is the amount of current that pierces
the Amp\`{e}rian surface. We'll call this current $I_{through}$. We have found one specific example
of the general law of nature known
as Amp\`{e}re's law:
\begin{equation*}
        \Gamma = \frac{4\pi k}{c^2}\,I_{through}
\end{equation*}

        
<% begin_sec("Positive and negative signs") %>

Figures \figref{amperesigns}/1 and \figref{amperesigns}/2 show what happens to the
circulation when we reverse the direction of the current $I_{through}$. Reversing the
current causes the magnetic field to reverse itself as well. The dot products occurring
in the circulation are all negative in \figref{amperesigns}/2, so the total circulation
is now negative. To preserve Amp\`{e}re's law, we need to define the current in
\figref{amperesigns}/2 as a negative number. In general, determine these plus
and minus signs using the right-hand rule shown in the figure. As the fingers of your
hand sweep around in the direction of the $\vc{s}$ vectors, your thumb defines the direction
of current which is positive. Choosing the direction of the thumb is like choosing which
way to insert an ammeter in a circuit: on a digital meter, reversing the connections
gives readings which are opposite in sign.

<% marg(80) %>
<%
  fig(
    'amperesigns',
    %q{Positive and negative signs in Amp\`{e}re's law.}
  )
%>

\spacebetweenfigs
%

<%
  fig(
    'amperesolenoid',
    %q{Example \ref{eg:amperesolenoid}: a cutaway view of a solenoid.}
  )
%>
<% end_marg %>

\begin{eg}{A solenoid}\label{eg:amperesolenoid}\index{solenoid!magnetic field of}
\egquestion
What is the field inside a long, straight solenoid of length $\ell$ and radius $a$,
and having $N$ loops of wire evenly wound along it, which carry a current $I$\/?

\eganswer
This is an interesting example, because it allows us to get a very good approximation
to the field, but without some experimental input it wouldn't be obvious what approximation
to use. Figure \figref{amperesolenoid}/1 shows what we'd observe by measuring the field
of a real solenoid. The field is nearly constant inside the tube, as long as we stay far
away from the mouths. The field outside is much weaker. For the sake of an approximate
calculation, we can idealize this field as shown in figure \figref{amperesolenoid}/2.
Of the edges of the Amp\`{e}rian surface shown in \figref{amperesolenoid}/3, only AB
contributes to the flux --- there is zero field along CD, and the field is perpendicular
to edges BC and DA. Amp\`{e}re's law gives
\begin{align*}
        \Gamma &= \frac{4\pi k}{ c^2}\, I_{ through} \\
        (B)(\text{length of AB}) &= \frac{4\pi k}{ c^2}\,(\eta)(\text{length of AB})\\
        B &= \frac{4\pi k\eta}{ c^2}\\
          &= \frac{4\pi k NI}{ c^2 \ell}\\
\end{align*}

\end{eg}

        
<% self_check('solenoiddirection',<<-'SELF_CHECK'
What direction is the current in figure \figref{amperesolenoid}?
  SELF_CHECK
  ) %>

        
<% self_check('solenoidell',<<-'SELF_CHECK'
Based on how $\ell$ entered into the derivation in example \ref{eg:amperesolenoid},
        how should it be interpreted? Is it the total length of the wire?
  SELF_CHECK
  ) %>

<% self_check('solenoidsize',<<-'SELF_CHECK'
Surprisingly, we never needed to know the radius of the solenoid in example \ref{eg:amperesolenoid}.
        Why is it physically plausible that the answer would be independent of the radius?
  SELF_CHECK
  ) %>

        Example \ref{eg:amperesolenoid} shows how much easier it can sometimes be to calculate
        a field using Amp\`{e}re's law rather than the approaches developed previously in this
        chapter. However, if we hadn't already known something about the field, we wouldn't have
        been able to get started. In situations that lack symmetry, Amp\`{e}re's law may make things
        harder, not easier. Anyhow, we will have no choice in nonstatic cases, where Amp\`{e}re's law
        is true, and static equations like the Biot-Savart law are false.
 %ampere's law

<% end_sec() %>

<% end_sec() %>

<% begin_sec("A quick and dirty proof") %>
\label{ampereproof}
        Here's an informal sketch for a proof of Amp\`{e}re's law, with no pretensions to rigor.
        Even if you don't care much for proofs, it would be a good idea to read it, because it
        will help to build your ability to visualize how Amp\`{e}re's law works.

First we establish by a direct computation (homework problem \ref{hw:amperehalo}) that
Amp\`{e}re's law holds for the geometry shown in figure \figref{ampereproof}/1, a circular
Amp\`{e}rian surface with a wire passing perpendicularly through its center. If we then
alter the surface as in figure \figref{ampereproof}/2, Amp\`{e}re's law still works, because
the straight segments, being perpendicular to the field, don't contribute to the circulation,
and the new arc makes the same contribution to the circulation as the old one it replaced,
because the weaker field is compensated for by the greater length of the arc. It is clear that
by a series of such modifications, we could mold the surface into any shape, \figref{ampereproof}/3.

<% marg(0) %>
<%
  fig(
    'ampereproof',
    %q{A proof of Amp\`{e}re's law.}
  )
%>
<% end_marg %>

Next we prove Amp\`{e}re's law in the case shown in figure \figref{ampereproof}/4: a small,
square Amp\`{e}rian surface subject to the field of a distant square dipole. This part of the
proof can be most easily accomplished by the methods of section \ref{sec:amperediff}.
It should, for example, be plausible in the case illustrated here. The field on the left
edge is stronger than the field on the right, so the overall contribution of these two
edges to the circulation is slightly counterclockwise. However, the field is not quite perpendicular
to the top and bottoms edges, so they both make small clockwise contributions. The clockwise
and counterclockwise parts of the circulation end up canceling each other out. Once 
Amp\`{e}re's law is established for a square surface like \figref{ampereproof}/4, it follows
that it is true for an irregular surface like \figref{ampereproof}/5, since we can build
such a shape out of squares, and the circulations are additive when we paste the surfaces together
this way.

By pasting a square dipole onto the wire, \figref{ampereproof}/6,
like a flag attached to a flagpole, we can cancel
out a segment of the wire's current and create a detour. Amp\`{e}re's law is still true because,
as shown in the last step,
the square dipole makes zero contribution to the circulation. We can make as many detours
as we like in this manner, thereby morphing the wire into an arbitrary shape like
\figref{ampereproof}/7.

What about a wire like \figref{ampereproof}/8? It doesn't
pierce the Amp\`{e}rian surface, so it doesn't add anything to $I_{through}$, and
we need to show that it likewise doesn't change the circulation. This wire, however,
could be built by tiling the half-plane on its right with square dipoles, and we've
already established that the field of a distant dipole doesn't contribute to the
circulation. (Note that we couldn't have done this with a wire like
\figref{ampereproof}/7, because some of the dipoles would have been right on top
of the Amp\`{e}rian surface.)

If Amp\`{e}re's law holds for cases like \figref{ampereproof}/7 and
\figref{ampereproof}/8, then it holds for any complex bundle of wires, including some that
pass through the Amp\`{e}rian surface and some that don't. But we can build just about
any static current distribution we like using such a bundle of wires, so it follows that
Amp\`{e}re's law is valid for any static current distribution.

 %proof

<% end_sec() %>

<% begin_sec("Maxwell's equations for static fields") %>

Static electric fields \emph{don't} curl the way magnetic fields do, so we can state
a version of Amp\`{e}re's law for electric fields, which is that the circulation of the electric
field is zero. Summarizing what we know so far about static fields, we have
\begin{align*}
        \Phi_E                &= 4\pi kq_{in}\\
        \Phi_B                &= 0\\
        \Gamma_E         &= 0 \\
        \Gamma_B         &= \frac{4\pi k}{c^2}\,I_{through}\eqquad.\\
\end{align*}
This set of equations is the static case of the more general relations known as
Maxwell's equations.\index{Maxwell's equations!for static fields}
On the left side of each equation, we have information about a field. On the right
 is information about the field's sources.

It is vitally important to realize that these equations are only true for statics.
They are incorrect if the distribution of charges or currents is changing over time.
For example, we saw on page \pageref{inductorinduction}  that the changing magnetic
field in an inductor gives rise to an electric field. Such an effect is completely
inconsistent with the static version of Maxwell's equations; the equations don't
even refer to time, so if the magnetic field is changing over time, they will
not do anything special. The extension of Maxwell's equations to nonstatic fields
is discussed in section \ref{sec:maxwell}.

\startdqs

<% marg(0) %>
<%
  fig(
    'dq-ampere-two-wires',
    %q{Discussion question \ref{dq:ampere-two-wires}.}
  )
%>

\spacebetweenfigs

<%
  fig(
    'dq-ampere-perp-wire',
    %q{Discussion question \ref{dq:ampere-perp-wire}.}
  )
%>

\spacebetweenfigs

<%
  fig(
    'dq-ampere-off-center',
    %q{Discussion question \ref{dq:ampere-off-center}.}
  )
%>

\spacebetweenfigs

<%
  fig(
    'dq-ampere-nudge-wire',
    %q{Discussion question \ref{dq:ampere-nudge-wire}.}
  )
%>

\spacebetweenfigs

<%
  fig(
    'dq-ampere-blobs',
    %q{Discussion question \ref{dq:ampere-blobs}.}
  )
%>
<% end_marg %>

\begin{dq}\label{dq:ampere-two-wires}
Figure \figref{dq-ampere-two-wires}/1 shows a wire with a circular Amp\`{e}rian surface drawn
around its waist; in this situation, Amp\`{e}re's law can be verified easily based on the
equation for the field of a wire. In panel 2, a second wire has been added. Explain why it's
plausible that Amp\`{e}re's law still holds.
\end{dq}

\begin{dq}\label{dq:ampere-perp-wire}
Figure \figref{dq-ampere-perp-wire} is like figure \figref{dq-ampere-two-wires}, but now the
second wire is perpendicular to the first, and lies in the plane of, and outside of, the Amp\`{e}rian surface.
Carry out a similar analysis.
\end{dq}

\begin{dq}\label{dq:ampere-off-center}
This discussion question is similar to questions \ref{dq:ampere-two-wires} and \ref{dq:ampere-perp-wire},
but now the Amp\`{e}rian surface has been moved off center.
\end{dq}

\begin{dq}\label{dq:ampere-nudge-wire}
The left-hand wire has been nudged over a little. Analyze as before.
\end{dq}

\begin{dq}\label{dq:ampere-blobs}
You know what to do.
\end{dq}
\vfill

 % 
 % ----------------------------------------------------------------------------- 
 % 

<% end_sec() %>

<% end_sec() %>

<% begin_sec("Amp\\\`{e}re's law in differential form (optional)",4,'amperediff') %>

<% begin_sec("The curl operator") %>

The differential form of Gauss' law is more physically satisfying than the integral
form, because it relates the charges that are present at some point to the
properties of the electric field \emph{at the same point}. Likewise, it would be
more attractive to have a differential version of Amp\`{e}re's law that would
relate the currents to the magnetic field at a single point. intuitively, the
divergence was based on the idea of the div-meter, \figref{curlmeter}/1. The
corresponding device for measuring the curliness of a field is the
curl-meter, \figref{curlmeter}/2. If the field is curly, then the torques on the
charges will not cancel out, and the wheel will twist against the resistance
of the spring. If your intuition tells you that the curlmeter will never do
anything at all, then your intuition is doing a beautiful job on static fields;
for nonstatic fields, however, it is perfectly possible to get a curly electric
field. 

<% marg(70) %>
<%
  fig(
    'curlmeter',
    %q{The div-meter, 1, and the curl-meter, 2 and 3.}
  )
%>
<% end_marg %>

Gauss' law in differential form relates $\divg\vc{E}$, a scalar, to the charge
density, another scalar. Amp\`{e}re's law, however, deals with directions in
space: if we reverse the directions of the currents, it makes a difference.
We therefore expect that the differential form of Amp\`{e}re's law will have
vectors on both sides of the equal sign, and we should be thinking of the curl-meter's result as
a vector. First we find the orientation of the curl-meter that gives the strongest
torque, and then we define the direction of the curl vector
using the right-hand rule shown in figure \figref{curlmeter}/3.

To convert the div-meter concept to a mathematical definition, we found the
infinitesimal flux, $\der\Phi$ through a tiny cubical Gaussian surface containing
a volume $\der v$. By analogy, we imagine a tiny square Amp\`{e}rian surface with
infinitesimal area $\der\vc{A}$. We assume this surface has been oriented in
order to get the maximum circulation. The area vector $\der\vc{A}$ will then be
in the same direction as the one defined in figure \figref{curlmeter}/3. Amp\`{e}re's
law is
\begin{align*}
        \der\Gamma        &= \frac{4\pi k}{c^2}\,\der I_{through}\eqquad.\\
\intertext{We define a current density per unit
area\index{current density}, $\vc{j}$, which is a vector pointing in the direction of
the current and having magnitude $\vc{j}=\der I/|\der\vc{A}|$. In terms of this quantity, we have}
        \der\Gamma        &= \frac{4\pi k}{c^2}\,{j} |\vc{j}|\,|\der\vc{A}| \qquad \\
        \frac{\der\Gamma}{|\der\vc{A}|}        &= \frac{4\pi k}{c^2}\, |\vc{j}| \qquad \\
\intertext{With this motivation, we define the magnitude of the curl as}
        |\curl\,\vc{B}|        &= \frac{\der\Gamma}{|\der\vc{A}|}\eqquad. \qquad \\
\intertext{Note that the curl, just like a derivative, has a differential divided by
another differential. In terms of this definition, we find Amp\`{e}re's law in differential form:}
        \curl\,\vc{B} &= \frac{4\pi k}{c^2} \,\vc{j}
\end{align*}
The complete set of Maxwell's equations in differential form is collected on page \pageref{maxwell-forms}.

<% end_sec() %>

<% begin_sec("Properties of the curl operator") %>

<% begin_sec("The curl is a derivative.") %>

As an example, let's calculate the curl of the field $\hat{\vc{x}}$ shown
in figure \figref{curlxhat}. For our present purposes, it doesn't really matter
whether this is an electric or a magnetic field; we're just getting out feet wet
with the curl as a mathematical definition.
Applying the definition of the curl directly, we construct an Amp\`{e}rian surface
in the shape of an infinitesimally small square. Actually, since the field is
uniform, it doesn't even matter very much whether we make the square finite or
infinitesimal. The right and left edges don't
contribute to the circulation, since the field is perpendicular to these edges. The
top and bottom do contribute, but the top's contribution is clockwise, i.e., into the page
according to the right-hand rule, while the bottom contributes an equal amount
in the counterclockwise direction, which corresponds to an out-of-the-page contribution
to the curl. They cancel, and the circulation is zero. We could also have determined this
by imagining a curl-meter inserted in this field: the torques on it would have canceled out.

<% marg(123) %>
<%
  fig(
    'curlcoords',
    %q{The coordinate system used in the following examples.}
  )
%>

\spacebetweenfigs
%

<%
  fig(
    'curlxhat',
    %q{The field $\hat{\vc{x}}$.}
  )
%>

\spacebetweenfigs
%

<%
  fig(
    'curlyhat',
    %q{The field $\hat{\vc{y}}$.}
  )
%>

\spacebetweenfigs
%

<%
  fig(
    'curlxyhat',
    %q{The field $x\hat{\vc{y}}$.}
  )
%>
<% end_marg %>

It makes sense that the curl of a constant field is zero, because the curl is a kind of
derivative. The derivative of a constant is zero.

<% end_sec() %>

<% begin_sec("The curl is rotationally invariant.") %>

Figure \figref{curlxhat} looks just like figure \figref{curlxhat}, but rotated by 90 degrees.
Physically, we could be viewing the same field from a point of view that was rotated.
Since the laws of physics are the same regardless of rotation, the curl must be zero
here as well. In other words, the curl is rotationally invariant. If a certain field has
a certain curl vector, then viewed from some other angle, we simply see the same field
and the same curl vector, viewed from a different angle. A zero vector viewed from a
different angle is still a zero vector.

As a less trivial example, let's compute the curl of the field
$\vc{F}=x\hat{\vc{y}}$ shown in figure \figref{curlxyhat}, at the point $(x=0,y=0)$.
The circulation around a square of side $s$
centered on the origin can be approximated by evaluating the
field at the midpoints of its sides,
\begin{alignat*}{4}
                x&=s/2        &\qquad y&=0        &\qquad \vc{F}&=(s/2)\hat{\vc{y}}        &\qquad \vc{s}_1\cdot\vc{F}&=s^2/2 \\
                x&=0        &\qquad y&=s/2        &\qquad \vc{F}&=0                                        &\qquad \vc{s}_2\cdot\vc{F}&=0 \\
                x&=-s/2        &\qquad y&=0        &\qquad \vc{F}&=-(s/2)\hat{\vc{y}}        &\qquad \vc{s}_3\cdot\vc{F}&=s^2/2 \\
                x&=0        &\qquad y&=-s/2 &\qquad \vc{F}&=0                                        &\qquad \vc{s}_4\cdot\vc{F}&=0\eqquad,\\
\end{alignat*}
which gives a circulation of $s^2$, and a curl 
with a magnitude of $s^2/\text{area}=s^2/s^2=1$. By the right-hand rule, the
curl points out of the page, i.e., along the positive $z$ axis, so we have
\begin{equation*}
        \curl\,x\hat{\vc{y}} = \hat{\vc{z}}\eqquad.
\end{equation*}\label{curlxy}

<% marg(35) %>
<%
  fig(
    'curlyxhat',
    %q{The field $- y\hat{\vc{x}}$.}
  )
%>

\spacebetweenfigs
%

<%
  fig(
    'curlminusxyhat',
    %q{Example \ref{eg:curlminusxyhat}.}
  )
%>

\spacebetweenfigs
%

<%
  fig(
    'curlxyyx',
    %q{Example \ref{eg:curlxyyx}.}
  )
%>
<% end_marg %>

Now consider the field $-y\hat{\vc{x}}$, shown in figure \figref{curlyxhat}.
This is the same as the previous field, but with your book rotated by
90 degrees about the $z$ axis. Rotating the result of the first calculation,
$\hat{\vc{z}}$, about the $z$ axis doesn't change it, so the curl of this field
is also $\hat{\vc{z}}$.

<% end_sec() %>

<% begin_sec("Scaling") %>

When you're taking an ordinary derivative, you have the rule
\begin{equation*}
        \frac{\der}{\der x}[cf(x)] = c\frac{\der}{\der x}f(x)\eqquad.
\end{equation*}
In other words, multiplying a function by a constant results in a derivative
that is multiplied by that constant. The curl is a kind of derivative
operator, and the same is true for a curl.

\begin{eg}{Multiplying the field by $-1$.}\label{eg:curlminusxyhat}
  \egquestion
  What is the curl of the field $- x\hat{\vc{y}}$ at the origin?

  \eganswer
  Using the scaling property just discussed, we can make this
  into a curl that we've already calculated:
  \begin{align*}
          \curl\,(- x\hat{\vc{y}})        &= -\curl\,( x\hat{\vc{y}})        \\
                                                                          &= -\hat{\vc{z}}        \\
  \end{align*}
  This is in agreement with the right-hand rule.
\end{eg}        

<% end_sec() %>

<% begin_sec("The curl is additive.") %>

We have only calculated each field's curl at the origin, but
each of these fields actually has the same curl everywhere.
In example \ref{eg:curlminusxyhat}, for instance, it is obvious that the
curl is constant along any vertical line. But even if we
move along the $x$ axis, there is still an imbalance between
the torques on the left and right sides of the curl-meter.
More formally, suppose we start from the origin and move
to the left by one unit. We find ourselves in a region where the
field is very much as it was before, except that all the
field vectors have had one unit worth of $\hat{\vc{y}}$ added to them. But
what do we get if we take the curl of $- x\hat{\vc{y}}+\hat{\vc{y}}$? The curl, like any
god-fearing derivative operation, has the additive property 
\begin{equation*}
                \curl(\vc{F}+\vc{G}) = \curl\,\vc{F}+\curl\,\vc{G}\eqquad,  
\end{equation*}
so
\begin{equation*}
                \curl(- x\hat{\vc{y}}+\hat{\vc{y}}) = \curl(- x\hat{\vc{y}})+\curl(\hat{\vc{y}})\eqquad.   
\end{equation*}
But the second term is zero, so we get the same result as at the origin.

\begin{eg}{A field that goes in a circle}\label{eg:curlxyyx}
\egquestion
What is the curl of the field $x\hat{\vc{y}}- y\hat{\vc{x}}$?

\eganswer
Using the linearity of the curl, and recognizing
each of the terms as one whose curl we have already
computed, we find that this field's curl is a constant $2\hat{\vc{z}}$.
This agrees with the right-hand rule.
\end{eg}

\begin{eg}{The field inside a long, straight wire}
\egquestion
What is the magnetic field \emph{inside} a long, straight wire in which the
current density is $j$?

\eganswer
Let the wire be along the $z$ axis, so $\vc{j}= j\hat{\vc{z}}$.
Amp\`{e}re's law gives
\begin{equation*}
        \curl\,\vc{B}= \frac{4\pi k}{ c^2} \, j\hat{\vc{z}}\eqquad.
\end{equation*}
In other words, we need a magnetic field whose curl is a constant. We've encountered
several fields with constant curls, but the only one that has the same symmetry as the
cylindrical wire is $x\hat{\vc{y}}- y\hat{\vc{x}}$, so the answer must be
this field or some constant multiplied by it,
\begin{equation*}
        \vc{B}=   b\left( x\hat{\vc{y}}- y\hat{\vc{x}}\right)\eqquad.
\end{equation*}
The curl of this field is $2 b\hat{\vc{z}}$, so
\begin{align*}
        2 b &= \frac{4\pi k}{ c^2} \, j\eqquad,\\
\intertext{and thus}
        \vc{B}&=  \frac{2\pi k}{ c^2} \, j\left( x\hat{\vc{y}}- y\hat{\vc{x}}\right)\eqquad.\\
\end{align*}
\end{eg}

        
<% end_sec() %>

<% begin_sec("The curl in component form") %>

Now consider the field
\begin{align*}
        F_x &= ax+by+c \\
        F_y &= dx+ey+f\eqquad,\\
\intertext{i.e.,}
        \vc{F} &= ax\hat{\vc{x}}+by\hat{\vc{x}}+c\hat{\vc{x}}+dx\hat{\vc{y}}+ey\hat{\vc{y}}+f\hat{\vc{y}}\eqquad.
\end{align*}
The only terms whose curls we haven't yet explicitly computed are the $a$, $e$, and $f$ terms, and their
curls turn out to be zero (homework problem \ref{hw:xxhat}). Only the $b$ and $d$ terms have
nonvanishing curls.
The curl of this field is
\begin{align*}
        \curl\,\vc{F} &= \curl(by\hat{\vc{x}})+\curl(dx\hat{\vc{y}}) \\ 
                                   &= b\,\curl(y\hat{\vc{x}})+d\,\curl(x\hat{\vc{y}}) \qquad \text{[scaling]}\\ 
                                   &= b(-\hat{\vc{z}})+d(\hat{\vc{z}}) \qquad \text{[found previously]}\\ 
                                   &= (d-b)\hat{\vc{z}}\eqquad.\\ 
\end{align*}

But \emph{any} field in the $x-y$ plane can be approximated with this type of field, as long
as we only need to get a good approximation within a small region. The infinitesimal
Amp\`{e}rian surface occurring in the definition of the curl is tiny enough to
fit in a pretty small region, so we can get away with this here. The $d$ and $b$ coefficients
can then be associated with the partial derivatives $\partial F_y/\partial x$ and $\partial F_x/\partial y$.
We therefore have
\begin{equation*}
        \curl\,\vc{F} = \left(\frac{\partial F_y}{\partial x}-\frac{\partial F_x}{\partial y}\right)\hat{\vc{z}} \\ 
\end{equation*}
for any field in the $x-y$ plane. 
In three dimensions, we just need to generate two more equations like this by
doing a cyclic permutation of the variables $x$, $y$, and $z$:
\begin{align*}
        (\curl\,\vc{F})_x &= \frac{\partial F_z}{\partial y}-\frac{\partial F_y}{\partial z} \\ 
        (\curl\,\vc{F})_y &= \frac{\partial F_x}{\partial z}-\frac{\partial F_z}{\partial x}  \\ 
        (\curl\,\vc{F})_z &= \frac{\partial F_y}{\partial x}-\frac{\partial F_x}{\partial y} \\ 
\end{align*}

<% marg(150) %>
<%
  fig(
    'cyclicperm',
    %q{A cyclic permutation of $x$, $y$, and $z$.}
  )
%>

\spacebetweenfigs

<%
  fig(
    'curlsine',
    %q{Example \ref{eg:curlsine}.}
  )
%>
<% end_marg %>

\begin{eg}{A sine wave}\label{eg:curlsine}
\egquestion
Find the curl of the following electric field
\begin{equation*}
        \vc{E} = (\zu{sin}\, x)\hat{\vc{y}}\eqquad,
\end{equation*}
and interpret the result.

\eganswer
The only nonvanishing partial derivative occurring in this curl is
\begin{align*}
        (\curl\,\vc{E})_z &= \frac{\partial  E_{y}}{\partial  x} \\ 
                                          &= \zu{cos}\, x\eqquad,\\ 
\intertext{so}
        \curl\,\vc{E}        &= \zu{cos}\,\hat{\vc{z}}
\end{align*}
This is visually reasonable: the curl-meter would spin if we put its wheel
in the plane of the page, with its axle poking out along the $z$ axis.
In some areas it would spin clockwise, in others
counterclockwise, and this makes sense, because the cosine is positive in
some placed and negative in others.

This is a perfectly reasonable field pattern: it the electric field pattern of a light wave! But Amp\`{e}re's
law for electric fields says the curl of \vc{E} is supposed to be zero.
What's going on? What's wrong is that we can't assume the \emph{static} version of
Amp\`{e}re's law. All we've really proved is that this pattern is impossible as a static
field: we can't have a light wave that stands still.
\end{eg}

Figure \figref{math-summary} is a summary of the vector calculus presented  in the optional sections of this book.
The first column shows that one function is a related to another by a kind of differentiation. The second column
states the fundamental theorem of calculus, which says that if you integrate the derivative over the interior of
a region, you get some information about the original function at the boundary of that region.

<%
  fig(
    'math-summary',
    %q{%
      A summary of the derivative, gradient, curl, and divergence.
    },
    {
      'width'=>'fullpage'
    }
  )
%>

\pagebreak[4]

 % 
 % ----------------------------------------------------------------------------- 
 % 

<% end_sec() %>

<% end_sec() %>

<% end_sec %>

<% begin_sec("Induced electric fields",4,'induction') %>

<% begin_sec("Faraday's experiment") %>

Nature is simple, but the simplicity may not become evident until a hundred
years after the discovery of some new piece of physics. We've already seen,
on page \pageref{inductorinduction}, that
the time-varying magnetic field in an inductor causes an electric field. This
electric field is \emph{not created by charges}.
That argument, however, only seems clear with hindsight. The discovery of
this phenomenon of induced electric fields --- fields that are not due to
charges --- was a purely experimental accomplishment by Michael Faraday (1791-1867), the son of a
blacksmith who had to struggle against the rigid class structure of 19th century England.
Faraday, working in 1831, had only a vague and general idea that electricity and magnetism
were related to each other, based on Oersted's demonstration, a decade before,
that magnetic fields were caused by electric currents. 

<% marg(50) %>
<%
  fig(
    'faraday-portrait',
    %q{Faraday on a British banknote.}
  )
%>

\spacebetweenfigs
%

<%
  fig(
    'faraday',
    %q{%
      Faraday's experiment, simplified and shown with
              modern equipment.
    }
  )
%>
<% end_marg %>

Figure \figref{faraday} is a simplified drawing of the following experiment,
as described in Faraday's original paper:
``Two hundred and three feet of copper wire \ldots were passed round a large block
of wood; [another] two hundred and three feet of similar wire were interposed
as a spiral between the turns of the first, and metallic contact everywhere
prevented by twine [insulation]. One of these [coils] was connected
with a galvanometer [voltmeter], and the other with a battery\ldots When the
contact was made, there was a sudden and very slight effect at the galvanometer,
and there was also a similar slight effect when the contact with the battery
was broken. But whilst the \ldots current was continuing to pass through the one
[coil], no  \ldots effect \ldots upon the other [coil] could be perceived,
although the active power of the battery was proved to be great, by its heating
the whole of its own coil [through ordinary resistive heating] \ldots''

From Faraday's notes and publications, it appears that the situation in figure
\figref{faraday}/3 was a surprise to him, and he probably thought it would be
a surprise to his readers, as well. That's why he offered evidence that the
current was still flowing: to show that the battery hadn't just died.
The induction effect occurred during the short time it took for the black coil's
magnetic field to be established, \figref{faraday}/2. Even more counterintuitively,
we get an effect, equally strong but in the opposite direction, when the circuit
is \emph{broken}, \figref{faraday}/4. The effect occurs only when the magnetic field
is changing, and it appears to be proportional to the derivative
$\partial\vc{B}/\partial\vc{t}$, which is in one direction when the field is
being established, and in the opposite direction when it collapses.

The effect is proportional to $\partial\vc{B}/\partial\vc{t}$, but what \emph{is}
the effect? A voltmeter is nothing more than a resistor with an attachment for
measuring the current through it. A current will not flow through a resistor unless
there is some electric field pushing the electrons, so we conclude that the
changing \emph{magnetic field} has produced an \emph{electric field} in the
surrounding space. Since the white wire is not a perfect conductor, there must
be electric fields in it as well. The remarkable thing about the circuit formed
by the white wire is that as the electrons travel around and around, they are
always being pushed forward by electric fields. This violates the loop rule, which
says that when an electron makes a round trip, there is supposed to be just as
much ``uphill'' (moving against the electric field) as ``downhill'' (moving with it).
That's OK. The loop rule is only true for statics. 
Faraday's experiments show that an electron really can go around and around, and
always be going ``downhill,'' as in the famous drawing by M.C. Escher shown in figure
\figref{escher}. That's just what happens when you have a curly field.

When a field is curly, we can measure its curliness using a circulation. Unlike
the magnetic circulation $\Gamma_B$, the electric circulation $\Gamma_E$ is something
we can measure directly using ordinary tools. A circulation is defined by breaking
up a loop into tiny segments, $\der\vc{s}$, and adding up the dot products 
of these distance vectors with
the field. But when we multiply electric field by distance, what we get is an indication
of the amount of work per unit charge done on a test charge that has been moved through that
distance. The work per unit charge has units of volts, and it can be measured using
a voltmeter, as shown in figure \figref{emf}, where $\Gamma_E$ equals the sum
of the voltmeter readings. Since the electric circulation is
directly measurable, most people who work with circuits are more familiar with
it than they are with the magnetic circulation. They usually refer to $\Gamma_E$ 
using the synonym ``emf,'' which stands for ``electromotive force,'' and notate it as $\mathcal{E}$. (This
is an unfortunate piece of terminology, because its units are really volts,
not newtons.)\index{emf}\label{emf-term-introduced} The term emf can also be used when the path is not a closed loop.

Faraday's experiment demonstrates
a new relationship
\begin{equation*}
        \Gamma_E \propto -\frac{\partial B}{\partial t}\eqquad,
\end{equation*}
where the negative sign is a way of showing the observed
left-handed relationship, \figref{inducedegeom}.
This is similar to the structure of of Amp\`{e}re's
law:
\begin{equation*}
        \Gamma_B \propto I_{through}\eqquad,
\end{equation*}
which also relates the curliness of a field to something that is going on
nearby (a current, in this case).

<% marg(150) %>
<%
  fig(
    'escher',
    %q{Detail from \textit{Ascending and Descending}, M.C. Escher, 1960.}
  )
%>

\spacebetweenfigs
%

<%
  fig(
    'inducedegeom',
    %q{%
      The relationship between the change in the
              magnetic field, and the electric field it produces.
    }
  )
%>

\spacebetweenfigs
%

<%
  fig(
    'emf',
    %q{The electric circulation is the sum of the voltmeter readings.}
  )
%>
<% end_marg %>

It's important to note that even though the emf, $\Gamma_E$, has units
of volts, it isn't a voltage. A voltage is a measure of the electrical
energy a charge has when it is at a certain point in space. The curly
nature of nonstatic fields means that this whole concept becomes nonsense.
In a curly field, suppose one electron stays at home while its friend goes for
a drive around the block. When they are reunited, the one that went around the
block has picked up some kinetic energy, while the one who stayed at home hasn't.
We simply can't define an electrical energy $U_e=qV$ so that $U_e+K$ stays the
same for each electron. No voltage pattern, $V$, can do this, because then
it would predict the same kinetic energies for the two electrons, which is
incorrect.
When we're dealing with nonstatic fields, we need to think of the electrical
energy in terms of the energy density of the fields themselves.

It might sound as though an electron could get a free lunch by circling
around and around in a curly electric field, resulting in a violation of
conservation of energy. The following examples, in addition to their
practical interest, both show that energy is in fact conserved.

\begin{eg}{The \index{generator}generator}
A  basic generator, \figref{generator}, consists of a permanent magnet that
rotates within a coil of wire. The magnet is turned by a
motor or crank, (not shown). As it spins, the nearby
magnetic field changes. This changing magnetic field results in an
electric field, which has a curly pattern. This electric
field pattern creates a current that whips around the coils
of wire, and we can tap this current to light the lightbulb.

<% marg(0) %>
<%
  fig(
    'generator',
    %q{A generator.}
  )
%>
<% end_marg %>

If the magnet was on a frictionless bearing, could we light the bulb
for free indefinitely, thus violating conservation of energy? No.
Mechanical work has to be done to crank the magnet, and that's where
the energy comes from. If we break the light-bulb circuit, it suddenly
gets easier to crank the magnet! This is because the current in the coil
sets up its own magnetic field, and that field exerts a torque on the magnet.
If we stopped cranking, this torque would quickly make the magnet stop turning.
\end{eg}

<% self_check('alternator',<<-'SELF_CHECK'
When you're driving your car, the engine recharges the
        battery continuously using a device called an alternator,
        which is really just a generator. Why can't you use the
        alternator to start the engine if your car's battery is dead?
  SELF_CHECK
  ) %>

<% marg(0) %>
<%
  fig(
    'transformer',
    %q{A transformer.}
  )
%>
<% end_marg %>

\begin{eg}{The transformer\index{transformer}}
In example \ref{hvtransmission} on page \pageref{hvtransmission},
we discussed the advantages of transmitting
power over electrical lines using high voltages and low
currents. However, we don't want our wall sockets to operate
at 10000 volts! For this reason, the electric company uses a
device called a transformer, \figref{transformer}, to
convert everything to lower voltages and higher currents inside your
house. The coil on the input side creates a magnetic field.
Transformers work with alternating current, so the magnetic
field surrounding the input coil is always changing. This
induces an electric field, which drives a current around the output coil.

Since the electric field is curly, an electron can keep gaining more
and more energy by circling through it again and again. 
Thus the
output voltage can be controlled by changing the number of coils
of wire on the output side. Changing the number of coils on the input
side also has an effect (homework problem \ref{hw:transformer}).

In any case, conservation of energy guarantees
that the amount of power on the output side must equal the
amount  put in originally, $I_{in}V_{in} =  I_{out}V_{out}$,
so no matter what factor the voltage is reduced by, the current is
increased by the same factor.  
\end{eg}

\startdqs

\begin{dq}
Suppose the bar magnet in figure \figref{generator} on page \pageref{fig:generator}
has a magnetic field pattern that emerges
from its top, circling around and coming back in the bottom.
This field is created by electrons orbiting atoms inside the magnet.
Are these atomic currents clockwise or counterclockwise as seen from above?
In what direction is the current flowing in the circuit?

We have a circling atomic current inside the circling current in the wires.
When we have two circling currents like this, they will make torques
on each other that will tend to align them in a certain way. 
Since currents in the same direction attract one another, which way
is the torque made by the wires on the bar magnet?
Verify that due to this torque,
mechanical work has to be done in order to crank the generator.
\end{dq}

<% end_sec() %>

<% begin_sec("Why induction?") %>

Faraday's results leave us in the dark about several things:\label{inductionquestions}
\begin{itemize}
        \item They don't explain \emph{why} induction effects occur.
        \item The relationship $\Gamma_E \propto -\partial B/\partial t$
                tells us that a changing magnetic field creates an electric field
                in the surrounding region of space, but the phrase ``surrounding
                region of space'' is  vague, and needs to be made mathematical.
        \item Suppose that we can make the ``surrounding region of space'' idea more well defined.
                We would then want to know the proportionality constant that has been
                hidden by the $\propto$ symbol. Although experiments like Faraday's
                could be used to find a numerical value for this constant, we would like to
                know why it should have that particular value.
\end{itemize}

<% marg(66) %>
<%
  fig(
    'alternator',
    %q{%
      It doesn't matter whether it's the coil or the permanent
              magnet that spins. Either way, we get a functioning generator.
    }
  )
%>
<% end_marg %>

We can get some guidance from the example of a car's alternator (which just means generator), referred
to in the self-check on page \pageref{sc:alternator}. To keep things conceptually
simple, I carefully avoided mentioning that in a real car's alternator, it isn't
actually the permanent magnet that spins. The coil is what spins. The choice of
design \figref{alternator}/1 or \figref{alternator}/2 is merely a matter of engineering
convenience, not physics. All that matters is the relative motion of the two objects.

This is highly suggestive. As discussed at the beginning of this chapter, magnetism
is a relativistic effect. From arguments about relative motion, we concluded that
moving electric charges create magnetic fields. Now perhaps we can use
reasoning with the same flavor to show that changing magnetic fields produce curly electric fields.
Note that figure \figref{alternator}/2 doesn't even require induction. The protons and
electrons in the coil are moving through a magnetic field, so they experience forces.
The protons can't flow, because the coil is a solid substance, but the electrons
can, so a current is induced.\footnote{Note that the magnetic field never does work on a charged
particle, because its force is perpendicular to the motion; the electric power is
actually coming from the mechanical work that had to be done to spin the coil.
Spinning the coil is more difficult due to the presence of the magnet.}

Now if we're convinced that figure \figref{alternator}/2 produces a current in the
coil, then it seems very plausible that the same will happen in figure  \figref{alternator}/1,
which implies the existence of induction effects. But this example involves circular motion,
so it doesn't quite work as a way of proving that induction exists. When we say
that motion is relative, we only mean straight-line motion, not circular motion.

A more ironclad relativistic argument comes from the arrangement shown in figure
\figref{inductionrel}. This is also a generator --- one that is impractical,
but much easier to understand.

Flea 1 doesn't believe in this
modern foolishness about induction. She's sitting on the bar magnet, which to her is
obviously at rest. As the square wire loop is dragged away from her and the magnet,
its protons experience a force out of the page, because the cross product
$\vc{F}=q\vc{v}\times\vc{B}$ is out of the page. The electrons, which are negatively
charged, feel a force into the page. The conduction electrons are free to move, but the
protons aren't. In the front and back sides of the loop, this force is perpendicular
to the wire. In the right and left sides, however, the electrons are free to respond to the force.
Note that the magnetic field is weaker on the right side. It's as though we had
two pumps in a loop of pipe, with the weaker pump trying to push in the opposite direction; the
weaker pump loses the argument.\footnote{If the pump analogy makes you uneasy, consider what would happen if all the electrons
moved into the page on both sides of the loop. We'd end up with a net negative charge at the
back side, and a net positive charge on the front. This actually would happen in the first
nanosecond after the loop was set in motion. This buildup of charge would start to quench
both currents due to electrical forces,
but the current in the right side of the wire, which is driven by the weaker
magnetic field, would be the first to stop. Eventually, an equilibrium will be reached
in which the same amount of current is flowing at every point around the loop, and no more
charge is being piled up.}
We get a current that circulates around the 
loop.\footnote{The wire is not a perfect conductor, so this current produces
heat. The energy required to produce this heat comes from the hands, which are doing
mechanical work as they separate the magnet from the loop.} There
is no induction going on in this frame of reference; the forces that cause the current are
just the ordinary magnetic forces experienced by any charged particle moving through
a magnetic field. 

<% marg(80) %>
<%
  fig(
    'inductionrel',
    %q{A generator that works with linear motion.}
  )
%>
<% end_marg %>

Flea 2 is sitting on the loop, which she considers to be at rest.
In her frame of reference, it's the bar magnet that is moving. Like flea 1, she
observes a current circulating around the loop, but unlike flea 1, she
cannot use magnetic forces to explain this current. As far as she is concerned, the
electrons were initially at rest. Magnetic forces are forces between moving charges
and other moving charges, so a magnetic field can never accelerate a charged particle
starting from rest. A force that accelerates a charge from rest can only be an
\emph{electric} force, so she is forced to conclude that there is an electric field
in her region of space. This field drives electrons
around and around in circles, so it is apparently violating the loop rule --- it is
a curly field. What reason can flea 2
offer for the existence of this electric field pattern? Well, she's been noticing that
the magnetic field in her region of space has been changing, possibly because that bar
magnet over there has been getting farther away. She observes that a changing magnetic
field creates a curly electric field.

We therefore conclude that induction effects \emph{must} exist based on the fact that
motion is relative. If we didn't want to admit induction effects, we would have to
outlaw flea 2's frame of reference, but the whole idea of relative motion is that
all frames of reference are created equal, 
and there is no way to determine which one is really at rest. 


This whole line of reasoning was not available to Faraday and his contemporaries, since
they thought the relative nature of motion only applied to matter, not to electric
and magnetic fields.\footnote{They can't be blamed too much for this. As a consequence of Faraday's
work, it soon became apparent that light was an electromagnetic wave, and to reconcile
this with the relative nature of motion requires Einstein's version of relativity,
with all its subversive ideas how space and time are not absolute.} But with the advantage of
modern hindsight, we can understand in fundamental terms the facts that Faraday had
to take simply as mysterious experimental observations. For example, the 
geometric relationship shown in figure \figref{inducedegeom} follows directly
from the direction of the current we deduced in the story of the two fleas.

<% end_sec() %>

<% begin_sec("Faraday's law") %>

We can also answer the other questions posed on page \pageref{inductionquestions}.
The divide-and-conquer approach should be familiar by now. We first determine the circulation
$\Gamma_E$ in the case where the wire loop is very tiny, \figref{relfaraday}. Then we can break down
any big loop into a grid of small ones; we've already seen 
that when we make this kind of grid, the circulations add together.
Although we'll continue to talk about a physical loop of wire, as in figure
\figref{inductionrel}, the tiny loop can really be just like the edges of an Amp\`{e}rian
surface: a mathematical construct that doesn't necessarily correspond to a real object.

<% marg(50) %>
<%
  fig(
    'relfaraday',
    %q{%
      A new version of figure \figref{inductionrel} with a tiny loop. The point
              of view is above the plane of the loop. In the frame of reference where the magnetic field is
              constant, the loop is moving to the right.
    }
  )
%>
<% end_marg %>

In the close-up view shown in figure \figref{relfaraday}, the field looks simpler.
Just as a tiny part of a curve looks straight, a tiny part of this magnetic field
looks like the field vectors are just getting shorter by the same amount with each step
to the right. Writing $\der x$ for the width of the loop, we therefore have
\begin{equation*}
        B(x+\der x)-B(x)=\frac{\partial B}{\partial x}\,\der x 
\end{equation*} 
for the difference in the strength of the field between the left and right sides. In the
frame of reference where the loop is moving, a charge $q$ moving along with the loop
at velocity $v$ will experience a magnetic force $\vc{F}_B=qvB\hat{\vc{y}}$. In the frame moving along with
the loop, this is interpreted as an electrical force, $\vc{F}_E=qE\hat{\vc{y}}$. Observers in the
two frames agree on how much force there is, so in the loop's frame, we have
an electric field $\vc{E}=vB\hat{\vc{y}}$. This field is perpendicular to the front and
back sides of the loop, BC and DA, so there is no contribution to the circulation along
these sides, but there is a counterclockwise contribution to the
circulation on CD, and smaller clockwise one on AB. The result is a circulation that
is counterclockwise, and has an absolute value
\begin{align*}
        |\Gamma_E|        &= |E(x)\der y - E(x+\der x)\der y|\\
                                &= |v[B(x)-B(x+\der x)]|\der y\\
                                &= \left|v\,\frac{\partial B}{\partial x}\right|\,\der x\der y \\
                                &= \left|\frac{\der x}{\der t}\,\frac{\partial B}{\partial x}\right|\,\der x\der y \\
                                &= \left|\frac{\partial B}{\partial t}\right|\,\der A\eqquad.
\end{align*}
Using a right-hand rule, the counterclockwise
circulation is represented by pointing one's thumb up, but the vector $\partial \vc{B}/\partial t$
is down. This is just a rephrasing of the geometric relationship shown in figure 
\figref{inducedegeom} on page \pageref{fig:inducedegeom}. We can represent the opposing
directions using a minus sign,
\begin{equation*}
        \Gamma_E        = -\frac{\partial B}{\partial t}\,\der A\eqquad.
\end{equation*}
Although this derivation was carried out with everything aligned in a specific way along
the coordinate axes, it turns out that this relationship can be generalized as a vector
dot product,
\begin{equation*}
        \Gamma_E        = -\frac{\partial \vc{B}}{\partial t}\cdot\der\vc{A}\eqquad.
\end{equation*}

Finally, we can take a finite-sized loop and break down the circulation around its edges
into a grid of tiny loops. The circulations add, so we have
\begin{equation*}
        \Gamma_E        = -\sum \frac{\partial \vc{B}_j}{\partial t}\cdot\der\vc{A}_j\eqquad.
\end{equation*}
This is known as Faraday's law. (I don't recommend memorizing all these names.)
Mathematically, Faraday's law is very similar to the structure of Amp\`{e}re's law: the circulation
of a field around the edges of a surface is equal to the sum of something that points through the

If the loop itself isn't moving, twisting, or changing shape, then the area vectors
don't change over time, and we can move the derivative outside the sum, and rewrite
Faraday's law in a slightly more transparent form:
\begin{align*}
        \Gamma_E        &= -\frac{\partial}{\partial t}\sum \vc{B}_j\cdot\der\vc{A}_j \\
                                &= -\frac{\partial\Phi_B}{\partial t}
\end{align*}
A changing magnetic flux makes a curly electric field. 
You might think based on Gauss' law for magnetic fields
that $\Phi_B$ would be identically zero. However, Gauss' law only applies to surfaces that
are closed, i.e., have no edges.

        
<% self_check('faradayunits',<<-'SELF_CHECK'
Check that the units in Faraday's law work out. An easy way to
        approach this is to use the fact that $ vB$ has the same units as $E$, which
        can be seen by comparing the equations for magnetic and electric forces used above.
  SELF_CHECK
  ) %>

\begin{eg}{A pathetic generator}
\egquestion
The horizontal component of the earth's magnetic field varies from zero, at a magnetic
pole, to about $10^{-4}$ T near the equator. Since the distance from the equator to a pole
is about $10^7$ m, we can estimate, very roughly, that the horizontal component of the
earth's magnetic field typically varies by about $10^{-11}$ T/m as you go north or south.
Suppose you connect the terminals of a one-ohm lightbulb to each other with a loop of wire having
an area of 1 $\zu{m}^2$. Holding the loop so that it lies in the east-west-up-down plane,
you run straight north at a speed of 10 m/s, how much current
will flow? Next, repeat the same calculation for the surface of a neutron star.
The magnetic field on a neutron star is
typically $10^9$ T, and the radius of an average neutron star is about $10^4$ m.

\eganswer
Let's work in the frame of reference of the running person. In this frame of reference,
the earth is moving, and therefore the local magnetic field is changing in strength
by $10^{-9}$ T/s. This rate of change is almost exactly the same throughout the
interior of the loop, so we can dispense with the summation, and simply write
Faraday's law as
\begin{equation*}
        \Gamma_E        = -\frac{\partial\vc{B}}{\partial t}\cdot\vc{A}\eqquad.
\end{equation*}
Since what we estimated was the rate of change of the horizontal component, and
the vector $\vc{A}$ is horizontal (perpendicular to the loop), we can find this
dot product simply by multiplying the two numbers:
\begin{align*}
        \Gamma_E        &= (10^{-9}\ \zu{T}/\zu{s})(1\ \zu{m}^2) \\
                                &= 10^{-9}\ \zu{T}\unitdot\zu{m}^2/\zu{s}\\
                                &= 10^{-9}\ \zu{V}\\
\end{align*}
This is certainly not enough to light the bulb, and would not even be easy to
measure using the most sensitive laboratory instruments.

<% marg(60) %>
<%
  fig(
    'generatorspeed',
    %q{Example \ref{eg:generatorspeed}.}
  )
%>
<% end_marg %>

Now what about the neutron star? We'll pretend you're tough enough that its
gravity doesn't instantly crush you. The spatial variation of the magnetic field is
on the order of $(10^9\ \zu{T}/10^4\ \zu{m})=10^5\ \zu{T}/\zu{m}$.
If you can run north at the same speed of 10 m/s, then in your frame of reference there is
a temporal (time) variation of about $10^6$ T/s, and a calculation similar to the previous
one results in an emf of $10^6$ V! This isn't just strong enough to light the bulb, it's
sufficient to evaporate it, and kill you as well!

It might seem as though having access to a region of rapidly changing magnetic field
would therefore give us an infinite supply of free energy. However, the energy
that lights the bulb is actually coming from the mechanical work you do by running
through the field. A tremendous force would be required to make the wire loop move
through the neutron star's field at any significant speed.
\end{eg}

\begin{eg}{Speed and power in a generator}\label{eg:generatorspeed}
\egquestion
Figure \figref{generatorspeed} shows three graphs of the magnetic flux
through a generator's coils as a function of time. In graph 2, the generator
is being cranked at twice the frequency. In 3, a permanent magnet with double
the strength has been used. In 4, the generator is being cranked in the opposite
direction. Compare the power generated in figures 2-4 with the the original case, 1.

\eganswer
If the flux varies as $\Phi=A\sin\omega t$, then the time derivative occurring
in Faraday's law is $\partial\Phi/\partial t=A\omega\cos\omega t$. The absolute
value of this is the same as the absolute value of the emf, $\Gamma_E$. The current
through the lightbulb is proportional to this emf, and the power dissipated depends
on the square of the current ($P=I^2R$), so $P\propto A^2\omega^2$. Figures
2 and 3 both give four times the output power (and require four times the input power).
Figure 4 gives the same result as figure 1; we can think of this as a negative
amplitude, which gives the same result when squared.

\end{eg}

\begin{eg}{An approximate loop rule}\label{eg:approxlooprule}
Figure \figref{lumpedloop}/1 shows a simple RL circuit of the type
discussed in the last chapter. A current has already been established in the
coil, let's say by a battery. The battery was then unclipped from the coil,
and we now see the circuit as the magnetic field in and around the inductor
is beginning to collapse. I've already cautioned you that the loop rule doesn't
apply in nonstatic situations, so we can't assume that 
the readings on the four voltmeters add up to zero. The interesting thing is
that although they don't add up to exactly zero in this circuit, they very
nearly do. Why is the loop rule even approximately valid in this situation?

<% marg(140) %>
<%
  fig(
    'lumpedloop',
    %q{Example \ref{eg:approxlooprule}.}
  )
%>
<% end_marg %>

The reason is that the voltmeters are measuring the emf $\Gamma_E$ around
the path shown in figure \figref{lumpedloop}/2, and the stray field of the
solenoid is extremely weak out there. In the region where the meters are,
the arrows representing the magnetic field
would be too small to allow me to draw them to scale, so I have simply omitted them.
Since the field is so weak in this region, the flux through the loop
is nearly zero, and the rate of change of the flux, $\partial\Phi_B/\partial t$,
 is also nearly zero. By Faraday's law, then, the emf around this loop is nearly zero.

 Now consider figure \figref{lumpedloop}/3.
 The flux through the interior of this path is not zero, because the strong part
 of the field passes through it, and not just once but many times.
  To visualize this, imagine that we make a wire frame in this
 shape, dip it in a tank of soapy water, and pull it out, so that there is a soap-bubble
 film spanning its interior. Faraday's law refers to the rate of change of
 the flux through a surface such as this one. (The soap film  tends to assume a certain
 special shape which results in the minimum possible surface area, but Faraday's
 law would be true for any surface that filled in the loop.) In the coiled part of the
 wire, the soap makes a three-dimensional screw shape, like the shape you would get if
 you took the steps of a spiral staircase and smoothed them into a ramp.
 The loop rule is going to be strongly violated for this path. 

 We can interpret this as follows. Since the wire in the
 solenoid has a very low resistance compared to the resistances of the light bulbs,
 we can expect that the electric field along the corkscrew part of
 loop \figref{lumpedloop}/3 will be very small.
 As an electron passes through the coil, the work done on it is therefore
 essentially zero, and the true emf along the coil is zero.
 In figure \figref{lumpedloop}/1, the meter on top is therefore not
 telling us the actual emf experienced by an electron that passes through the
 coil. It is telling us the emf experienced by an electron that passes through
 the meter itself, which is a different quantity entirely. The other three
 meters, however, really do tell us the emf through the bulbs, since there are
 no magnetic fields where they are, and therefore no funny induction effects.
\end{eg}

% inductor
% lumped circuit, path, loop rule
% pop ring off
% generator that works in Earth's magnetic field, single loop

 % 
 % ----------------------------------------------------------------------------- 
 % 

<% end_sec() %>

<% end_sec() %>

<% begin_sec("Maxwell's equations",4,'maxwell') %>
\index{Maxwell's equations}

<% begin_sec("Induced magnetic fields") %>

We are almost, but not quite, done figuring out the complete set of physical
laws, called Maxwell's equations, governing electricity and magnetism. We are only
missing one more term. For clarity,
I'll state Maxwell's equations with the missing part included, and then
discuss the physical motivation and experimental evidence for sticking it in:
\begin{important}[Maxwell's equations]\index{Maxwell's equations}
For any closed surface, the fluxes through the surface are
\begin{align*}
        \Phi_E                &= 4\pi kq_{in} \qquad\qquad\qquad \text{and}\\
        \Phi_B                &= 0\eqquad.\\
\intertext{For any surface that is not closed, the circulations 
around the edges of the surface are given by}
        \Gamma_E         &= -\frac{\partial\Phi_B}{\partial t}  \qquad\qquad\qquad \text{and} \\
        c^2\Gamma_B         &= \frac{\partial\Phi_E}{\partial t}  + 4\pi k I_{through}\eqquad.
\end{align*}
\end{important}
The $\Phi_E$ equation is Gauss' law: charges make diverging electric fields.
The corresponding equation for $\Phi_B$ tells us that magnetic ``charges'' (monopoles) don't
exist, so magnetic fields never diverge. The third equation says that
changing magnetic fields induce curly electric fields, whose curliness we can measure
using the emf, $\Gamma_E$, around a closed loop.
The final equation, for $\Gamma_B$, is the only
one where anything new has been added. Without the new time derivative term,
this equation would simply be Amp\`{e}re's law. (I've chosen to move the $c^2$ over
to the left because it simplifies the writing, and also because it more clearly
demonstrates the analogous roles played by charges and currents in the
$\Phi_E$ and $\Gamma_B$ equations.)

This new $\partial\Phi_E/\partial t$ term says that just as a changing magnetic field
can induce a curly electric field, a changing electric field can induce a curly magnetic field.
Why should this be so? The following examples show that Maxwell's equations would not
make sense in general without it.

<% marg(180) %>
<%
  fig(
    'young-maxwell',
    %q{James Clerk Maxwell (1831-1879)}
  )
%>

\spacebetweenfigs
%

<%
  fig(
    'bmystery',
    %q{Where is the moving charge responsible for this magnetic field?}
  )
%>
<% end_marg %>

Figure \figref{bmystery} shows a mysterious curly magnetic field. Magnetic fields
are supposed to be made by moving charges, but there don't seem to be any moving charges
in this landscape. Where are they? One reasonable guess would be that they're behind
your head, where you can't see them. Suppose there's a positively charged particle
about to hit you in the back of the head. This particle is like a current going into
the page. We're used to dealing with currents made by many charged particles, but logically
we can't have some minimum number that would qualify as a current. This is not a static
current, however, because the current at a given point in space is not staying the same
over time. If the particle is pointlike, then it takes zero time to pass any particular
location, and the current is then infinite at that point in space. A moment later, when the
particle is passing by some other location, there will be an infinite current there, and
zero current in the previous location.
If this single particle qualifies as a current, then
it should be surrounded by a curly magnetic field, just like any other current.\footnote{One
way to prove this rigorously is that in a frame of reference where the particle is
at rest, it has an electric field that surrounds it on all sides.
If the particle has been moving with constant velocity for a long time, then
this is just an ordinary Coulomb's-law field, extending off to very large distances, since
disturbances in the field ripple outward at the speed of light. In a frame where the
particle is moving, this pure electric field is experienced instead as a combination
of an electric field and a magnetic field, so the magnetic field must exist throughout
the same vast region of space.}

<% marg(50) %>
<%
  fig(
    'bmysterymaxw',
    %q{An Amp\`{e}rian surface superimposed on the landscape.}
  )
%>
<% end_marg %>

This explanation is simple and reasonable, but how do we know it's correct?
Well, it makes another prediction, which is that the positively charged particle
should be making an electric field as well. Not only that, but if it's headed for the
back of your head, then it's getting closer and closer, so the electric field should
be getting stronger over time. But this is exactly what Maxwell's equations
require. There is no current $I_{through}$ piercing the Amp\`{e}rian surface shown in
figure \figref{bmysterymaxw}, so Maxwell's equation for $\Gamma_B$ becomes
$c^2\Gamma_B = \partial\Phi_E/\partial t$. The only reason for an electric field
to change is if there are charged particles making it, and those charged particles
are moving. When charged particles are moving, they make magnetic fields as well.

Note that the above example is also sufficient to prove the positive sign
of the $\partial\Phi_E/\partial t$ term in Maxwell's equations, which is
different from the negative sign of Faraday's $-\partial\Phi_B/\partial t$ term.

The addition of the $\partial\Phi_E/\partial t$ term has an even deeper and more
important physical meaning. With the inclusion of this term, Max\-well's equations
can describe correctly the way in which disturbances in the electric and magnetic
fields ripple outwards at the speed of light. Indeed, Maxwell was the first human
to understand that light was in fact an electromagnetic wave. Legend has it that
 it was on a starry night that he first realized this implication of his equations.
 He went for a walk with his wife, and told her she was the only other person in
 the world who really knew what starlight was.

<% marg(78) %>
<%
  fig(
    'throughhoop',
    %q{An electron jumps through a hoop.}
  )
%>

\spacebetweenfigs
%

<%
  fig(
    'diaphragm',
    %q{An alternative Amp\`{e}rian surface.}
  )
%>
<% end_marg %>

 To see how the $\partial\Phi_E/\partial t$ term relates to electromagnetic waves,
 let's look at an example where we would get nonsense without it.
 Figure \figref{throughhoop} shows an electron that sits just on one side
 of an imaginary Amp\`{e}rian surface, and then hops through it at some randomly chosen moment.
 Unadorned with the  $\partial\Phi_E/\partial t$ term, Maxwell's equation
 for $\Gamma_B$ reads as
  $c^2\Gamma_B         = 4\pi k I_{through}$, which is Amp\`{e}re's law. 
  If the electron is a pointlike particle, then
  we have an infinite current $I_{through}$ at the moment when it pierces the
  imaginary surface, and zero current at all other times. An infinite magnetic
  circulation $\Gamma_B$ can only be produced by an infinite magnetic field, so
  without the $\partial\Phi_E/\partial t$ term, Maxwell's equations predict nonsense:
  the edge of the surface would experience an
   infinite magnetic field at one instant, and zero magnetic field at all other times.
  Even if the infinity didn't upset us, it doesn't make sense that anything special
  would happen at the moment the electron passed through the surface, because the
  surface is an imaginary mathematical construct. We could just as well have chosen
  the curved surface shown in figure \figref{diaphragm}, which the electron never crosses at all.
We are already clearly getting nonsensical results by omitting the $\partial\Phi_E/\partial t$ term,
and this shouldn't surprise us because Amp\`{e}re's law only applies to statics.
More to the point, Amp\`{e}re's law doesn't have time in it, so it predicts that
this effect is instantaneous. According to Amp\`{e}re's law, we could send Morse code 
signals by wiggling the electron back and forth, and these signals would be received
at distant locations instantly, without any time delay at all. This contradicts the
theory of relativity, one of whose predictions is that information cannot be transmitted
at speeds greater than the speed of light.

\startdqs

\begin{dq}
Induced magnetic fields were introduced in the text via the
imaginary landscape shown in figure \figref{bmystery} on
page \pageref{fig:bmystery}, and I argued that the
magnetic field could have been produced by a positive charge
coming from behind your head. This is a specific assumption
about the \emph{number} of charges (one), the \emph{direction} of
motion, and the \emph{sign} of the charge. What are some other
scenarios that could explain this field? 
\end{dq}

 % ----------------------------------------------------------------------- 

<% end_sec() %>

<% begin_sec("Light waves") %>
\index{wave!light}\index{light!electromagnetic wave}\index{wave!electromagnetic}\index{electromagnetic wave}

<% marg(0) %>
<%
  fig(
    'maxwellwave',
    %q{A magnetic field in the form of a sine wave.}
  )
%>

\spacebetweenfigs
%

<%
  fig(
    'maxwavecirc',
    %q{%
      The wave pattern is curly. For example, the circulation around
              this reactangle is nonzero and counterclockwise.
    }
  )
%>
<% end_marg %>

We could indeed send signals using this scheme, and the signals would \emph{be}
a form of light. A radio transmitting antenna, for instance, is simply a device
for whipping electrons back and forth at megahertz frequencies. Radio waves are
just like visible light, but with a lower frequency. With the addition of the
$\partial\Phi_E/\partial t$ term, Maxwell's equations are capable of describing
electromagnetic waves. It would be possible to use
Maxwell's equations to calculate the pattern of the electric and magnetic fields
rippling outward from a single electron that fidgets at irregular intervals,
but let's pick a simpler example to analyze.

The simplest wave pattern is
 a sine wave like the one shown in figure \figref{maxwellwave}. Let's assume
 a magnetic field of this form, and see what Maxwell's equations tell us about it.
 If the wave is traveling through empty space, then there are no charges or currents
 present, and Maxwell's equations become
\begin{align*}
        \Phi_E                &= 0 \\
        \Phi_B                &= 0 \\
        \Gamma_E         &= -\frac{\partial\Phi_B}{\partial t} \\
        c^2\Gamma_B         &= \frac{\partial\Phi_E}{\partial t}\eqquad.
\end{align*}

The equation $\Phi=0$ has already been verified for this type of
wave pattern in example \ref{eg:divsine} on page \pageref{eg:divsine}.
Even if you haven't learned the techniques from that section, it should
be visually plausible that this field pattern doesn't diverge or converge
on any particular point.



<% begin_sec("Geometry of the electric and magnetic fields") %>

The equation $c^2\Gamma_B=\partial\Phi_E/\partial t$ tells us that there can be
no such thing as a purely magnetic wave. The wave pattern clearly does have
a nonvanishing circulation around the edge of the surface suggested in figure
\figref{maxwavecirc},
so there must be an electric flux through the surface.
This magnetic field pattern must be intertwined with an electric field
pattern that fills the same space. There is also no
way that the two sides of the equation could stay synchronized with each other unless
the electric field pattern is also a sine wave, and one that has the same
wavelength, frequency, and velocity. Since the electric field is making a flux
through the indicated surface, it's plausible that the electric field vectors
lie in a plane perpendicular to that of the magnetic field vectors. The resulting
geometry is shown in figure \figref{emwave-with-handedness}. Further justification for this
geometry is given later in this subsection.

<%
  fig(
    'emwave-with-handedness',
    %q{The geometry of an electromagnetic wave.},
    {
      'width'=>'wide'
    }
  )
%>

<% marg(50) %>
<%
  fig(
    'maxlong',
    %q{An impossible wave pattern.}
  )
%>
<% end_marg %>

One feature of figure \figref{emwave-with-handedness} that is easily justified is that
the electric and magnetic fields are  perpendicular not only to each other,
but also to the direction of propagation of the wave.
In other words, the vibration is sideways, like people in a stadium ``doing
the wave,'' not
lengthwise, like the accordion pattern in figure \figref{maxlong}. (In standard wave terminology, we say that the
wave is transverse, not longitudinal.) The wave pattern in figure
\figref{maxlong} is impossible, because it diverges from the middle. For
virtually any choice of Gaussian surface, the magnetic and electric fluxes would
be nonzero, contradicting the
equations $\Phi_B=0$ and $\Phi_E=0$.\footnote{Even if the fields can't be parallel to the direction of
propagation, one might wonder whether they could form some angle other than
90 degrees with it. No. One proof is given on page
\pageref{lightmom}. A alternative argument, which is simpler but more esoteric,
 is that if there was such a pattern, then
there would be some other frame of reference in which it would look like
figure \figref{maxlong}.}

\begin{eg}{Reflection}\label{eg:em-wave-refl-conductor}
The wave in figure \figref{em-wave-refl-conductor} hits a silvered mirror.
The metal is a good conductor, so it has constant voltage throughout, and
the electric field equals zero inside it: the wave
doesn't penetrate and is 100\%
reflected. If the electric field is to be zero at the surface as well, the reflected wave must have
its electric field inverted (p.~\pageref{wave-inversion}), so that the incident and reflected
fields cancel there.

But the magnetic field of the reflected wave is \emph{not} inverted. This is because the reflected
wave has to have the correct right-handed relationship between the fields and the direction of
propagation.
\end{eg}

<% marg(50) %>
<%
  fig(
    'em-wave-refl-conductor',
    %q{Example \ref{eg:em-wave-refl-conductor}. The incident and reflected waves are drawn offset from
       each other for clarity, but are actually on top of each other so that their fields superpose.}
  )
%>
<% end_marg %>

<% end_sec() %>

<% begin_sec("Polarization") %>

\index{polarization}

Two electromagnetic waves traveling in the same direction
through space can differ by having their electric and
magnetic fields in different directions, a property of the
wave called its polarization.

<% end_sec() %>

<% begin_sec("The speed of light") %>

What is the velocity of the waves described by Maxwell's equations? 
Maxwell convinced himself that light was an electromagnetic wave 
partly because his equations predicted waves
moving at the velocity of light, $c$. The only velocity that
appears in the equations is $c$, so this is fairly plausible, although a real
calculation is required in order to prove that the velocity of the waves
isn't something like $2c$ or $c/\pi$ --- or zero, which is also
$c$ multiplied by a constant!
The following discussion, leading up to a proof that electromagnetic waves
travel at $c$, is meant to be understandable even if you're
reading this book out of order,
and haven't yet learned much about waves. As always with proofs in this book,
the reason to read it isn't to convince yourself that it's true, but rather to
build your intuition. The style will be visual. In all the following figures,
the wave patterns are moving across the page (let's say to the right), and
it usually doesn't matter whether you imagine them as representing the wave's
magnetic field or its electric field, because Maxwell's equations in a vacuum have
the same form for both fields. Whichever field we imagine the figures as representing,
the other field is coming in and out of the page.

\emph{The velocity of the waves is not zero.\/} If the wave pattern was standing still
in space, then the right sides of the $\Gamma$ equations would be zero, because
there would be no change in the field over time at a particular point. But the
left sides are not zero, so this is impossible.\footnote{A young Einstein
worried about what would happen if you rode a motorcycle alongside a light
wave, traveling at the speed of light. Would the light wave have a zero
velocity in this frame of reference? The only solution lies in the theory
of relativity, one of whose consequences is that a material object like a
student or a motorcycle cannot move at the speed of light.}



\emph{The velocity of the waves is a fixed number for a given wave pattern.\/} 
Consider a typical sinusoidal wave of visible light, with
a distance of half a micrometer from one peak to the next peak. Suppose this
wave pattern provides a valid solution to Maxwell's equations when it is moving
with a certain velocity. We then know, for instance, that there \emph{cannot} be a valid
solution to Maxwell's equations in which the same wave pattern moves with double
that velocity. The time derivatives on the right sides of Maxwell's equations 
for $\Gamma_E$ and $\Gamma_B$ would
be twice as big, since an observer at a certain point in space would see
the wave pattern sweeping past  at twice the rate. But the left sides
would be the same, so the equations wouldn't equate.

\emph{The velocity is the same for all wave patterns.\/}
In other words, it isn't $0.878c$
for one wave pattern, and $1.067c$ for some other pattern. This is surprising,
since, for example, water waves with different shapes do travel at different
speeds. Similarly, even though we speak of ``the speed of sound,'' sound
waves do travel at slightly different speeds depending on their pitch and
loudness, although the differences are small unless you're talking about
cannon blasts or extremely high frequency ultrasound. To see how Maxwell's
equations give a consistent velocity, consider figure \figref{maxnondispersive}.
Along the right and left edges of the same Amp\`{e}rian
surface, the more compressed wave pattern of blue light has twice as strong a field,
so the circulations on the left sides of Maxwell's equations are
 twice as large.\footnote{Actually, this is only
exactly true of the rectangular strip is made infinitesimally thin.}
To satisfy Maxwell's equations, the time derivatives of the fields must also
be twice as large for the blue light. But this is true only if the blue light's
wave pattern is moving to the right at the \emph{same} speed as the red light's:
if the blue light pattern is sweeping over an observer with a given
velocity, then the time between peaks is half as much, like the clicking of
the wheels on a train whose cars are half the length.\footnote{You may know already
that different colors of light have different speeds when they pass through a material
substance, such as the glass or water. This is not in contradiction with what
I'm saying here, since this whole analysis is for light in a vacuum.}

<% marg(170) %>
<%
  fig(
    'maxnondispersive',
    %q{Red and blue light travel at the same speed.}
  )
%>

\spacebetweenfigs
%

<%
  fig(
    'maxlinear',
    %q{Bright and dim light travel at the same speed.}
  )
%>

\spacebetweenfigs
%

<%
  fig(
    'maxnonsinus',
    %q{A nonsinusoidal wave.}
  )
%>
<% end_marg %>

We can also check that bright and dim light, as shown in figure \figref{maxlinear},
have the same velocity. If you haven't yet learned much about waves, then this
might be surprising. A material object with more energy goes faster, but that's
not the case for waves. The circulation around the edge of the Amp\`{e}rian surface
shown in the figure is twice as strong for the light whose fields are doubled in
strength, so the left sides of Maxwell's $\Gamma$ equations are doubled. The right
sides are also doubled, because the derivative of twice a function is twice the
derivative of the original function. Thus if dim light moving with a particular
velocity is a solution, then so is bright light, provided that it has the same
velocity.

We can now see that all sinusoidal waves have the same velocity. What about
nonsinusoidal waves like the one in figure \figref{maxnonsinus}? There is a
mathematical theorem, due to Fourier, that says any function can be made by
adding together sinusoidal functions. For instance, $3\sin x-7\cos 3x$ can be
made by adding together the functions $3\sin x$ and $-7\cos 3x$, but Fourier
proved that this can be done even for functions, like figure \figref{maxnonsinus},
 that aren't obviously built
out of sines and cosines in the first place. Therefore our proof that sinusoidal
waves all have the same velocity is sufficient to demonstrate that other waves
also have this same velocity.

We're now ready to prove that this universal speed for all electromagnetic waves
is indeed $c$. Since we've already convinced ourselves that all such waves
travel at the same speed, it's sufficient to find the velocity of one wave
in particular. Let's pick the wave whose fields have magnitudes
\begin{align*}
        E &= \tilde{E}\sin(x+vt) \qquad \text{and}\\
        B &= \tilde{B}\sin(x+vt)\eqquad,
\end{align*}
which is about as simple as we can get. The peak electric field of this wave
has a strength $\tilde{E}$, and the peak magnetic field is $\tilde{B}$. 
The sine functions go through
one complete cycle as $x$ increases by $2\pi=6.28\ldots$, so the distance from
one peak of this
wave to the next --- its wavelength ---
is 6.28\ldots meters. This means that it is not a wave of visible light but
rather a radio wave (its wavelength is on
the same order of magnitude as the size of a radio antenna).
That's OK. What was glorious about Maxwell's work was that
it unified the whole electromagnetic spectrum. Light is simple. Radio waves aren't fundamentally
any different than light waves, x-rays, or gamma rays. 
\footnote{What makes them appear
to be unrelated phenomena is that we experience them through their interaction
with atoms, and atoms are complicated, so they respond to various kinds of electromagnetic waves
in complicated ways.}

The justification for putting $x+vt$ inside the sine functions is as follows.
As the wave travels through space, the whole pattern just shifts over.
The fields are zero at $x=0$, $t=0$, since the sine of zero is zero. This
zero-point of the wave pattern shifts over as time goes by; at any time $t$ its
location is given by $x+vt=0$. After one second, the zero-point is
located at $x=-(1\ \zu{s})v$. The distance it travels in one second
is therefore numerically equal to $v$, and this is exactly the concept of
velocity: how far something goes per unit time.

The  wave has to satisfy Maxwell's equations for $\Gamma_E$
and $\Gamma_B$ regardless of what Amp\`{e}rian surfaces we pick, and by applying them to
any surface, we could determine the speed of the wave. The surface shown
in figure \figref{maxwellc} turns out to result in an easy calculation:
a narrow strip of width $2\ell$ and height $h$, coinciding with the 
position of the zero-point of the field at $t=0$.

<% marg(30) %>
<%
  fig(
    'maxwellc',
    %q{%
      The magnetic field of the wave. The electric field,
              not shown, is perpendicular to the page.
    }
  )
%>
<% end_marg %>

Now let's apply the equation $c^2\Gamma_B=\partial\Phi_E/\partial t$ at $t=0$.
Since the strip is narrow, we can approximate the magnetic field using
$\sin x\approx x$, which is valid for small $x$.
The magnetic field on the right edge of the strip, at $x=\ell$, is then
$\tilde{B}\ell$, so the right edge of the strip contributes
$\tilde{B}\ell h$ to the circulation. The left edge contributes the
same amount, so the left side of Maxwell's equation is
\begin{equation*}
        c^2\Gamma_B = c^2 \cdot 2 \tilde{B}\ell h\eqquad.
\end{equation*}
The other side of the equation is
\begin{align*}
        \frac{\partial\Phi_E}{\partial t} &= \frac{\partial}{\partial t}(EA) \\
                 &= 2\ell h \frac{\partial E}{\partial t}\eqquad,\\
\intertext{where we can dispense with the usual sum because the strip is narrow and there is
no variation in the field as we go up and down the strip. The derivative 
equals $v\tilde{E}\cos(x+vt)$, and evaluating the cosine at $x=0$, $t=0$ gives}
        \frac{\partial\Phi_E}{\partial t} &= 2v \tilde{E}\ell h \\
\end{align*}
Maxwell's equation for $\Gamma_B$ therefore results in
\begin{align*}
        2c^2\tilde{B}\ell h &= 2\tilde{E}\ell h  v\\
        c^2\tilde{B} &=   v\tilde{E}\eqquad.
\end{align*}

An application of $\Gamma_E=-\partial\Phi_B/\partial t$ gives a similar result,
except that there is no factor of $c^2$
\begin{equation*}
        \tilde{E} =   v \tilde{B}\eqquad.
\end{equation*}
(The minus sign simply represents the
right-handed relationship of the fields relative to their direction of propagation.)

Multiplying these last two equations by each other, we get
\begin{align*}
        c^2\tilde{B}\tilde{E} &=   v^2\tilde{E}\tilde{B} \\
        c^2 &=   v^2 \\
        v &=   \pm c\eqquad.
\end{align*} 
This is the desired result.
(The plus or minus sign shows that the wave can travel in either direction.)

As a byproduct of this calculation, we can find
the relationship between the strengths of the electric and magnetic fields in
an electromagnetic wave. If, instead of multiplying the equations
$c^2\tilde{B} =   v \tilde{E}$ and $\tilde{E} =   v \tilde{B}$,
we divide them, we can easily show that $\tilde{E}=c\tilde{B}$.

%

<%
  fig(
    'em-spectrum',
    %q{The electromagnetic spectrum.},
    {
      'width'=>'wide',
      'sidecaption'=>true
    }
  )
%>

Figure \figref{em-spectrum} shows the complete spectrum of light waves.
The wavelength $\lambda$ (number of meters per cycle) and frequency $f$
(number of cycles per second) are related by the
equation $c=f\lambda$.
Maxwell's equations predict that all light waves have the same structure,
regardless of wavelength and frequency, so even though radio and x-rays, for example,
hadn't been discovered, Maxwell predicted that such waves would have to exist.
Maxwell's 1865 prediction passed an important test in 1888, when
Heinrich Hertz\index{Hertz!Heinrich} published the results of experiments in which he showed
that radio waves could be manipulated in the same ways as visible light waves. Hertz
showed, for example, that radio waves could be reflected from a flat surface, and
that the directions of the reflected and incoming waves were related in the same
way as with light waves, forming equal angles with the surface. Likewise,
light waves can be focused with a curved, dish-shaped mirror, and Hertz demonstrated
the same thing with radio waves using a metal dish.

<% end_sec() %>

<% begin_sec("Momentum of light waves") %>
\label{lightmom}\index{light!momentum of}\index{momentum!of light}
        A light wave consists of electric and magnetic fields, and fields contain energy.
        Thus a light wave carries energy with it when it travels from one place to another.
        If a material object has kinetic energy and moves from one place to another, it must
        also have momentum, so it is logical to ask whether light waves have momentum as well.
        It can be proved based on relativity\footnote{See problem \ref{hw:ultrarelativistic} on p.~\pageref{hw:ultrarelativistic},
        or example \ref{eg:light-p-from-four-vector} on p.~\pageref{eg:light-p-from-four-vector}.} that it does, and that the momentum and energy
        are related by the equation $U=p/c$, where $p$ is the magnitude of the momentum
        vector, and $U=U_e+U_m$ is the
        sum of the energy of the electric and magnetic fields.
        We can now demonstrate this without explicitly referring to relativity,
        and connect it to the specific
        structure of a light wave.

The energy density of a light wave is related to the magnitudes
of the fields in a specific way --- it depends on the squares of their magnitudes,
$E^2$ and $B^2$, which are the same as the dot products $\vc{E}\cdot\vc{E}$
and $\vc{B}\cdot\vc{B}$. We argued on page \pageref{sec:fieldenergy} that since
energy is a scalar, the only possible expressions for the energy densities of the
fields are dot products like these, multiplied by some constants. This is because
the dot product is the only mathematically sensible way of multiplying two vectors
to get a scalar result. (Any other way violates the symmetry of space itself.)

How does this relate to momentum? Well, we know that 
if we double the strengths of the fields
in a light beam, it will have four times the energy, because the energy depends
on the square of the fields. But we then know that this quadruple-energy light beam
must have quadruple the momentum as well. If there wasn't this kind of consistency
between the momentum and the energy, then we could violate conservation of momentum
by combining light beams or splitting them up. We therefore know that the momentum
density of a light beam must depend on a field multiplied by a field.
Momentum, however, is a vector, and there is only one physically meaningful
way of multiplying two vectors to get a vector result, which is the cross product (see
page \pageref{misc:uniquexproof}). The momentum density can therefore only depend
on the cross products $\vc{E}\times\vc{E}$, $\vc{B}\times\vc{B}$, and
$\vc{E}\times\vc{B}$. But the first two of these are zero, since the cross product
vanishes when there is a zero angle between the vectors. Thus the momentum per unit
volume must equal $\vc{E}\times\vc{B}$ multiplied by some constant,
\begin{equation*}
        \der\vc{p} = (\text{constant})\vc{E}\times\vc{B}\,\der v
\end{equation*}
This predicts
something specific about the direction of propagation of a light wave: it must be along
the line perpendicular to the electric and magnetic fields. We've already seen that
this is correct, and also that the electric and magnetic fields are perpendicular to each
other. Therefore this cross product has a magnitude
\begin{align*}
        |\vc{E}\times\vc{B}| &=|\vc{E}||\vc{B}|\sin 90\degunit \\
                                                 &=|\vc{E}||\vc{B}| \\
                                                 &=\frac{|\vc{E}|^2}{c}=c|\vc{B}|^2\eqquad,
\end{align*}
where in the last step the relation $|\vc{E}|=c|\vc{B}|$ has been used.

We now only need to find one physical example in order to fix the constant of
proportionality. Indeed, if we didn't know relativity, it would be possible to
believe that the constant of proportionality was zero! The simplest example of which I
know is as follows. Suppose a piece of wire of length $\ell$ is bathed in electromagnetic waves
coming in sideways,
and let's say for convenience that this is a radio wave, with a wavelength that is large compared
to $\ell$, so that the fields don't change significantly across the length of the wire.
Let's say the electric field of the wave happens to be aligned with the wire. Then there
is an emf between the ends of the wire which equals $E\ell$, and since the wire is small
compared to the wavelength, we can pretend that the field is uniform, not curly, in which
case voltage is a well-defined concept, and 
this is equivalent to a voltage difference $\Delta V=E\ell$ between the ends of the wire.
The wire obeys Ohm's law, and a current flows in response to the wave.\footnote{This current
will soon come to a grinding halt, because we don't have a complete circuit, but let's
say we're talking about the first picosecond during which the radio wave
encounters the wire. This is why real radio antennas are \emph{not} very short compared
to a wavelength!}
Equating the expressions $\der U/\der t$ and $I\Delta V$ for the power dissipated by
ohmic heating, we have
\begin{equation*}
        \der U = IE\ell \der t
\end{equation*}
for the energy the wave transfers to the wire in a time interval $\der t$.

<% marg(70) %>
<%
  fig(
    'light-momentum',
    'A classical calculation of the momentum of a light wave. An antenna of length $\ell$ is bathed in
     an electromagnetic wave. The black arrows represent the electric field, the white circles the magnetic
     field coming out of the page. The wave is traveling to the right.'
  )
%>
<% end_marg %>

 Note that although some electrons have been set in motion in the wire,
we haven't yet seen any momentum transfer, since the protons are experiencing the same
amount of electric force in the opposite direction. However, the electromagnetic wave also
has a magnetic field, and a magnetic field transfers momentum to (exerts a force on)
a current. This is only a force on the electrons, because they're what make the current.
The magnitude of this force equals $\ell IB$ (homework problem \ref{hw:forcebetweentwowires}),
and using the definition of force, $\der\vc{p}/\der t$, we find for the magnitude
of the momentum transferred:
\begin{equation*}
        \der p = \ell IB \der t 
\end{equation*}

We now know both the amount of energy and the amount of momentum that the wave
has lost by interacting with the wire. Dividing these two equations, we find
\begin{align*}
        \frac{\der p}{\der U} &= \frac{B}{E} \\
                        &= \frac{1}{c}\eqquad,
\end{align*}
which is what we expected based on relativity.
This can now be restated in the form
$\der\vc{p} = (\text{constant})\vc{E}\times\vc{B}\,\der v$
(homework problem \ref{hw:poynting}).

<% marg(80) %>
<%
  fig(
    'nichols-radiometer',          
    %q{A simplified drawing of the 1903 experiment by Nichols and Hull that verified the predicted momentum  
       of light waves. Two circular mirrors were hung from a fine quartz fiber, inside an evacuated  
       bell jar. A 150 mW beam of light was shone on one of the mirrors for 6 s, producing a tiny rotation,  
       which was measurable by an optical lever (not shown). The force was within 0.6\%
       of the theoretically predicted value    
       (problem \ref{hw:ultrarelativistic} on p.~\pageref{hw:ultrarelativistic}) 
       of $0.001\ \mu\nunit$.\index{Nichols-Hull experiment on momentum of light}
       For comparison, a short clipping of a single human hair weighs $\sim 1\ \mu\nunit$.}
  )
%>
<% end_marg %>

Note that although the equations $p=U/c$ and $\der\vc{p} = (\text{constant})\vc{E}\times\vc{B}\,\der v$
are consistent with each other for a sine wave, they are not consistent with
each other in general. The relativistic argument leading up to $p=U/c$ assumed
that we were only talking about a single thing traveling in a single direction,
whereas no such assumption was made in arguing for the $\vc{E}\times\vc{B}$ form.
For instance, if two light beams of equal strength are traveling through one another,
going in opposite directions, their total momentum is zero, which is consistent with the
$\vc{E}\times\vc{B}$ form, but not with $U/c$.

Some examples were given in chapter \ref{ch:3} of situations where it actually matters
that light has momentum. Figure \figref{nichols-radiometer} shows the first
confirmation of this fact in the laboratory.

<% end_sec() %>

<% begin_sec("Angular momentum of light waves") %>
\index{light!angular momentum of}\index{angular momentum!of light}
        For completeness, we note that since light carries momentum, it must also be possible for
        it to have angular momentum. If you've studied chemistry, here's an example of why
        this can be important. You know that electrons in atoms can exist in states labeled
        s, p, d, f, and so on. What you might not have realized is that these are
        angular momentum labels. The s state, for example, has zero angular momentum.
        If light didn't have angular momentum, then, for example, it wouldn't be possible for a hydrogen
        atom in a p state to change to the lower-energy s state by emitting light. Conservation
        of angular momentum requires that the light wave carry away all the angular momentum
        originally possessed by the electron in the p state, since in the s state it has none.

<% end_sec() %>

<% end_sec() %>

\startdqs

<% marg(150) %>
<%
  fig(
    'dq-field-momentum',
    %q{Discussion question \ref{dq:field-momentum}.},
    {'anonymous'=>true}
  )
%>

\spacebetweenfigs

<%
  fig(
    'dq-gap-in-wire',
    %q{Discussion question \ref{dq:dq-gap-in-wire}.},
    {'anonymous'=>true}
  )
%>

\spacebetweenfigs

<%
  fig(
    'maxwellwave-gray',
    %q{Discussion questions \ref{dq:direction-of-propagation} and \ref{dq:move-with-wave}.},
    {'anonymous'=>true}
  )
%>
<% end_marg %>

\begin{dq}\label{dq:field-momentum}
Positive charges 1 and 2 are moving as shown. What electric and magnetic forces do they exert on each other?
What does this imply for conservation of momentum?
\end{dq}

\begin{dq}\label{dq:dq-gap-in-wire}
1. The figure shows a line of charges moving to the right, creating a current $I$. An Amp\`{e}rian
surface in the form of a disk has been superimposed. Use Maxwell's equations to
find the field $B$ at point P.\\
2. A tiny gap is chopped out of the line of charge. What happens when this gap is directly underneath the point P?
\end{dq}

\begin{dq}\label{dq:direction-of-propagation}
The diagram shows an electric field pattern frozen at one moment in time. Let's imagine
that it's the electric part of an electromagnetic wave. Consider four possible directions in which
it could be propagating: left, right, up, and down. Determine whether each of these is consistent
with Maxwell's equations. If so, infer the direction of the magnetic field.
\end{dq}

\begin{dq}\label{dq:move-with-wave}
Discuss what happens to the wave pattern shown in the diagram if we switch to a
frame of reference moving along with the wave.
\end{dq}

<% end_sec %>

<% begin_sec("Electromagnetic properties of materials",4) %>

Different types of matter have a variety of useful electrical and magnetic properties. Some are conductors, and some are insulators.
Some, like iron and nickel, can be magnetized, while others have useful electrical properties, e.g., dielectrics, discussed
qualitatively in the discussion question on page \pageref{dq:dielectric}, which allow us to make capacitors with much higher
values of capacitance than would otherwise be possible. We need to organize our knowledge about the properties that materials
can possess, and see whether this knowledge allows us to calculate anything useful with Maxwell's equations.

<% begin_sec("Conductors") %>

A perfect conductor, such as a superconductor, has no DC electrical resistance. It is not possible to have a static electric field
inside it, because then charges would move in response to that field, and the motion of the charges would tend to reduce the field,
contrary to the assumption that the field was static. Things are a little different at the surface of a perfect conductor than on
the interior. We expect that any net charges that exist on the conductor will spread out under the influence of their mutual
repulsion, and settle on the surface. As we saw in chapter \ref{ch:efield}, Gauss's law requires that the fields on the two
sides of a sheet of charge have $|\vc{E}_{\perp,1}-\vc{E}_{\perp,2}|$ proportional to the surface charge density, and since the field inside
the conductor is zero, we infer that there can be a field on or immediately outside the conductor, with a nonvanishing component
perpendicular to the surface. The component of the field parallel to the surface must vanish, however, since otherwise it would
cause the charges to move along the surface.

On a hot summer day, the reason the sun feels warm on your skin is that the oscillating fields of the light waves excite currents
in your skin, and these currents dissipate energy by ohmic heating. In a perfect conductor, however, this could never happen, because
there is no such thing as ohmic heating.
Since electric fields can't penetrate a perfect conductor, we also know that an electromagnetic wave can never pass into one.
By conservation of energy, we know that the wave can't just vanish, and if the energy can't be dissipated as heat, then the only
remaining possibility is that all of the wave's energy is reflected. This is why metals, which are good electrical conductors,
are also highly reflective. They are not \emph{perfect} electrical conductors, however, so they are not perfectly reflective.
The wave enters the conductor, but immediately excites oscillating currents, and these oscillating currents dissipate the energy
both by ohmic heating and by reradiating the reflected wave. Since the parts of Maxwell's equations describing radiation have
time derivatives in them, the efficiency of this reradiation process depends strongly on frequency. When the frequency is high
and the material is a good conductor, reflection predominates, and is so efficient that the wave only penetrates to a very
small depth, called the skin depth.\index{skin depth}
In the limit of poor conduction and low frequencies, absorption predominates, and the
skin depth becomes much greater. In a high-frequency AC circuit, the skin depth in a copper wire is very small, and therefore
the signals in such a circuit are propagated entirely at the surfaces of the wires. In the limit of low frequencies, i.e., DC,
the skin depth approaches infinity, so currents are carried uniformly over the wires' cross-sections.

We can quantify how well a particular material conducts electricity. We know that the resistance of a wire is proportional
to its length, and inversely proportional to its cross-sectional area. The constant of proportionality is $1/\sigma$, where $\sigma$ (not the
same $\sigma$ as the surface charge density) is called the electrical conductivity.\index{conductivity}
Exposed to an electric field $\vc{E}$, a conductor responds with a current per unit cross-sectional area $\vc{J}=\sigma\vc{E}$.
The skin depth is proportional to $1/\sqrt{f\sigma}$, where $f$ is the frequency of the wave.

<% marg(0) %>
<%
  fig(
    'dielectric2',
    %q{A capacitor with a dielectric between the plates.}
  )
%>
<% end_marg %>

<% end_sec() %>

<% begin_sec("Dielectrics") %>

A material with a very low conductivity is an insulator. Such materials are usually composed of atoms or molecules whose
electrons are strongly bound to them; since the atoms or molecules have zero total charge, their motion cannot create
an electric current. But even though they have zero charge, they may not have zero dipole moment.
Imagine such a substance filling in the space between the plates of a capacitor, as in figure \figref{dielectric2}.
For simplicity, we assume that the molecules are oriented randomly at first, \subfigref{dielectric2}{1}, and then
become completely aligned when a field is applied, \subfigref{dielectric2}{2}. The effect has been to take all of the negatively
charged black ands of the molecules and shift them upward, and the opposite for the positively charged white ends.
Where the black and white charges overlap, there is still zero net charge, but we have a strip of negative charge
at the top, and a strip of positive charge at the bottom, \subfigref{dielectric2}{3}. The effect has been to cancel
out part of the charge that was deposited on the plates of the capacitor. Now this is very subtle, because Maxwell's
equations treat these charges on an equal basis, but in terms of practical measurements, they are completely different.
The charge on the plates can be measured be inserting an ammeter in the circuit, and integrating the current over time.
But the charges in the layers at the top and bottom of the dielectric never flowed through any wires, and cannot be
detected by an ammeter. In other words, the total charge, $q$, appearing in Maxwell's equartions is actualy $q=q_{\text{free}}-q_{\text{bound}}$,
where $q_{\text{free}}$ is the charge that moves freely through wires, and can be detected in an ammeter, while $q_{bound}$ is the charge bound
onto the individual molecules, which can't. We will, however, detect the presence of the bound charges via their electric fields.
Since their electric fields partially cancel the fields of the free charges,
a voltmeter will register a smaller than expected voltage difference between the plates. If we measure $q_{\text{free}}/V$, we have a result
that is larger than the capacitance we would have expected.

Although the relationship $\vc{E}\leftrightarrow q$ between electric fields and their sources is unalterably locked in by Gauss's law,
that's not what we see in practical measurements. In this example, we can measure the voltage difference between the plates of
the capacitor and divide by the distance between them to find $\vc{E}$, and then integrate an ammeter reading to find $q_{\text{free}}$, and
we will find that Gauss's law appears not to hold. We have $\vc{E}\leftrightarrow q_{\text{free}}/(\text{constant})$, where the constant
fudge factor is greater than one. This constant is a property of the dielectric material, and tells us how many dipoles there are,
how strong they are, and how easily they can be reoriented. The conventional notation is to incorporate this fudge factor into
Gauss's law by defining an altered version of the electric field, 
\begin{equation*}
  \vc{D}=\epsilon \vc{E}\eqquad,
\end{equation*}
and to rewrite Gauss's law as
\begin{equation*}
  \Phi_D = q_{\text{in, free}}\eqquad.
\end{equation*}
The constant $\epsilon$ is a property of the material, known as its permittivity.\index{permittivity} In a vacuum, $\epsilon$ takes on a value known as
$\epsilon_\zu{o}$, defined as $1/(4\pi k)$. In a dielectric, $\epsilon$ is greater than $\epsilon_\zu{o}$.
When a dielectric is present between the plates of
a capacitor, its capacitance is proportional to $\epsilon$ (problem \ref{hw:cap-fom}).
The following table gives some sample values of the permittivities of a few substances.

\begin{tabular}{ll}
\emph{substance} & $\epsilon/\epsilon_\zu{o}$ at zero frequency\\
\hline
vacuum           & 1 \\
air              & 1.00054 \\
water            & 80 \\
barium titanate  & 1250
\end{tabular}

\noindent A capacitor with a very high capacitance is potentially a superior replacement for a battery, but until the 1990's this was
impractical because capacitors with high enough values couldn't be made, even with dielectrics having the largest known permittivities.
Such supercapactors, some with values in the kilofarad range,
are now available. Most of them do not use dielectric at all; the very high capacitance values are instead obtained by using electrodes that
are not parallel metal plates at all, but exotic
materials such as aerogels, which allows the spacing between the ``electrodes'' to be very small.

<% marg(30) %>
<%
  fig(
    'studfinder',
    %q{A stud finder is used to locate the wooden beams, or studs, that form the frame behind the wallboard. It is
       a capacitor whose capacitance changes when it is brought close to a substance with a particular permittivity.
       Although the wall is external to the capacitor, a change in capacitance is still observed, because the capacitor has
       ``fringing fields'' that extend outside the region between its plates.}
  )
%>
<% end_marg %>

Although figure \subfigref{dielectric2}{2} shows the dipoles in the dielectric being completely aligned, this is not a situation commonly
encountered in practice. In such a situation, the material would be as polarized as it could possibly be, and if the field was increased
further, it would not respond. In reality, a capacitor, for example, would normally be operated with fields that produced quite a small
amount of alignment, and it would be under these conditions that the linear relationship $\vc{D}=\epsilon\vc{E}$ would actually be
a good approximation. Before a material's maximum polarization is reached, it may actually spark or burn up.

<% self_check('withdraw-dielectric',<<-'SELF_CHECK'
Suppose a parallel-plate capacitor is built so that a slab of dielectric material can be slid in or out. (This is similar to the
way the stud finder in figure \figref{studfinder} works.) We insert the dielectric,
hook the capacitor up to a battery to charge it, and then use an ammeter and a voltmeter to observe what happens when the dielectric
is withdrawn. Predict the changes observed on the meters, and correlate them with the expected change in capacitance. Discuss the
energy transformations involved, and determine whether positive or negative work is done in removing the dielectric.
  SELF_CHECK
  ) %>

<% end_sec() %>

<% begin_sec("Magnetic materials") %>

<% begin_sec("Magnetic permeability") %>

Atoms and molecules may have magnetic dipole moments as well as electric dipole moments. Just as an electric dipole contains
bound charges, a magnetic dipole has bound currents, which come from
the motion of the electrons as they orbit the nucleus, \subfigref{permeability}{1}. Such a substance, subjected to a magnetic field, tends to align
itself, \subfigref{permeability}{2}, so that a sheet of current circulates around the externally applied field. Figure \subfigref{permeability}{3}
is closely analogous to figure \subfigref{dielectric2}{3}; in the central gray area, the atomic currents cancel out, but the atoms at the outer surface
form a sheet of bound current. However, whereas like charges repel and
opposite charges attract, it works the other way around for currents: currents in the same direction attract, and currents
in opposite directions repel. Therefore the bound currents in a material inserted inside a solenoid tend to \emph{reinforce} the
free currents, and the result is to strengthen the field. The total current is $I=I_{\text{free}}+I_{\text{bound}}$,
and we define an altered version of the magnetic field,
\begin{equation*}
  \vc{H}= \frac{\vc{B}}{\mu}\eqquad,
\end{equation*}
and rewrite Amp\`{e}re's law as
\begin{equation*}
  \Gamma_H = I_{\text{through, free}}\eqquad.
\end{equation*}
The constant $\mu$ is the permeability,\index{permeability} 
with a vacuum value of $\mu_\zu{o}=4\pi k/c^2$. Here are the magnetic permeabilities of some substances:

\begin{tabular}{ll}
\emph{substance} & $\mu/\mu_\zu{o}$ \\
\hline
vacuum           & 1 \\
aluminum         & 1.00002 \\
steel            & 700 \\
transformer iron & 4,000 \\
mu-metal         & 20,000
\end{tabular}

<% marg(175) %>
<%
  fig(
    'permeability',
    %q{The magnetic version of figure \figref{dielectric2}. A magnetically permeable material is placed at the center of a solenoid.}
  )
%>

\spacebetweenfigs

<%
  fig(
    'iron-core',
    %q{Example \ref{eg:iron-core}: a cutaway view of a solenoid.}
  )
%>
<% end_marg %>

\pagebreak[4]

\begin{eg}{An iron-core electromagnet}\label{eg:iron-core}
\egquestion A solenoid has 1000 turns of wire wound along a cylindrical core with a length of 10 cm. If
a current of 1.0 A is used, find the magnetic field inside the solenoid if the core is air, and if the
core is made of iron with $\mu/\mu_\zu{o}=4,000$.

\eganswer Air has essentially the same permability as vacuum, so using the result of example \ref{eg:amperesolenoid} on page \pageref{eg:amperesolenoid},
we find that the field is 0.013 T.

<% marg(80) %>
<%
  fig(
    'iron-core-photo',
    %q{Example \ref{eg:iron-core}: without the iron core, the field is so weak that it barely deflects the compass. With it,
       the deflection is nearly 90$\degunit$.}
  )
%>
<% end_marg %>

We now consider the case where the core is filled with iron. The original derivation in example  \ref{eg:amperesolenoid} started from
Amp\`{e}re's law, which we now rewrite as $\Gamma_H = I_{\text{through, free}}$. As argued previously, the only significant contributions
to the circulation come from line segment AB. This segment lies inside the iron, where $\vc{H}=\vc{B}/\mu$. The $\vc{H}$ field is the same as
in the air-core case, since the new form of Amp\`{e}re's law only relates  $\vc{H}$ to the current in the wires (the free current).
This means that $\vc{B}=\mu\vc{H}$ is greater by a factor of 4,000 than in the air-core case, or 52 T. This is an extremely intense
field --- so intense, in fact, that the iron's magnetic polarization would probably become saturated before we could actually get the
field that high.
\end{eg}

The electromagnet of example \ref{eg:iron-core} could also be used as an inductor, and its inductance would be proportional to
the permittivity of the core. This makes it possible to construct high-value inductors that are relatively compact.
Permeable cores are also used in transformers.

A transformer or
inductor with a permeable core does have some disadvantages, however, in certain applications.
The oscillating magnetic field induces an electric field, and because the core is typically a metal, these
currents dissipate energy strongly as heat. This behaves like a fairly large resistance in series with the coil.
Figure \figref{laminated-core} shows a method for reducing this effect. The iron core of this transformer
has been constructed out of laminated layers, which has the effect of blocking the conduction of the eddy currents.

<% marg(60) %>
<%
  fig(
    'laminated-core',
    %q{A transformer with a laminated iron core. The input and output coils are inside the paper wrapper. The
     iron core is the black part that passes through the coils at the center, and also wraps around them on the outside.}
  )
%>

\spacebetweenfigs

<%
  fig(
    'ferrite-bead',
    %q{Example \ref{eg:ferrite-bead}: ferrite beads. The top panel shows a clip-on type, while the bottom shows one built into a cable.}
  )
%>
<% end_marg %>

\begin{eg}{A ferrite bead}\label{eg:ferrite-bead}
Cables designed to carry audio signals are typically made with two adjacent conductors, such that the current flowing out through
one conductor comes back through the other one. Computer cables are similar, but usually have several such pairs bundled inside the
insulator. This paired arrangement is known as differential mode,\index{differential mode} and
has the advantage of cutting down on the reception and transmission of interference.
In terms of transmission, the magnetic field created by the outgoing current is almost exactly canceled by the field from the
return current, so electromagnetic waves are only weakly induced. In reception, both conductors are bathed in the same electric and
magnetic fields, so an emf that adds current on one side subtracts current from the other side, resulting in cancellation.

The opposite of differential mode is called common mode. In common mode, all conductors have currents flowing in the same direction.
Even when a circuit is designed to operate in differential mode, it may not have exactly equal currents in the two conductors with $I_1+I_2=0$,
meaning that current is leaking off to ground at one end of the circuit or the other. Although paired cables are relatively immune to
differential-mode interference, they do not have any automatic protection from common-mode interference.

Figure \figref{ferrite-bead} shows a device for reducing common-mode interference called a ferrite bead\index{ferrite bead}, which surrounds
the cable like a bead on a string. 
Ferrite is a magnetically permeable alloy.
In this application, the ohmic properties of the ferrite actually turn put to be advantageous.

Let's consider common-mode transmission of interference.
The bare cable has some DC resistance, but is also surrounded by a magnetic field, so it has inductance as well. This means that it behaves like
a series L-R circuit, with an impedance that varies as $R+i\omega L$, where both $R$ and $L$ are very small. When we add the ferrite bead,
the inductance is increased by orders of magnitude, but so is the resistance. 
Neither $R$ nor $L$ is actually constant with respect to frequency, but both are much greater than for the bare
cable.

Suppose, for example, that a signal is being transmitted from a digital camera to a computer via a USB cable. The camera has an
internal impedance that is on the order of 10 $\Omega$, the computer's input also has a $\sim10$ $\Omega$ impedance, and in differential
mode the ferrite bead has no effect, so the cable's impedance has its low, designed value (probably also about 10 $\Omega$, for good
impedance matching\index{impedance matching}). The signal is transmitted unattenuated from the camera to the computer, and there is
almost no radiation from the cable.

But in reality there will be a certain amount of common-mode current as well. With respect to common mode, the ferrite bead
has a large impedance, with the exact value depending on frequency, but typically on the order of 100 $\Omega$ for frequencies
in the MHz range. We now have a series circuit consisting of three impedances: 10, 100, and 10 $\Omega$. For a given emf applied
by an external radio wave, the current induced in the circuit has been attenuated by an order of magnitude, relative to its value
without the ferrite bead.

Why is the ferrite is necessary at all? Why not just insert ordinary air-core inductors in the circuit?
We could, for example, have two solenoidal coils, one in the outgoing line and one in the return line, interwound with one another
with their windings oriented so that their differential-mode fields would cancel.
There are two good reasons to prefer the ferrite bead design. One is that it allows a clip-on device like the one in the top panel
of figure \figref{ferrite-bead}, which can be added without breaking the circuit.
The other is that our circuit will inevitably have some stray capacitance, and will therefore
act like an LRC circuit, with a resonance at some frequency. 
At frequencies close to the resonant frequency,
the circuit would absorb and transmit
common-mode interference very strongly, which is exactly the opposite of the effect
we were hoping to produce. The resonance peak could be made low and broad by adding resistance in series, but this extra resistance
would attenuate the differential-mode signals as well as the common-mode ones. The ferrite's resistance, however, is actually
a purely magnetic effect, so it vanishes in differential mode.
\end{eg}

Surprisingly, some materials have magnetic permeabilities less than $\mu_\zu{o}$. This cannot be accounted for in the model
above, and although there are semiclassical arguments that can explain it to some extent, it is fundamentally a quantum mechanical effect.
Materials with $\mu>\mu_\zu{o}$ are called paramagnetic, while those with $\mu<\mu_\zu{o}$ are referred to as diamagnetic.
Diamagnetism is generally a much weaker effect than paramagnetism, and is easily masked if there is any trace of
contamination from a paramagnetic material. Diamagnetic materials have the interesting property that they are repelled from regions
of strong magnetic field, and it is therefore possible to levitate a diamagnetic object above a magnet, as in figure \figref{levitating-frog}.
\index{diamagnetism}\index{paramagnetism}

<% marg(20) %>
<%
  fig(
    'levitating-frog',
    %q{A frog is levitated diamagnetically by the nonuniform field inside a powerful magnet. Evidently frog has $\mu<\mu_\zu{o}$.}
  )
%>

\spacebetweenfigs

<%
  fig(
    'permeability-boundary',
    %q{At a boundary between two substances with $\mu_2>\mu_1$, the $\vc{H}$ field has a continuous component parallel to the
       surface, which implies a discontinuity in the parallel component of the magnetic field $\vc{B}$.}
  )
%>
<% end_marg %>

A complete statement of Maxwell's equations in the presence of electric and magnetic materials is as follows:

\begin{align*}
    \Phi_D &= q_\text{free} \\
    \Phi_B &= 0 \\
    \Gamma_E &= -\frac{\der \Phi_B}{\der t} \\
    \Gamma_H &= \frac{\der \Phi_D}{\der t} + I_\text{free}
\end{align*}

Comparison with the vacuum case shows that the speed of an electromagnetic wave moving through a substance described by
permittivity and permeability $\epsilon$ and $\mu$ is $1/\sqrt{\epsilon\mu}$. For most substances, $\mu\approx\mu_\zu{o}$, and
$\epsilon$ is highly frequency-dependent.

Suppose we have a boundary between two substances.
By constructing a Gaussian or Amp\`{e}rian surface that extends across the boundary, we can arrive at various
constraints on how the fields must behave as me move from one substance into the other, when there are no free currents or charges present, and the fields are static.
An interesting example is the application of Faraday's law, $\Gamma_H=0$, to the case where one medium --- let's say it's air --- has a low permeability,
while the other one has a very high one. We will violate Faraday's law unless the component of the $\vc{H}$ field
parallel to the boundary is a continuous function, $\vc{H}_{\parallel,1}=\vc{H}_{\parallel,2}$. This means that if $\mu/\mu_\zu{o}$ is
very high, the component of $\vc{B}=\mu\vc{H}$ parallel to the surface will have an abrupt discontinuity, being much stronger inside
the high-permeability material. The result is that when a magnetic field enters a high-permeability material, it
tends to twist abruptly to one side, and the pattern of the field tends to be channeled through the material like water through a
funnel. In a transformer, a permeable core functions to channel more of the magnetic flux from the input coil to the output coil.
Figure \figref{eg-magnetic-shielding-sphere} shows another example, in which the effect is to shield the interior of the sphere
from the externally imposed field. Special high-permeability alloys, with trade names like Mu-Metal, are sold for this
purpose.
% In the following figure, I want this caption:
%      A hollow sphere with $\mu/\mu_\zu{o}=10$, is immersed in a uniform, externally imposed magnetic field.
%      The interior of the sphere is shielded from the field. The arrows map the magnetic field $\vc{B}$.
%      (See homework problem \ref{hw:spherical-shielding} on page \pageref{hw:spherical-shielding}.)
% But putting in the pageref causes this error: ! Missing \endcsname inserted.
%    %q{%
%      A hollow sphere with $\mu/\mu_\zu{o}=10$, is immersed in a uniform, externally imposed magnetic field.
%      The interior of the sphere is shielded from the field. The arrows map the magnetic field $\vc{B}$.
%      (See homework problem \ref{hw:spherical-shielding}, page 
%    }+pageref_workaround('hw:spherical-shielding')+'.)'

<%
  fig(
    'eg-magnetic-shielding-sphere',
    %q{%
      A hollow sphere with $\mu/\mu_\zu{o}=10$, is immersed in a uniform, externally imposed magnetic field.
      The interior of the sphere is shielded from the field. The arrows map the magnetic field $\vc{B}$.
      (See homework problem }+ref_workaround('hw:spherical-shielding')+%q{, page 
    }+pageref_workaround('hw:spherical-shielding')+'.)',
    {
      'width'=>'fullpage',
      'floatpos'=>'b'
    }
  )
%>

<% end_sec() %>

<% begin_sec("Ferromagnetism") %>

The very last magnetic phenomenon we'll discuss is probably the very first experience you ever had of magnetism.\index{ferromagnetism}
Ferromagnetism is a phenomenon in which a material tends to organize itself so that it has a nonvanishing magnetic field.
It is exhibited strongly by iron and nickel, which explains the origin of the name.

<%
  fig(
    'ferromagnetism',
    %q{%
      A model of ferromagnetism.
    },
    {
      'width'=>'wide',
      'sidecaption'=>true
    }
  )
%>

Figure \subfigref{ferromagnetism}{1} is a simple one-dimensional model of ferromagnetism. Each magnetic compass needle
represents an atom. The compasses in the chain are stable when aligned with one another, because each one's north end is
attracted to its neighbor's south end. The chain can be turned around, \subfigref{ferromagnetism}{2}, without disrupting
its organization, and the compasses do not realign themselves with the Earth's field, because their torques on one another
are stronger than the Earth's torques on them. The system has a memory. For example, if I want to remind myself that my friend's
address is 137 Coupling Ct., I can align the chain at an angle of 137 degrees. The model fails, however, as an explanation of
real ferromagnetism, because in two or more dimensions, the most stable arrangement of a set of interacting magnetic dipoles
is something more like \subfigref{ferromagnetism}{3}, in which alternating rows point in opposite directions. In this two-dimensional
pattern, every compass is aligned in the most stable way with all four of its neighbors. This shows that ferromagnetism, like
diamagnetism, has no purely classical explanation; a full explanation requires quantum mechanics.

<% marg(0) %>
<%
  fig(
    'core-memory',
    %q{Magnetic core memory.}
  )
%>

\spacebetweenfigs

<%
  fig(
    'hysteresis-curve',
    %q{A hysteresis curve.}
  )
%>
<% end_marg %>

Because ferromagnetic substances ``remember'' the history of how they were prepared, they are commonly used to store
information in computers. Figure \figref{core-memory} shows 16 bits from an ancient (ca. 1970) 4-kilobyte random-access memory,
in which each doughnut-shaped iron ``core'' can be magnetized in one of two possible directions, so that it stores
one bit of information. Today, RAM is made of transistors rather than magnetic cores, but a remnant of the old technology
remains in the term ``core dump,'' meaning ``memory dump,'' as in ``my girlfriend gave me a total core dump about her
mom's divorce.'' Most computer hard drives today do store their information on rotating magnetic platters, but the platter
technology may be obsoleted by flash memory in the near future.

The memory property of ferromagnets can be depicted on the type of graph shown in figure \figref{hysteresis-curve},
known as a hysteresis curve.\index{hysteresis} The y axis is the magnetization of a sample of the material --- a measure
of the extent to which its atomic dipoles are aligned with one another. If the sample is initially unmagnetized, 1,
and a field $H$ is externally applied, the magnetization increases, 2, but eventually becomes saturated, 3, so that
higher fields do not result in any further magnetization, 4. The external field can then be reduced, 5, and even eliminated
completely, but the material will retain its magnetization. It is a permanent magnet. To eliminate its magnetization
completely, a substantial field must be applied in the opposite direction. If this reversed field is made stronger, then
the substance will eventually become magnetized just as strongly in the opposite direction. Since the hysteresis curve is
nonlinear, and is not a function (it has more than one value of $M$ for a particular value of $B$), a ferromagnetic material
does not have a single, well-defined value of the permeability $\mu$; a value like 4,000 for transformer iron represents some
kind of a rough average.

\begin{eg}{The fluxgate compass}
The fluxgate compass is a type of magnetic compass without moving parts, commonly used on ships and aircraft.
An AC current is applied in a coil wound around a ferromagnetic core, driving the core repeatedly around a hysteresis
loop. Because the hysteresis curve is highly nonlinear, the addition of an external field such as the Earth's alters
the core's behavior. Suppose, for example, that the axis of the coil is aligned with the magnetic north-south.
The core will reach saturation more quickly when the coil's field is in the same
direction as the Earth's, but will not saturate as early in the next half-cycle, when the two fields are in opposite directions.
With the use of multiple coils, the components of the Earth's field can be measured along two or three axes, permitting the
compass's orientation to be determined in two or (for aircraft) three dimensions.
\end{eg}

<% marg(50) %>
<%
  fig(
    'fluxgate-compass',
    %q{A fluxgate compass.}
  )
%>
<% end_marg %>

\begin{eg}{Sharp magnet poles}\label{eg:sharp-magnet-poles}
Although a ferromagnetic material does not really have a single value of the magnetic permeability,
there is still a strong tendency to have $\vc{B}_\parallel\approx 0$ just outside the magnet's surface,
for the same reasons as discussed above for high-permeability substances in general. For example, if
we have a cylindrical bar magnet about the size and shape of your finger, magnetized lengthwise, then the field
near the ends is nearly perpendicular to the surfaces, while the field near the sides, although it may be
oriented nearly parallel to the surface, is very weak, so that we still have $\vc{B}_\parallel\approx 0$.
This is in close analogy to the situation for the \emph{electric} field near the surface of a conductor in
equilibrium, for which $\vc{E}_\parallel=0$. This analogy is close enough so that we can recycle much
of our knowledge about electrostatics.

For example, we saw in example \ref{eg:lightning-rod}, p.~\pageref{eg:lightning-rod},
and problem \ref{hw:lightning-rod}, p.~\pageref{hw:lightning-rod},
that charge tends to collect on the most highly curved portions of a conductor, and therefore
becomes especially dense near a corner or knife-edge. This gives us a way of making especially
intense magnetic fields. Most people would imagine that a very intense field could be made simply
by using a very large and bulky permanent magnet, but this doesn't actually work very well, because
magnetic dipole fields fall off as $1/r^3$, so that at a point near the surface,
nearly all the field is contributed by atoms near the surface. Our analogy with electrostatics suggests that
we should instead construct a permanent magnet with a sharp edge.

Figure \figref{sharp-magnet-poles} shows the cross-sectional shapes of two magnet poles used
in the historic Stern-Gerlach experiment (sec.~\ref{sec:stern-gerlach}, p.~\pageref{sec:stern-gerlach}). 
The external magnetic field is represented using field lines.
The field lines enter and exit the surfaces perpendicularly, and they are particularly dense
near the corner of the upper pole, indicating a strong field. The spreading of the field lines
indicates that the field is strongly nonuniform, becoming much weaker toward the bottom of the
gap between the poles. This strong nonuniformity was crucial for the experiment, in which the
magnets were used as part of a dipole spectrometer. See example \ref{eg:dipole-in-nonuniform-field-fancy}
and figure \figref{dipole-spectrometer} on p.~\pageref{fig:dipole-spectrometer} for an explanation of
an electric version of such a spectrometer.
\end{eg}

<% marg(50) %>
<%
  fig(
    'sharp-magnet-poles',
    %q{Example \ref{eg:sharp-magnet-poles}.}
  )
%>
<% end_marg %>

<% end_sec() %>

\backofchapterboilerplate{em}

<% end_sec() %>

<% end_sec() %>

<% begin_hw_sec %>

% *********************************************************************************
% Old visual formatting in this section had a bunch of \vspace{15}'s to make it come out right. May need to do that again,
% since new order of problems isn't so different.
% *********************************************************************************

<% begin_hw('ebforce',0) %>__incl(hw/ebforce)<% end_hw() %>

<% begin_hw('righthandmodel',0) %>__incl(hw/righthandmodel)<% end_hw() %>

<% begin_hw('moveandcurve',0) %>__incl(hw/moveandcurve)<% end_hw() %>

<% begin_hw('describemotioninb',0) %>__incl(hw/describemotioninb)<% end_hw() %>

<% begin_hw('linechargecurrent',0) %>__incl(hw/linechargecurrent)<% end_hw() %>

<% begin_hw('forcebetweentwowires') %>__incl(hw/forcebetweentwowires)<% end_hw() %>

<% begin_hw('vfilter',0) %>__incl(hw/vfilter)<% end_hw() %>

<% begin_hw('ambiguousb') %>__incl(hw/ambiguousb)<% end_hw() %>

<% begin_hw('ebnotpure') %>__incl(hw/ebnotpure)<% end_hw() %>

<% begin_hw('twowiresrepel') %>__incl(hw/twowiresrepel)<% end_hw() %>

<% begin_hw('circularorbitphoto',0) %>__incl(hw/circularorbitphoto)<% end_hw() %>

<% begin_hw('cyclotron',0) %>__incl(hw/cyclotron)<% end_hw() %>

<% begin_hw('dottodot') %>__incl(hw/dottodot)<% end_hw() %>

%

<%
  fig(
    'hw-dottodot',
    %q{Problem \ref{hw:dottodot}.},
    {
      'width'=>'wide'
    }
  )
%>

<% begin_hw('atom') %>__incl(hw/atom)<% end_hw() %>

<% begin_hw('dipole-units-proof',0) %>__incl(hw/dipole-units-proof)<% end_hw() %>

<% begin_hw('findeandb') %>__incl(hw/findeandb)<% end_hw() %>

<% begin_hw('solenoid-u-quadruple-i',0) %>__incl(hw/solenoid-u-quadruple-i)<% end_hw() %>

<% marg(0) %>
<%
  fig(
    'hw-helmholtz-coil',
    %q{Problem \ref{hw:helmholtzcoil}.}
  )
%>
<% end_marg %>

<% begin_hw('helmholtzcoil') %>__incl(hw/helmholtzcoil)<% end_hw() %>

<% marg(0) %>
<%
  fig(
    'hw-nested-wire-loops',
    %q{Problem \ref{hw:wireloops}.}
  )
%>
<% end_marg %>

<% begin_hw('wireloops') %>__incl(hw/wireloops)<% end_hw() %>

<%
  fig(
    'hw-wire-box',
    %q{Problem \ref{hw:wire-box}.},
    {
      'width'=>'wide'
    }
  )
%>

<% begin_hw('wire-box') %>__incl(hw/wire-box)<% end_hw() %>

<% begin_hw('ebexperiment',2) %>__incl(hw/ebexperiment)<% end_hw() %>

<% begin_hw('biotsavartwire') %>__incl(hw/biotsavartwire)<% end_hw() %>

<% begin_hw('sheetz') %>__incl(hw/sheetz)<% end_hw() %>

<% begin_hw('nestedsolenoids') %>__incl(hw/nestedsolenoids)<% end_hw() %>

<% marg(0) %>
<%
  fig(
    'hw-solenoid-field-on-axis',
    %q{Problem \ref{hw:solenoid-field-on-axis}.}
  )
%>
<% end_marg %>

<% begin_hw('solenoid-field-on-axis') %>__incl(hw/solenoid-field-on-axis)<% end_hw() %>

<% begin_hw('amperehalo') %>__incl(hw/amperehalo)<% end_hw() %>

<% begin_hw('amperes-law-find-i') %>__incl(hw/amperes-law-find-i)<% end_hw() %>

<% marg(0) %>
<%
  fig(
    'nautilus',
    %q{A nautilus shell is approximately a logarithmic spiral, of the type in problem \ref{hw:biot-savart-log-spiral}.}
  )
%>
<% end_marg %>

<% begin_hw('biot-savart-log-spiral') %>__incl(hw/biot-savart-log-spiral)<% end_hw() %>

<% begin_hw('tilestrip') %>__incl(hw/tilestrip)<% end_hw() %>

<% begin_hw('solenoidinductance') %>__incl(hw/solenoidinductance)<% end_hw() %>

<% begin_hw('solenoid-sex') %>__incl(hw/solenoid-sex)<% end_hw() %>

<% begin_hw('amperian-rectangle') %>__incl(hw/amperian-rectangle)<% end_hw() %>

<% marg(300) %>
<%
  fig(
    'hw-amperian-rectangle',
    %q{Problem \ref{hw:amperian-rectangle}.}
  )
%>
<% end_marg %>

<% begin_hw('transformer') %>__incl(hw/transformer)<% end_hw() %>

<% begin_hw('transformerf') %>__incl(hw/transformerf)<% end_hw() %>

<% marg(3) %>
<%
  fig(
    'hw-rolling-wire',
    %q{Problem \ref{hw:rolling-wire}.}
  )
%>
<% end_marg %>

<% begin_hw('rolling-wire') %>__incl(hw/rolling-wire)<% end_hw() %>

\pagebreak

<% begin_hw('minimum-em-force') %>__incl(hw/minimum-em-force)<% end_hw() %>

\vfill

<% marg(3) %>
<%
  fig(
    'hw-dropping-circuit',
    %q{Problem \ref{hw:dropping-circuit}.}
  )
%>
<% end_marg %>

<% begin_hw('dropping-circuit') %>__incl(hw/dropping-circuit)<% end_hw() %>

\vfill

<% begin_hw('cap-fom') %>__incl(hw/cap-fom)<% end_hw() %>

\vfill

<% begin_hw('everyday-maxwell') %>__incl(hw/everyday-maxwell)<% end_hw() %>

\pagebreak

<% begin_hw('poynting') %>__incl(hw/poynting)<% end_hw() %>

<% begin_hw('solarconstant') %>__incl(hw/solarconstant)<% end_hw() %>

<% marg(50) %>
<%
  fig(
    'circularcap',
    %q{Problem \ref{hw:circularcap}.}
  )
%>
<% end_marg %>

<% begin_hw('circularcap') %>__incl(hw/circularcap)<% end_hw() %>

<% begin_hw('surfing',2) %>__incl(hw/surfing)<% end_hw() %>

<% begin_hw('disprove-em-wave') %>__incl(hw/disprove-em-wave)<% end_hw() %>

<% begin_hw('withdraw-dielectric-open') %>__incl(hw/withdraw-dielectric-open)<% end_hw() %>

<% begin_hw('boundary-eb') %>__incl(hw/boundary-eb)<% end_hw() %>

<% begin_hw('spherical-shielding',3) %>__incl(hw/spherical-shielding)<% end_hw() %>

<% begin_hw('sandwich') %>__incl(hw/sandwich)<% end_hw() %>

<% begin_hw('mystery-magnet',2) %>__incl(hw/mystery-magnet)<% end_hw() %>

<% begin_hw('xxhat') %>__incl(hw/xxhat)<% end_hw() %>

<% begin_hw('timereversalem') %>__incl(hw/timereversalem)<% end_hw() %>

<% begin_hw('timereversalem2',2) %>__incl(hw/timereversalem2)<% end_hw() %>

<% begin_hw('bwork',2) %>__incl(hw/bwork)<% end_hw() %>

<% marg(0) %>
<%
  fig(
    'hw-biot-savart-spiral',
    %q{Problem \ref{hw:biot-savart-spiral}.}
  )
%>
<% end_marg %>

<% begin_hw('biot-savart-spiral') %>__incl(hw/biot-savart-spiral)<% end_hw() %>

<% begin_hw('capacitor-paradox') %>__incl(hw/capacitor-paradox)<% end_hw() %>

<% end_hw_sec %>

\vfill\pagebreak[4]

 % ==================================================================== 
 % ==================================================================== 
 % ====================================================================  

\begin{exsection}
\extitle{B}{Polarization}

\noindent Apparatus:

\begin{indentedblock}
calcite (Iceland spar) crystal

polaroid film
\end{indentedblock}

1. Lay the crystal on a piece of paper that has print on it.
You will observe a double image. See what happens if
you rotate the crystal.

        Evidently the crystal does something to the light that
passes through it on the way from the page to your eye. One
beam of light enters the crystal from underneath, but two
emerge from the top; by conservation of energy the energy of
the original beam must be shared between them. Consider the
following three possible interpretations of what you have observed:

(a) The two new beams differ from each other, and from the
original beam, only in energy. Their other properties are the same.

(b) The crystal adds to the light some mysterious new
property (not energy), which comes in two flavors, X and
Y. Ordinary light doesn't have any of either. One beam
that emerges from the crystal has some X added to it, and
the other beam has Y.

(c) There is some mysterious new property that is possessed
by all light. It comes in two flavors, X and Y, and most
ordinary light sources make an equal mixture of type X and
type Y light. The original beam is an even mixture of both
types, and this mixture is then split up by the crystal into
the two purified forms.

In parts 2 and 3 you'll make observations that will allow
you to figure out which of these is correct.

2. Now place a polaroid film over the crystal and see what
you observe. What happens when you rotate the film in the
horizontal plane? Does this observation allow you to rule
out any of the three interpretations?

\vspace{20mm}

3. Now put the polaroid film under the crystal and try the
same thing. Putting together all your observations, which
interpretation do you think is correct?

\vspace{20mm}

4. Look at an overhead light fixture through the polaroid,
and try rotating it. What do you observe? What does this
tell you about the light emitted by the lightbulb?

\vspace{20mm}

5. Now position yourself with your head under a light
fixture and directly over a shiny surface, such as a glossy
tabletop. You'll see the lamp's reflection, and the light
coming from the lamp to your eye will have undergone a
reflection through roughly a 180-degree angle (i.e., it very
nearly reversed its direction). Observe this reflection
through the polaroid, and try rotating it. Finally, position
yourself so that you are seeing glancing reflections, and
try the same thing. Summarize what happens to light with
properties X and Y when it is reflected. (This is the
principle behind polarizing sunglasses.)
\end{exsection}

<% end_chapter() %>
